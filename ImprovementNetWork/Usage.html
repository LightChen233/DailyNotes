<!DOCTYPE html>
<html>
  <head>
      <title>Emojify</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      
        <script type="text/x-mathjax-config">
          MathJax.Hub.Config({"extensions":["tex2jax.js"],"jax":["input/TeX","output/HTML-CSS"],"messageStyle":"none","tex2jax":{"processEnvironments":false,"processEscapes":true,"inlineMath":[["$","$"],["\\(","\\)"]],"displayMath":[["$$","$$"],["\\[","\\]"]]},"TeX":{"extensions":["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]},"HTML-CSS":{"availableFonts":["TeX"]}});
        </script>
        <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"></script>
        <link rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.3.1/css/bootstrap.min.css">
        <script src="https://cdn.staticfile.org/jquery/3.2.1/jquery.min.js"></script>
        <script src="https://cdn.staticfile.org/twitter-bootstrap/4.3.1/js/bootstrap.min.js"></script>
      <style>
      /**
 * prism.js Github theme based on GitHub's theme.
 * @author Sam Clarke
 */
code[class*="language-"],
pre[class*="language-"] {
  color: #333;
  background: none;
  font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.4;

  -moz-tab-size: 8;
  -o-tab-size: 8;
  tab-size: 8;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

/* Code blocks */
pre[class*="language-"] {
  padding: .8em;
  overflow: auto;
  /* border: 1px solid #ddd; */
  border-radius: 3px;
  /* background: #fff; */
  background: #f5f5f5;
}

/* Inline code */
:not(pre) > code[class*="language-"] {
  padding: .1em;
  border-radius: .3em;
  white-space: normal;
  background: #f5f5f5;
}

.token.comment,
.token.blockquote {
  color: #969896;
}

.token.cdata {
  color: #183691;
}

.token.doctype,
.token.punctuation,
.token.variable,
.token.macro.property {
  color: #333;
}

.token.operator,
.token.important,
.token.keyword,
.token.rule,
.token.builtin {
  color: #a71d5d;
}

.token.string,
.token.url,
.token.regex,
.token.attr-value {
  color: #183691;
}

.token.property,
.token.number,
.token.boolean,
.token.entity,
.token.atrule,
.token.constant,
.token.symbol,
.token.command,
.token.code {
  color: #0086b3;
}

.token.tag,
.token.selector,
.token.prolog {
  color: #63a35c;
}

.token.function,
.token.namespace,
.token.pseudo-element,
.token.class,
.token.class-name,
.token.pseudo-class,
.token.id,
.token.url-reference .token.variable,
.token.attr-name {
  color: #795da3;
}

.token.entity {
  cursor: help;
}

.token.title,
.token.title .token.punctuation {
  font-weight: bold;
  color: #1d3e81;
}

.token.list {
  color: #ed6a43;
}

.token.inserted {
  background-color: #eaffea;
  color: #55a532;
}

.token.deleted {
  background-color: #ffecec;
  color: #bd2c00;
}

.token.bold {
  font-weight: bold;
}

.token.italic {
  font-style: italic;
}


/* JSON */
.language-json .token.property {
  color: #183691;
}

.language-markup .token.tag .token.punctuation {
  color: #333;
}

/* CSS */
code.language-css,
.language-css .token.function {
  color: #0086b3;
}

/* YAML */
.language-yaml .token.atrule {
  color: #63a35c;
}

code.language-yaml {
  color: #183691;
}

/* Ruby */
.language-ruby .token.function {
  color: #333;
}

/* Markdown */
.language-markdown .token.url {
  color: #795da3;
}

/* Makefile */
.language-makefile .token.symbol {
  color: #795da3;
}

.language-makefile .token.variable {
  color: #183691;
}

.language-makefile .token.builtin {
  color: #0086b3;
}

/* Bash */
.language-bash .token.keyword {
  color: #0086b3;
}

/* highlight */
pre[data-line] {
  position: relative;
  padding: 1em 0 1em 3em;
}
pre[data-line] .line-highlight-wrapper {
  position: absolute;
  top: 0;
  left: 0;
  background-color: transparent;
  display: block;
  width: 100%;
}

pre[data-line] .line-highlight {
  position: absolute;
  left: 0;
  right: 0;
  padding: inherit 0;
  margin-top: 1em;
  background: hsla(24, 20%, 50%,.08);
  background: linear-gradient(to right, hsla(24, 20%, 50%,.1) 70%, hsla(24, 20%, 50%,0));
  pointer-events: none;
  line-height: inherit;
  white-space: pre;
}

pre[data-line] .line-highlight:before, 
pre[data-line] .line-highlight[data-end]:after {
  content: attr(data-start);
  position: absolute;
  top: .4em;
  left: .6em;
  min-width: 1em;
  padding: 0 .5em;
  background-color: hsla(24, 20%, 50%,.4);
  color: hsl(24, 20%, 95%);
  font: bold 65%/1.5 sans-serif;
  text-align: center;
  vertical-align: .3em;
  border-radius: 999px;
  text-shadow: none;
  box-shadow: 0 1px white;
}

pre[data-line] .line-highlight[data-end]:after {
  content: attr(data-end);
  top: auto;
  bottom: .4em;
}html body{font-family:"Helvetica Neue",Helvetica,"Segoe UI",Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ul,html body>ol{margin-bottom:16px}html body ul,html body ol{padding-left:2em}html body ul.no-list,html body ol.no-list{padding:0;list-style-type:none}html body ul ul,html body ul ol,html body ol ol,html body ol ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;background-color:#f0f0f0;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:bold;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:bold}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em !important;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::before,html body code::after{letter-spacing:-0.2em;content:"\00a0"}html body pre>code{padding:0;margin:0;font-size:.85em !important;word-break:normal;white-space:pre;background:transparent;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;font-size:.85em !important;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:before,html body pre tt:before,html body pre code:after,html body pre tt:after{content:normal}html body p,html body blockquote,html body ul,html body ol,html body dl,html body pre{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body pre,html body code{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview .pagebreak,.markdown-preview .newpage{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center !important}.markdown-preview:not([for="preview"]) .code-chunk .btn-group{display:none}.markdown-preview:not([for="preview"]) .code-chunk .status{display:none}.markdown-preview:not([for="preview"]) .code-chunk .output-div{margin-bottom:16px}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for="html-export"]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0}@media screen and (min-width:914px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px + 2em)}}@media screen and (max-width:914px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{font-size:14px !important;padding:1em}}@media print{html body[for="html-export"]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for="html-export"]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,0.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc ul{padding:0 1.6em;margin-top:.8em}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc li{margin-bottom:.8em}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc ul{list-style-type:none}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% -  300px);padding:2em calc(50% - 457px -  150px);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for="html-export"]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for="html-export"]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */

      </style>
    </head>
    <body for="html-export">
      <nav class="navbar navbar-expand-sm bg-dark navbar-dark fixed-top">
        <!-- Brand -->
        <img src="../logo.jpg">
      
        <!-- Links -->
        <ul class="navbar-nav">
          <li class="nav-item dropdown">
            <a class="nav-link" href="../index.html">主页</a>
          </li>
          <li class="nav-item dropdown">
            <a class="nav-link" href="../PyTorch.html">Pytorch</a>
          </li>
          <li class="nav-item dropdown">
            <a class="nav-link" href="../DeepLearning/DeepNetwork.html">人工智能</a>
          </li>
        </ul>
      </nav>
      <br>
      <br>
      <br>
      <div class="container-fluid">
        <div class="row">
          <nav class="col-md-2 d-none d-md-block bg-light sidebar fixed-bottom">
          <div class="sidebar-sticky">
            <ul class="nav flex-column">
              <li class="nav-item">
                <a class="nav-link active" href="#">
                  训练/开发/测试集
                </a>
              </li>
              <li class="nav-item">
                <a class="nav-link" href="#">
                  初始化
                </a>
              </li>
              <li class="nav-item">
                <a class="nav-link" href="#">
                  正则化
                </a>
              </li>
            </ul>
            <br><br><br><br><br><br><br><br><br><br>
            <br><br><br><br><br><br><br><br><br><br>
          </div>
          </nav>
          <main role="main" class="col-md-9 ml-sm-auto col-lg-10 pt-3 px-4">
            <div class="mume markdown-preview  ">
              <h1 class="mume-header" id="%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%AE%9E%E7%94%A8%E5%B1%82%E9%9D%A2">&#x6DF1;&#x5EA6;&#x5B66;&#x4E60;&#x7684;&#x5B9E;&#x7528;&#x5C42;&#x9762;</h1>
        
        <h2 class="mume-header" id="%E8%AE%AD%E7%BB%83%E5%BC%80%E5%8F%91%E6%B5%8B%E8%AF%95%E9%9B%86">&#x8BAD;&#x7EC3;/&#x5F00;&#x53D1;/&#x6D4B;&#x8BD5;&#x96C6;</h2>
        
        <p>&#x5982;&#x679C;&#x60F3;&#x8F6C;&#x53D8;&#x6A21;&#x578B;&#xFF0C;&#x7B49;&#x7B49;&#xFF0C;&#x4E0D;&#x53EF;&#x80FD;&#x90FD;&#x77E5;&#x9053;&#x6700;&#x6709;&#x53C2;&#x6570;&#x662F;&#x4EC0;&#x4E48;&#xFF0C;&#x8FD9;&#x8282;&#x8BFE;&#x6765;&#x8BB2;&#x89E3;&#x5982;&#x4F55;&#x8C03;&#x6574;&#x53C2;&#x6570;&#xFF0C;&#x4F7F;&#x5176;&#x8FBE;&#x5230;&#x6700;&#x4F18;&#xFF08;&#x6216;&#x8F83;&#x4F18;&#xFF09;</p>
        <p>&#x6570;&#x636E;&#x96C6;&#x6570;&#x636E;&#x6211;&#x4EEC;&#x5F80;&#x5F80;&#x628A;&#x5B83;&#x5206;&#x4E3A;&#x8BAD;&#x7EC3;&#x96C6;(training set), &#x9A8C;&#x8BC1;&#x96C6;/&#x5F00;&#x53D1;&#x96C6;(development set(dev set)), &#x6D4B;&#x8BD5;&#x96C6;(test set)&#x3002;</p>
        <p>&#x6211;&#x4EEC;&#x901A;&#x8FC7;&#x9A8C;&#x8BC1;&#x96C6;&#x6216;&#x7B80;&#x5355;&#x4EA4;&#x53C9;&#x9A8C;&#x8BC1;&#x96C6;&#x9009;&#x62E9;&#x6700;&#x597D;&#x7684;&#x6A21;&#x578B;&#xFF0C;&#x7136;&#x540E;&#x5C31;&#x53EF;&#x4EE5;&#x5728;&#x6D4B;&#x8BD5;&#x96C6;&#x4E0A;&#x8FDB;&#x884C;&#x8BC4;&#x4F30;&#x4E86;&#x3002;</p>
        <p>&#x5728;&#x5C0F;&#x6570;&#x636E;&#x65F6;&#x4EE3;&#xFF0C;&#x5F80;&#x5F80;&#x8FD9;&#x4E48;&#x5212;&#x5206;70% / 30%&#x6216;60% / 20% / 20%&#x3010;10,1k&#x7EA7;, 1w&#x7EA7;&#x90FD;&#x662F;&#x6BD4;&#x8F83;&#x6709;&#x6548;&#x7684;&#x3011;</p>
        <p>&#x5728;&#x5927;&#x6570;&#x636E;&#x65F6;&#x4EE3;&#xFF0C;&#x90A3;&#x4E48;&#x9A8C;&#x8BC1;&#x96C6;&#x548C;&#x6D4B;&#x8BD5;&#x63A5;&#x7AD9;&#x6570;&#x636E;&#x603B;&#x91CF;&#x7684;&#x6BD4;&#x4F8B;&#x4F1A;&#x8D8B;&#x5411;&#x4E8E;&#x53D8;&#x5F97;&#x66F4;&#x5C0F;&#xFF0C;&#x56E0;&#x4E3A;&#x9A8C;&#x8BC1;&#x96C6;&#x7684;&#x76EE;&#x7684;&#x5C31;&#x662F;&#x9A8C;&#x8BC1;&#x4E0D;&#x540C;&#x7684;&#x7B97;&#x6CD5;&#x54EA;&#x79CD;&#x66F4;&#x6709;&#x6548;&#xFF0C;&#x56E0;&#x6B64;&#xFF0C;&#x9A8C;&#x8BC1;&#x96C6;&#x8981;&#x8DB3;&#x591F;&#x5927;&#x624D;&#x80FD;&#x8BC4;&#x4F30;&#x3002;&#x6BD4;&#x5982;2&#x4E2A;&#x751A;&#x81F3;10&#x4E2A;&#x4E0D;&#x540C;&#x7B97;&#x6CD5;&#xFF0C;&#x5E76;&#x8FC5;&#x901F;&#x5224;&#x65AD;&#x6811;&#x90A3;&#x79CD;&#x7B97;&#x6CD5;&#x66F4;&#x52A0;&#x6709;&#x6548;&#x3002;&#x6BD4;&#x5982;&#x3010;100w&#x7EA7;&#x3011;&#x6570;&#x636E;&#xFF0C;&#x90A3;&#x4E48;&#x53D6;1w&#x6761;&#x6570;&#x636E;&#x4FBF;&#x8DB3;&#x4EE5;&#x8FDB;&#x884C;&#x8BC4;&#x4F30;&#xFF0C;&#x540C;&#x6837;&#x7684;&#xFF0C;&#x6839;&#x636E;&#x6700;&#x7EC8;&#x9009;&#x62E9;&#x7684;&#x5206;&#x7C7B;&#x5668;&#xFF0C;1k&#x4E2A;&#x6570;&#x636E;&#x7F16;&#x8DB3;&#x4EE5;&#x8BC4;&#x4F30;&#x5355;&#x4E2A;&#x5206;&#x7C7B;&#x5668;&#x3002;&#x6240;&#x4EE5;&#x53EF;&#x4EE5;&#x662F;98% / 1% / 1%&#xFF0C;99.5% / 0.4% / 0.1%&#x7B49;&#x7B49;&#x3002;</p>
        <p>&#x968F;&#x7740;&#x4EBA;&#x5DE5;&#x667A;&#x80FD;&#x7684;&#x6D41;&#x884C;&#xFF0C;&#x548C;&#x6280;&#x672F;&#x7684;&#x666E;&#x53CA;&#xFF0C;&#x73B0;&#x5728;&#x8D8A;&#x6765;&#x8D8A;&#x591A;&#x4EBA;&#x5728;&#x8BAD;&#x7EC3;&#x96C6;&#x548C;&#x6D4B;&#x8BD5;&#x96C6;&#x5206;&#x5E03;&#x4E0D;&#x5339;&#x914D;&#x7684;&#x60C5;&#x51B5;&#x4E0B;&#x8FDB;&#x884C;&#x8BAD;&#x7EC3;&#x3002;&#x73B0;&#x5047;&#x8BBE;&#x4F60;&#x8981;&#x6784;&#x5EFA;&#x4E00;&#x4E2A;&#x7528;&#x6237;&#x53EF;&#x4EE5;&#x4E0A;&#x4F20;&#x5927;&#x91CF;&#x56FE;&#x7247;&#x7684;&#x5E94;&#x7528;&#x7A0B;&#x5E8F;&#x3002;&#x76EE;&#x7684;&#x662F;&#x627E;&#x51FA;&#x5E76;&#x5448;&#x73B0;&#x6240;&#x6709;&#x7684;&#x732B;&#x54AA;&#x56FE;&#x7247;&#xFF0C;&#x8BAD;&#x7EC3;&#x96C6;&#x662F;&#x4F60;&#x7F51;&#x4E0A;&#x6293;&#x53D6;&#x7684;&#x7167;&#x7247;&#x3010;&#x5927;&#x91CF;&#x662F;&#x9AD8;&#x6E05;+&#x7CBE;&#x4FEE;&#x3011;&#xFF0C;&#x800C;&#x9A8C;&#x8BC1;&#x96C6;&#x548C;&#x6D4B;&#x8BD5;&#x96C6;&#x662F;&#x7528;&#x6237;&#x4E0A;&#x4F20;&#x7684;&#x7167;&#x7247;&#x3010;&#x53EF;&#x80FD;&#x968F;&#x624B;&#x4E00;&#x62CD;&#x6216;&#x662F;&#x5341;&#x5206;&#x6A21;&#x7CCA;&#x3011;&#xFF0C;&#x8FD9;&#x6837;&#x5C31;&#x4F1A;&#x5BFC;&#x81F4;&#x8BC6;&#x522B;&#x5EA6;&#x4E0D;&#x9AD8;&#x3002;</p>
        <p>&#x6240;&#x4EE5;&#xFF0C;&#x6700;&#x597D;&#x786E;&#x4FDD;&#x8BAD;&#x7EC3;&#x96C6;&#x548C;&#x6D4B;&#x8BD5;&#x96C6;&#x5206;&#x5E03;&#x5339;&#x914D;&#xFF0C;&#x5C3D;&#x53EF;&#x80FD;&#x7684;&#x4F18;&#x5316;&#x6027;&#x80FD;&#x3002;&#x4E3A;&#x4E86;&#x83B7;&#x53D6;&#x5927;&#x91CF;&#x6570;&#x636E;&#xFF0C;&#x6211;&#x4EEC;&#x5F80;&#x5F80;&#x91C7;&#x53D6;&#x7F51;&#x9875;&#x6293;&#x53D6;&#x7684;&#x65B9;&#x6CD5;&#xFF0C;&#x4F46;&#x662F;&#x4EE3;&#x4EF7;&#x5C31;&#x662F;&#x8BAD;&#x7EC3;&#x96C6;&#x4E0E;&#x9A8C;&#x8BC1;&#x96C6;&#x548C;&#x6D4B;&#x8BD5;&#x96C6;&#x6570;&#x636E;&#xFF0C;&#x53EF;&#x80FD;&#x5206;&#x5E03;&#x4E0D;&#x4E00;&#x81F4;&#xFF0C;&#x4F46;&#x662F;&#x9075;&#x4ECE;&#x4E00;&#x81F4;&#x539F;&#x5219;&#xFF0C;&#x4F60;&#x4F1A;&#x53D1;&#x73B0;&#x673A;&#x5668;&#x5B66;&#x4E60;&#x7B97;&#x6CD5;&#x4F1A;&#x53D8;&#x5F97;&#x66F4;&#x5FEB;&#x3002;</p>
        <p>&#x6CE8;&#x610F;&#xFF1A;&#x6CA1;&#x6709;test&#x96C6;&#x4E5F;&#x6CA1;&#x6709;&#x5173;&#x7CFB;&#xFF0C;test&#x96C6;&#x662F;&#x4E3A;&#x4E86;&#x8FDB;&#x884C;&#x65E0;&#x504F;&#x8BC4;&#x4F30;&#xFF0C;&#x5982;&#x679C;&#x65E0;&#x9700;&#x65E0;&#x504F;&#x8BC4;&#x4F30;&#xFF0C;&#x90A3;&#x5C31;&#x4E0D;&#x9700;&#x8981;&#x4E86;&#x3002;&#x3010;&#x5BF9;&#x4E8E;&#x6CA1;&#x6709;test&#x96C6;&#x7684;&#x6A21;&#x578B;&#xFF0C;&#x6709;&#x65F6;&#x5019;&#x4F1A;&#x628A;dev&#x96C6;&#x79F0;&#x4F5C;test&#x96C6;&#x3011;</p>
        <h2 class="mume-header" id="%E5%81%8F%E5%B7%AE%E6%96%B9%E5%B7%AEbiasvariance">&#x504F;&#x5DEE;/&#x65B9;&#x5DEE;(bias/variance)</h2>
        
        <p>&#x6240;&#x6709;&#x673A;&#x5668;&#x5B66;&#x4E60;&#x7684;&#x4ECE;&#x4E1A;&#x8005;&#x90FD;&#x671F;&#x671B;&#x6DF1;&#x523B;&#x7406;&#x89E3;<strong>&#x504F;&#x5DEE;</strong>&#x548C;<strong>&#x65B9;&#x5DEE;</strong>&#x3002;</p>
        <p>&#x5F88;&#x91CD;&#x8981;&#xFF0C;&#x4F46;&#x662F;&#x6613;&#x5B66;&#x96BE;&#x7CBE;&#x3002;&#x8FD9;&#x4E24;&#x4E2A;&#x90FD;&#x5F71;&#x54CD;&#x7740;&#x673A;&#x5668;&#x5B66;&#x4E60;&#x7684;&#x6548;&#x679C;&#xFF0C;&#x4F46;&#x6DF1;&#x5EA6;&#x5B66;&#x4E60;&#x7684;&#x8BEF;&#x5DEE;&#x5F88;&#x5C11;&#x6743;&#x8861;&#x4E8C;&#x8005;&#x3002;</p>
        <p>&#x5E76;&#x4E0D;&#x80FD;&#x5F88;&#x597D;&#x5730;&#x62DF;&#x5408;&#x66F2;&#x7EBF;&#xFF0C;&#x5373;&#x5F53;<strong>&#x504F;&#x5DEE;&#x9AD8;</strong>&#x7684;&#x60C5;&#x51B5;&#x4E0B;&#xFF0C;&#x79F0;&#x4E4B;&#x4E3A;<strong>&#x6B20;&#x62DF;&#x5408;</strong>&#x3002;&#x3010;&#x76F4;&#x7EBF;&#x592A;&#x8FC7;&#x50F5;&#x76F4;&#x3011;</p>
        <p>&#x76F8;&#x53CD;&#x5730;&#x5982;&#x679C;&#x62DF;&#x5408;&#x4E00;&#x4E2A;&#x8FC7;&#x5EA6;&#x590D;&#x6742;&#x7684;&#x5206;&#x7C7B;&#x5668;&#xFF0C;&#x6BD4;&#x5982;&#x6DF1;&#x5EA6;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x6216;&#x542B;&#x6709;&#x9690;&#x85CF;&#x5355;&#x5143;&#x7684;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#xFF0C;&#x4F1A;&#x8FC7;&#x4E8E;&#x5B8C;&#x7F8E;&#x5730;&#x62DF;&#x5408;&#x8FD9;&#x4E2A;&#x66F2;&#x7EBF;&#x3002;&#x5373;&#x5206;&#x7C7B;&#x5668;<strong>&#x65B9;&#x5DEE;&#x8F83;&#x9AD8;</strong>&#xFF0C;&#x79F0;&#x4E4B;&#x4E3A;<strong>&#x8FC7;&#x62DF;&#x5408;</strong>&#x3002;&#x3010;&#x66F2;&#x7EBF;&#x7075;&#x6D3B;&#x6027;&#x8FC7;&#x9AD8;&#x3011;</p>
        <img src="img/QQ&#x622A;&#x56FE;20200814113238.jpg" style="zoom:60%;">
        <p>&#x73B0;&#x5B9E;&#x4E2D;&#xFF0C;&#x5F80;&#x5F80;&#x5F88;&#x5C11;&#x6709;&#x76F4;&#x63A5;&#x8FD9;&#x6837;&#x7684;&#x754C;&#x9762;&#x5212;&#x5206;&#xFF0C;&#x4F46;&#x662F;&#x4E5F;&#x6709;&#x7C7B;&#x4F3C;&#x7684;&#x73B0;&#x8C61;&#xFF0C;&#x6BD4;&#x5982;&#x4E0B;&#x9762;&#x8FD9;&#x4E2A;&#x732B;&#x732B;&#x5206;&#x7C7B;&#x5668;&#x3002;</p>
        <p>&#x5047;&#x8BBE;&#x8BAD;&#x7EC3;&#x96C6;&#x8BEF;&#x5DEE;&#x548C;&#x9A8C;&#x8BC1;&#x96C6;&#x8BEF;&#x5DEE;&#x3002;</p>
        <h3 class="mume-header" id="a%E9%AB%98%E6%96%B9%E5%B7%AE">A.&#x9AD8;&#x65B9;&#x5DEE;</h3>
        
        <p>&#x8BAD;&#x7EC3;&#x96C6;&#x8BEF;&#x5DEE;&#xFF1A;1%&#x3010;&#x5047;&#x8BBE;&#x8089;&#x773C;&#x8BC6;&#x522B;+&#x6807;&#x7B7E;&#x51E0;&#x4E4E;&#x6CA1;&#x9519;&#x3011;</p>
        <p>&#x9A8C;&#x8BC1;&#x96C6;&#x8BEF;&#x5DEE;&#xFF1A;11%</p>
        <p>&#x8FD9;&#x6837;&#x53EF;&#x4EE5;&#x53D1;&#x73B0;&#xFF0C;&#x8BAD;&#x7EC3;&#x96C6;&#x7684;&#x8BBE;&#x7F6E;&#x8F83;&#x597D;&#xFF0C;&#x4F46;&#x9A8C;&#x8BC1;&#x96C6;&#x7684;&#x8BBE;&#x7F6E;&#x76F8;&#x5BF9;&#x8F83;&#x5DEE;&#xFF0C;&#x5219;&#x6211;&#x4EEC;&#x53EF;&#x80FD;&#x4F1A;&#x8FC7;&#x5EA6;&#x62DF;&#x5408;&#x4E86;&#x8BAD;&#x7EC3;&#x96C6;&#x3002;</p>
        <p>&#x67D0;&#x79CD;&#x7A0B;&#x5EA6;&#x4E0A;&#xFF0C;&#x9A8C;&#x8BC1;&#x96C6;&#x5E76;&#x6CA1;&#x6709;&#x5229;&#x7528;&#x4EA4;&#x53C9;&#x9A8C;&#x8BC1;&#x96C6;&#x7684;&#x4F5C;&#x7528;&#x3002;&#x6211;&#x4EEC;&#x79F0;&#x8FD9;&#x6837;&#x7684;&#x6570;&#x636E;&#x4E3A;<strong>&#x9AD8;&#x65B9;&#x5DEE;</strong>&#xFF0C;&#x901A;&#x8FC7;&#x67E5;&#x770B;&#x8BAD;&#x7EC3;&#x96C6;&#x8BEF;&#x5DEE;&#x548C;&#x9A8C;&#x8BC1;&#x96C6;&#x8BEF;&#x5DEE;&#xFF0C;&#x6211;&#x4EEC;&#x4FBF;&#x53EF;&#x4EE5;&#x8BCA;&#x65AD;&#x7B97;&#x6CD5;&#x662F;&#x5426;&#x5177;&#x6709;&#x9AD8;&#x65B9;&#x5DEE;&#x3002;</p>
        <h3 class="mume-header" id="b%E9%AB%98%E5%81%8F%E5%B7%AE">B.&#x9AD8;&#x504F;&#x5DEE;</h3>
        
        <p>&#x8BAD;&#x7EC3;&#x96C6;&#x8BEF;&#x5DEE;&#xFF1A;15%</p>
        <p>&#x9A8C;&#x8BC1;&#x96C6;&#x8BEF;&#x5DEE;&#xFF1A;16%</p>
        <p>&#x5047;&#x8BBE;&#x8BE5;&#x6848;&#x4F8B;&#x4E2D;&#x4EBA;&#x7684;&#x9519;&#x8BEF;&#x7387;&#x51E0;&#x4E4E;&#x4E3A;0%&#x3002;&#x4E0E;&#x4E4B;&#x76F8;&#x5BF9;&#x7684;&#xFF0C;&#x8BAD;&#x7EC3;&#x96C6;&#x7684;&#x8BC6;&#x522B;&#x8BEF;&#x5DEE;&#x8F83;&#x5927;&#xFF0C;&#x7B97;&#x6CD5;&#x5E76;&#x6CA1;&#x6709;&#x5728;&#x8BAD;&#x7EC3;&#x96C6;&#x4E2D;&#x5F97;&#x5230;&#x5F88;&#x597D;&#x7684;&#x8BAD;&#x7EC3;&#x3002;&#x5982;&#x679C;&#x8BAD;&#x7EC3;&#x6570;&#x636E;&#x7684;&#x62DF;&#x5408;&#x5EA6;&#x4E0D;&#x9AD8;&#xFF0C;&#x5C31;&#x662F;<strong>&#x6B20;&#x62DF;&#x5408;</strong>&#x3002;</p>
        <p>&#x4F46;&#x662F;&#x4ED6;&#x5BF9;&#x4E0E;&#x9A8C;&#x8BC1;&#x96C6;&#x4EA7;&#x751F;&#x7684;&#x7ED3;&#x679C;&#x5374;&#x662F;&#x5408;&#x7406;&#x7684;&#xFF0C;&#x9A8C;&#x8BC1;&#x96C6;&#x4E2D;&#x7684;&#x9519;&#x8BEF;&#x7387;&#x53EA;&#x6BD4;&#x8BAD;&#x7EC3;&#x96C6;&#x591A;&#x4E86;1%&#xFF0C;&#x8FD9;&#x6837;&#x7684;&#x6570;&#x636E;<strong>&#x9AD8;&#x504F;&#x5DEE;</strong>&#x3002;&#x56E0;&#x4E3A;&#x4ED6;&#x751A;&#x81F3;&#x4E0D;&#x80FD;&#x62DF;&#x5408;&#x8BAD;&#x7EC3;&#x96C6;</p>
        <h3 class="mume-header" id="c%E9%AB%98%E6%96%B9%E5%B7%AE%E9%AB%98%E5%81%8F%E5%B7%AE">C.&#x9AD8;&#x65B9;&#x5DEE;+&#x9AD8;&#x504F;&#x5DEE;</h3>
        
        <p>&#x8BAD;&#x7EC3;&#x96C6;&#x8BEF;&#x5DEE;&#xFF1A;15%</p>
        <p>&#x9A8C;&#x8BC1;&#x96C6;&#x8BEF;&#x5DEE;&#xFF1A;30%</p>
        <p>&#x4E24;&#x4E2A;&#x60C5;&#x51B5;&#x90FD;&#x5F88;&#x7CDF;&#x7CD5;&#x3010;&#x522B;&#x8BAD;&#x7EC3;&#x4E86;&#xFF0C;&#x63A5;&#x4E0B;&#x53BB;&#x8BAD;&#x7EC3;&#x6CA1;&#x5565;&#x7528;&#x6362;&#x4E2A;&#x6A21;&#x578B;&#x5427;&#xFF0C;&#x6ED1;&#x7A3D;&#x3011;</p>
        <h3 class="mume-header" id="d%E4%BD%8E%E6%96%B9%E5%B7%AE%E4%BD%8E%E5%81%8F%E5%B7%AE">D.&#x4F4E;&#x65B9;&#x5DEE;+&#x4F4E;&#x504F;&#x5DEE;</h3>
        
        <p>&#x8BAD;&#x7EC3;&#x96C6;&#x8BEF;&#x5DEE;&#xFF1A;0.5%</p>
        <p>&#x9A8C;&#x8BC1;&#x96C6;&#x8BEF;&#x5DEE;&#xFF1A;1%</p>
        <p>&#x5F53;&#x7136;&#xFF0C;&#x8FD9;&#x4E2A;&#x5047;&#x8BBE;&#x7684;&#x524D;&#x63D0;&#x90FD;&#x662F;&#xFF0C;&#x5047;&#x8BBE;&#x8BE5;&#x6848;&#x4F8B;&#x4E2D;&#x4EBA;&#x7684;&#x9519;&#x8BEF;&#x7387;&#x51E0;&#x4E4E;&#x4E3A;0%&#x3002;&#x4E00;&#x822C;&#x6765;&#x8BF4;&#x6700;&#x4F18;&#x8BEF;&#x5DEE;&#x4E5F;&#x88AB;&#x79F0;&#x4E3A;<strong>&#x8D1D;&#x53F6;&#x65AF;&#x8BEF;&#x5DEE;</strong>&#x3010;&#x63A5;&#x8FD1;0%&#xFF0C;&#x5982;&#x679C;&#x4EBA;&#x7684;&#x5206;&#x8FA8;&#x9519;&#x8BEF;&#x7387;&#x90FD;&#x80FD;&#x8FBE;&#x5230;15%&#xFF0C;&#x90A3;&#x4E48;B&#x7EC4;&#x4E5F;&#x8BB8;&#x662F;&#x66F4;&#x597D;&#x7684;&#x9009;&#x62E9;&#x3011;</p>
        <p>&#x90A3;&#x4E48;&#x5F53;&#x6240;&#x6709;&#x5206;&#x7C7B;&#x5668;&#x90FD;&#x4E0D;&#x9876;&#x7528;&#x65F6;&#xFF0C;&#x8BE5;&#x5982;&#x4F55;&#x5206;&#x6790;&#x504F;&#x5DEE;&#x548C;&#x65B9;&#x5DEE;&#x5462;&#xFF1F;&#x5F53;&#x4EBA;&#x7684;&#x9519;&#x8BEF;&#x7387;&#x90FD;&#x6BD4;&#x8F83;&#x9AD8;&#x65F6;&#xFF0C;&#x90A3;&#x4E48;&#x8D1D;&#x53F6;&#x65AF;&#x8BEF;&#x5DEE;&#x4E5F;&#x5C31;&#x6539;&#x53D8;&#x4E86;&#xFF0C;&#x90A3;&#x4E48;&#x5206;&#x6790;&#x8FC7;&#x7A0B;&#x4E5F;&#x5C31;&#x8981;&#x505A;&#x4E9B;&#x6539;&#x53D8;&#x4E86;&#x3002;</p>
        <p>&#x6211;&#x4EEC;&#x4E3B;&#x8981;&#x5148;&#x5224;&#x65AD;&#x662F;&#x5426;&#x65B9;&#x5DEE;&#x8FC7;&#x9AD8;&#xFF0C;&#x53EF;&#x4EE5;&#x6839;&#x636E;&#x6570;&#x636E;&#x7684;&#x62DF;&#x5408;&#x60C5;&#x51B5;&#x6765;&#x5224;&#x65AD;&#xFF0C;&#x7136;&#x540E;&#x67E5;&#x770B;&#x9519;&#x8BEF;&#x7387;&#x6709;&#x591A;&#x9AD8;&#xFF0C;&#x68C0;&#x67E5;&#x9A8C;&#x8BC1;&#x96C6;&#x5224;&#x65AD;&#x65B9;&#x5DEE;&#x662F;&#x5426;&#x8FC7;&#x9AD8;&#x3002;&#x540C;&#x65F6;&#xFF0C;&#x6211;&#x4EEC;&#x8981;&#x6C42;&#x8BAD;&#x7EC3;&#x96C6;&#x548C;&#x9A8C;&#x8BC1;&#x96C6;&#x6765;&#x81EA;&#x76F8;&#x540C;&#x5206;&#x5E03;&#xFF0C;&#x5E76;&#x4E14;&#x9519;&#x8BEF;&#x7387;&#x5DEE;&#x8DDD;&#x8F83;&#x5C0F;&#x3002;</p>
        <h2 class="mume-header" id="%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80">&#x673A;&#x5668;&#x5B66;&#x4E60;&#x57FA;&#x7840;</h2>
        
        <p>&#x5728;&#x7B97;&#x6CD5;&#x8BAD;&#x7EC3;&#x5B8C;&#x6210;&#x65F6;&#xFF0C;&#x6211;&#x4EEC;&#x9996;&#x5148;&#x8981;&#x77E5;&#x9053;&#x7B97;&#x6CD5;&#x7684;&#x504F;&#x5DEE;&#x9AD8;&#x4E0D;&#x9AD8;&#xFF0C;&#x5982;&#x679C;&#x641E;&#xFF0C;&#x8BD5;&#x7740;&#x8BC4;&#x4F30;&#x8BAD;&#x7EC3;&#x96C6;&#x6216;&#x8BAD;&#x7EC3;&#x6570;&#x636E;&#x7684;&#x6027;&#x80FD;&#xFF0C;&#x5982;&#x679C;&#x504F;&#x5DEE;&#x4E5F;&#x5F88;&#x9AD8;&#xFF0C;&#x751A;&#x81F3;&#x65E0;&#x6CD5;&#x62DF;&#x5408;&#x8BAD;&#x7EC3;&#x96C6;&#xFF0C;&#x3010;&#x8BAD;&#x7EC3;&#x96C6;&#x7684;&#x8868;&#x73B0;&#xFF1A;&#x5982;&#x67E5;&#x770B;&#x6210;&#x672C;&#x66F2;&#x7EBF;&#xFF0C;&#x8BAD;&#x7EC3;&#x96C6;&#x7684;&#x51C6;&#x786E;&#x7387;&#x7B49;&#x7B49;&#x3011;&#x90A3;&#x4E48;&#x4F60;&#x5C31;&#x9700;&#x8981;&#x9009;&#x62E9;&#x4E00;&#x4E2A;&#x65B0;&#x7F51;&#x7EDC;&#xFF0C;&#x6BD4;&#x5982;&#x542B;&#x6709;<strong>&#x66F4;&#x591A;&#x9690;&#x5C42;&#x6216;&#x9690;&#x85CF;&#x5355;&#x5143;&#x7684;&#x7F51;&#x7EDC;</strong>&#xFF0C;&#x8BAD;&#x7EC3;&#x66F4;&#x957F;&#x65F6;&#x95F4;&#x7B49;&#x7B49;&#x3002;</p>
        <p>&#x68C0;&#x67E5;&#x504F;&#x5DEE;&#x662F;&#x5426;&#x964D;&#x4F4E;&#x5230;&#x53EF;&#x63A5;&#x53D7;&#x7684;&#x503C;&#xFF0C;&#x4E00;&#x65E6;&#x662F;&#xFF0C;&#x68C0;&#x67E5;&#x65B9;&#x5DEE;&#x662F;&#x5426;&#x6709;&#x95EE;&#x9898;&#xFF0C;&#x3010;&#x6D4B;&#x8BD5;&#x96C6;&#x96C6;&#x7684;&#x8868;&#x73B0;&#xFF1A;&#x5982;&#x67E5;&#x770B;&#x6210;&#x672C;&#x66F2;&#x7EBF;&#xFF0C;&#x51C6;&#x786E;&#x7387;&#x7B49;&#x7B49;&#x3011;&#x3002;&#x5982;&#x679C;&#x6709;&#xFF0C;&#x6700;&#x597D;&#x7684;&#x89E3;&#x51B3;&#x529E;&#x6CD5;&#x662F;&#xFF0C;&#x91C7;&#x96C6;&#x66F4;&#x591A;&#x6570;&#x636E;&#x3002;&#x5982;&#x679C;&#x6CA1;&#x6709;&#x66F4;&#x591A;&#x6570;&#x636E;&#xFF0C;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x91C7;&#x7528;<strong>&#x6B63;&#x5219;&#x5316;</strong>&#x6765;&#x51CF;&#x5C11;&#x8FC7;&#x62DF;&#x5408;&#x3002;&#x6539;&#x53D8;&#x67D0;&#x4E9B;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x67B6;&#x6784;&#x53EF;&#x80FD;&#x8D77;&#x5230;&#x4E00;&#x7BAD;&#x53CC;&#x96D5;&#x7684;&#x6548;&#x679C;&#x3002;&#x3010;&#x52A0;&#x7C97;&#x90E8;&#x5206;&#x5BF9;&#x53E6;&#x4E00;&#x56E0;&#x7D20;&#x5F71;&#x54CD;&#x662F;&#x6BD4;&#x8F83;&#x5C0F;&#x7684;&#x3011;&#x5F53;&#x7136;&#xFF0C;&#x5982;&#x679C;&#x4F60;&#x504F;&#x5DEE;&#x9AD8;&#xFF0C;&#x589E;&#x52A0;&#x6570;&#x636E;&#x91CF;&#x662F;&#x6CA1;&#x6709;&#x7528;&#x7684;&#x3002;</p>
        <p>&#x603B;&#x4E4B;&#xFF0C;&#x8FD9;&#x6837;&#x53CD;&#x590D;&#x67E5;&#x627E;&#xFF0C;&#x6539;&#x8FDB;&#xFF0C;&#x83B7;&#x5F97;&#x4F4E;&#x65B9;&#x5DEE;&#x4F4E;&#x504F;&#x5DEE;&#x7684;&#x6A21;&#x578B;&#xFF0C;&#x4F60;&#x5C31;&#x6210;&#x529F;&#x4E86;&#x3002;</p>
        <p><img src="img/QQ%E6%88%AA%E5%9B%BE20200814145736.jpg" alt></p>
        <h2 class="mume-header" id="%E6%AD%A3%E5%88%99%E5%8C%96">&#x6B63;&#x5219;&#x5316;</h2>
        
        <p>&#x4E0A;&#x6587;&#x8BF4;&#x660E;&#x4E86;&#x6B63;&#x5219;&#x5316;&#x7684;&#x4F5C;&#x7528;&#xFF0C;&#x4E0B;&#x9762;&#x6211;&#x4EEC;&#x6765;&#x8BF4;&#x660E;&#x6B63;&#x5219;&#x5316;&#x7684;&#x53EF;&#x884C;&#x6027;&#x3002;</p>
        <h3 class="mume-header" id="l2%E8%8C%83%E6%95%B0">L2&#x8303;&#x6570;</h3>
        
        <p>&#x8FD9;&#x91CC;&#xFF0C;&#x6211;&#x4EEC;&#x7528;logistic&#x56DE;&#x5F52;&#x6765;&#x5B9E;&#x73B0;&#x8FD9;&#x4E9B;&#x8BBE;&#x60F3;&#xFF0C;&#x5E76;&#x6C42;&#x51FA;&#x6210;&#x672C;&#x51FD;&#x6570;J&#x7684;&#x6700;&#x5C0F;&#x503C;<span class="mathjax-exps">$min_{w,b}J(w,b)$</span>&#x3002;&#x5728;&#x539F;&#x6709;&#x7684;logistic&#x56DE;&#x5F52;&#x7684;&#x57FA;&#x7840;&#x4E0A;&#xFF0C;&#x6211;&#x4EEC;&#x6DFB;&#x52A0;&#x4E86;&#x53C2;&#x6570;<span class="mathjax-exps">$\lambda$</span>&#xFF0C;&#x4E5F;&#x5C31;&#x662F;&#x6B63;&#x5219;&#x5316;&#x53C2;&#x6570;&#x3002;</p>
        <p></p><div class="mathjax-exps">$$J=\frac{1}{m}\sum^m_{i=1}L(\hat y^{(i)},y{(i)})+\frac{\lambda}{2m}||w||^2_2$$</div><br>
        <span class="mathjax-exps">$||w||^2_2$</span>&#x8868;&#x793A;w&#x7684;&#x5E73;&#x65B9;&#x8303;&#x6570;&#x3002;<br>
        <div class="mathjax-exps">$$L2&#x6B63;&#x5219;&#x5316;&#xFF1A;||w||^2_2=\sum^{n_x}_{j=1}w_j^2=w^Tw$$</div><br>
        &#x56E0;&#x4E3A;&#x4F7F;&#x7528;&#x4E86;&#x6B27;&#x51E0;&#x91CC;&#x5F97;&#x6CD5;&#x7EBF;&#xFF0C;&#x5C31;&#x88AB;&#x79F0;&#x4E3A;&#x5411;&#x91CF;&#x53C2;&#x6570;W&#x7684;L2&#x8303;&#x6570;.<p></p>
        <p>&#x4F46;&#x4E3A;&#x4EC0;&#x4E48;&#x53EA;&#x6B63;&#x5219;&#x5316;w&#x5462;&#xFF1F;&#x8FD9;&#x91CC;&#x7684;b&#x5F80;&#x5F80;&#x7701;&#x7565;&#x4E0D;&#x5199;&#xFF0C;&#x56E0;&#x4E3A;W&#x901A;&#x5E38;&#x662F;&#x4E00;&#x4E2A;&#x9AD8;&#x7EF4;&#x53C2;&#x6570;&#x77E2;&#x91CF;&#xFF0C;&#x5DF2;&#x7ECF;&#x53EF;&#x4EE5;&#x8868;&#x8FBE;&#x9AD8;&#x504F;&#x5DEE;&#x7684;&#x95EE;&#x9898;&#x3002;&#x6211;&#x4EEC;&#x4E0D;&#x53EF;&#x80FD;&#x62DF;&#x5408;&#x6240;&#x6709;&#x53C2;&#x6570;&#xFF0C;&#x800C;b&#x53EA;&#x662F;&#x5355;&#x4E2A;&#x6570;&#x5B57;&#xFF0C;&#x6240;&#x4EE5;w&#x51E0;&#x4E4E;&#x6DB5;&#x76D6;&#x4E86;&#x6240;&#x6709;&#x53C2;&#x6570;&#xFF0C;&#x800C;&#x4E0D;&#x662F;b&#xFF0C;&#x6240;&#x4EE5;&#x53EF;&#x4EE5;&#x7701;&#x7565;&#x4E0D;&#x8BA1;&#x3002;</p>
        <h3 class="mume-header" id="l1%E8%8C%83%E6%95%B0">L1&#x8303;&#x6570;</h3>
        
        <p></p><div class="mathjax-exps">$$L1&#x6B63;&#x5219;&#x5316;&#xFF1A;\frac{k\lambda}{m}\sum^{n_x}_{i=1}|w_i|=\frac{k\lambda}{m}||w||_1$$</div><br>
        &#x5982;&#x679C;&#x4F7F;&#x7528;L1&#x6B63;&#x5219;&#x5316;&#xFF0C;W&#x6700;&#x7EC8;&#x4F1A;&#x662F;&#x7A00;&#x758F;&#x7684;&#xFF0C;&#x4E5F;&#x5C31;&#x662F;&#x8BF4;W&#x5411;&#x91CF;&#x4E2D;&#x6709;&#x5F88;&#x591A;0&#x3002;&#x6709;&#x4EBA;&#x8BF4;&#x80FD;&#x591F;&#x6709;&#x5229;&#x4E8E;&#x538B;&#x7F29;&#x7A7A;&#x95F4;&#xFF0C;&#x4F46;&#x662F;&#x6548;&#x679C;&#x4E0D;&#x662F;&#x5F88;&#x660E;&#x663E;&#x3002;<p></p>
        <h3 class="mume-header" id="%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">&#x795E;&#x7ECF;&#x7F51;&#x7EDC;</h3>
        
        <p>&#x90A3;&#x4E48;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x5982;&#x4F55;&#x5B9E;&#x73B0;L2&#x6B63;&#x5219;&#x5316;&#x5462;&#xFF1F;</p>
        <p>&#x8BBE;&#x8BE5;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x6709;m&#x5C42;<br>
        </p><div class="mathjax-exps">$$J(w^{[1]},b^{[1]},...,w^{[L]},b^{[L]})=\frac 1 m \sum^{m}_{i=1}L(\hat y^{(i)},y^{(i)})+\frac{\lambda}{2m}\sum^L_{l=1}||w^{[l]}||^2_F$$</div><br>
        &#x6B64;&#x65F6;&#xFF1A;<br>
        <div class="mathjax-exps">$$||w^{[l]}||^2=\sum_{i=1}^{n^{[l-1]}}\sum_{j=1}^{n^{[l]}}(w_{ij})^2$$</div><br>
        w&#x662F;&#x4E00;&#x4E2A;<span class="mathjax-exps">$(n^{[l-1]},n^{[l]})$</span>&#x5927;&#x5C0F;&#x7684;&#x591A;&#x7EF4;&#x77E9;&#x9635;&#xFF0C;<span class="mathjax-exps">$n^{[l-1]}$</span>&#x8868;&#x793A;&#x4E0A;&#x4E00;&#x5C42;&#x9690;&#x85CF;&#x5355;&#x5143;&#x7684;&#x6570;&#x91CF;&#xFF0C;<span class="mathjax-exps">$n^{[l]}$</span>&#x8868;&#x793A; l &#x5C42;&#x5355;&#x5143;&#x7684;&#x6570;&#x91CF;&#x3002;&#x8BE5;&#x77E9;&#x9635;&#x8303;&#x6570;&#x88AB;&#x79F0;&#x4F5C;<strong>&#x5F17;&#x7F57;&#x8D1D;&#x5C3C;&#x4E4C;&#x65AF;&#x8303;&#x6570;&#xFF08;Frobenius norm of matrix)</strong>&#xFF0C;&#x7528;&#x4E0B;&#x6807;F&#x6807;&#x6CE8;&#x3002;<p></p>
        <p>&#x5BF9;&#x4E8E;&#x53CD;&#x9988;&#x6765;&#x8BF4;&#xFF0C;&#x4F1A;&#x53D8;&#x6210;&#x8FD9;&#x6837;&#xFF1A;<br>
        </p><div class="mathjax-exps">$$\frac{\partial J}{\partial w^{[l]}}=dw^{[l]}=(&#x539F;&#x6765;&#x7684;&#x53CD;&#x9988;&#x51FD;&#x6570;)+\frac{\lambda}{m}w^{[l]}$$</div><br>
        <div class="mathjax-exps">$$w^{[l]}=w^{[l]}-\alpha dw^{[l]}=&#xFF08;&#x539F;&#x6765;&#x7684;&#x66F4;&#x65B0;&#xFF09;-\frac{\lambda}{m}w^{[l]}$$</div><p></p>
        <p>&#x6240;&#x4EE5;&#x6211;&#x4EEC;&#x4E5F;&#x628A;L2&#x6B63;&#x5219;&#x5316;&#x79F0;&#x4E3A;&#x201C;<strong>&#x6743;&#x91CD;&#x8870;&#x51CF;</strong>&#x201D;&#xFF0C;&#x52A0;&#x5FEB;&#x4E86;w&#x6743;&#x91CD;&#x7684;&#x66F4;&#x65B0;&#x901F;&#x7387;&#x3002;</p>
        <h3 class="mume-header" id="%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E9%98%B2%E6%AD%A2%E8%BF%87%E6%8B%9F%E5%90%88">&#x5982;&#x4F55;&#x5B9E;&#x73B0;&#x9632;&#x6B62;&#x8FC7;&#x62DF;&#x5408;&#xFF1F;</h3>
        
        <p>&#x4E3A;&#x4EC0;&#x4E48;&#x6B63;&#x5219;&#x5316;&#x80FD;&#x591F;&#x6709;&#x6548;&#x907F;&#x514D;&#x9AD8;&#x65B9;&#x5DEE;&#xFF0C;&#x9632;&#x6B62;&#x8FC7;&#x62DF;&#x5408;&#x5462;&#xFF1F;&#x4E0B;&#x9762;&#x6211;&#x4EEC;&#x901A;&#x8FC7;&#x51E0;&#x4E2A;&#x4F8B;&#x5B50;&#x8BF4;&#x660E;&#x3002;</p>
        <p>&#x8FD8;&#x662F;&#x4E4B;&#x524D;&#x90A3;&#x5F20;&#x56FE;&#xFF0C;&#x4ECE;&#x5DE6;&#x5230;&#x53F3;&#xFF0C;&#x5206;&#x522B;&#x8868;&#x793A;&#x4E86;&#x6B20;&#x62DF;&#x5408;&#xFF0C;&#x521A;&#x597D;&#x62DF;&#x5408;&#xFF0C;&#x8FC7;&#x62DF;&#x5408;&#x4E09;&#x79CD;&#x60C5;&#x51B5;&#x3002;</p>
        <img src="img/5.jpg" style="zoom:80%;">
        <p>&#x5047;&#x5982;&#x6211;&#x4EEC;&#x9009;&#x62E9;&#x4E86;&#x975E;&#x5E38;&#x590D;&#x6742;&#x7684;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x6A21;&#x578B;&#xFF0C;&#x5982;&#x4E0A;&#x56FE;&#x5DE6;&#x4E0A;&#x89D2;&#x6240;&#x793A;&#x3002;&#x5728;&#x672A;&#x4F7F;&#x7528;&#x6B63;&#x5219;&#x5316;&#x7684;&#x60C5;&#x51B5;&#x4E0B;&#xFF0C;&#x6211;&#x4EEC;&#x5F97;&#x5230;&#x7684;&#x5206;&#x7C7B;&#x8D85;&#x5E73;&#x9762;&#x53EF;&#x80FD;&#x662F;&#x7C7B;&#x4F3C;&#x4E0A;&#x56FE;&#x53F3;&#x4FA7;&#x7684;&#x8FC7;&#x62DF;&#x5408;&#x3002;&#x4F46;&#x662F;&#xFF0C;&#x5982;&#x679C;&#x4F7F;&#x7528;L2&#x6B63;&#x5219;&#x5316;&#xFF0C;&#x5F53;&#x3BB;&#x5F88;&#x5927;&#x65F6;&#xFF0C;w[l]&#x2248;0&#x3002;w[l]&#x8FD1;&#x4F3C;&#x4E3A;&#x96F6;&#xFF0C;&#x610F;&#x5473;&#x7740;&#x8BE5;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x6A21;&#x578B;&#x4E2D;&#x7684;&#x67D0;&#x4E9B;&#x795E;&#x7ECF;&#x5143;&#x5B9E;&#x9645;&#x7684;&#x4F5C;&#x7528;&#x5F88;&#x5C0F;&#xFF0C;&#x53EF;&#x4EE5;&#x5FFD;&#x7565;&#x3002;&#x4ECE;&#x6548;&#x679C;&#x4E0A;&#x6765;&#x770B;&#xFF0C;&#x5176;&#x5B9E;&#x662F;&#x5C06;&#x67D0;&#x4E9B;&#x795E;&#x7ECF;&#x5143;&#x7ED9;&#x5FFD;&#x7565;&#x6389;&#x4E86;&#x3002;&#x8FD9;&#x6837;&#x539F;&#x672C;&#x8FC7;&#x4E8E;&#x590D;&#x6742;&#x7684;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x6A21;&#x578B;&#x5C31;&#x53D8;&#x5F97;&#x4E0D;&#x90A3;&#x4E48;&#x590D;&#x6742;&#x4E86;&#xFF0C;&#x800C;&#x53D8;&#x5F97;&#x975E;&#x5E38;&#x7B80;&#x5355;&#x5316;&#x4E86;&#x3002;</p>
        <p>&#x5982;&#x4E0B;&#x56FE;&#x6240;&#x793A;&#xFF0C;&#x6574;&#x4E2A;&#x7B80;&#x5316;&#x7684;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x6A21;&#x578B;&#x53D8;&#x6210;&#x4E86;&#x4E00;&#x4E2A;&#x903B;&#x8F91;&#x56DE;&#x5F52;&#x6A21;&#x578B;&#x3002;&#x95EE;&#x9898;&#x5C31;&#x4ECE;&#x9AD8;&#x65B9;&#x5DEE;&#x53D8;&#x6210;&#x4E86;&#x9AD8;&#x504F;&#x5DEE;&#x4E86;&#x3002;</p>
        <p><img src="img/7.jpg" alt></p>
        <p>&#x56E0;&#x6B64;&#xFF0C;&#x9009;&#x62E9;&#x5408;&#x9002;&#x5927;&#x5C0F;&#x7684;&#x3BB;&#x503C;&#xFF0C;&#x5C31;&#x80FD;&#x591F;&#x540C;&#x65F6;&#x907F;&#x514D;&#x9AD8;&#x65B9;&#x5DEE;&#x548C;&#x9AD8;&#x504F;&#x5DEE;&#xFF0C;&#x5F97;&#x5230;&#x6700;&#x4F73;&#x6A21;&#x578B;&#x3002;</p>
        <p>&#x8FD8;&#x6709;&#x53E6;&#x5916;&#x4E00;&#x4E2A;&#x76F4;&#x89C2;&#x7684;&#x4F8B;&#x5B50;&#x6765;&#x89E3;&#x91CA;&#x4E3A;&#x4EC0;&#x4E48;&#x6B63;&#x5219;&#x5316;&#x80FD;&#x591F;&#x907F;&#x514D;&#x53D1;&#x751F;&#x8FC7;&#x62DF;&#x5408;&#x3002;</p>
        <p>&#x5047;&#x8BBE;&#x6FC0;&#x6D3B;&#x51FD;&#x6570;&#x662F;tanh&#x51FD;&#x6570;&#x3002;tanh&#x51FD;&#x6570;&#x7684;&#x7279;&#x70B9;&#x662F;&#x5728;z&#x63A5;&#x8FD1;&#x96F6;&#x7684;&#x533A;&#x57DF;&#xFF0C;&#x51FD;&#x6570;&#x8FD1;&#x4F3C;&#x662F;&#x7EBF;&#x6027;&#x7684;&#xFF0C;&#x800C;&#x5F53;<span class="mathjax-exps">$|z|$</span>&#x5F88;&#x5927;&#x7684;&#x65F6;&#x5019;&#xFF0C;&#x51FD;&#x6570;&#x975E;&#x7EBF;&#x6027;&#x4E14;&#x53D8;&#x5316;&#x7F13;&#x6162;&#x3002;</p>
        <p>&#x5F53;&#x4F7F;&#x7528;&#x6B63;&#x5219;&#x5316;&#xFF0C;<span class="mathjax-exps">$&#x3BB;$</span>&#x8F83;&#x5927;&#xFF0C;&#x5373;&#x5BF9;&#x6743;&#x91CD;<span class="mathjax-exps">$w^{[l]}$</span>&#x7684;<strong>&#x60E9;&#x7F5A;</strong>&#x8F83;&#x5927;&#xFF0C;<span class="mathjax-exps">$w^{[l]}$</span>&#x51CF;&#x5C0F;&#x3002;</p>
        <p>&#x56E0;&#x4E3A;<span class="mathjax-exps">$z^{[l]}=w^{[l]}a^{[l]}+b^{[l]}$</span>&#xFF0C;&#x5F53;<span class="mathjax-exps">$w^{[l]}$</span>&#x51CF;&#x5C0F;&#x7684;&#x65F6;&#x5019;&#xFF0C;<span class="mathjax-exps">$z^{[l]}$</span>&#x4E5F;&#x4F1A;&#x51CF;&#x5C0F;&#x3002;&#x5219;&#x6B64;&#x65F6;&#x7684;<span class="mathjax-exps">$z^{[l]}$</span>&#x5206;&#x5E03;&#x5728;tanh&#x51FD;&#x6570;&#x7684;&#x8FD1;&#x4F3C;&#x7EBF;&#x6027;&#x533A;&#x57DF;&#x3002;&#x90A3;&#x4E48;&#x8FD9;&#x4E2A;&#x795E;&#x7ECF;&#x5143;&#x8D77;&#x7684;&#x4F5C;&#x7528;&#x5C31;&#x76F8;&#x5F53;&#x4E8E;&#x662F;&#x7EBF;&#x6027;&#x56DE;&#x5F52;&#x3002;&#x5982;&#x679C;&#x6BCF;&#x4E2A;&#x795E;&#x7ECF;&#x5143;&#x5BF9;&#x5E94;&#x7684;&#x6743;&#x91CD;<span class="mathjax-exps">$w^{[l]}$</span>&#x90FD;&#x6BD4;&#x8F83;&#x5C0F;&#xFF0C;&#x90A3;&#x4E48;&#x6574;&#x4E2A;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x6A21;&#x578B;&#x76F8;&#x5F53;&#x4E8E;&#x662F;&#x591A;&#x4E2A;&#x7EBF;&#x6027;&#x56DE;&#x5F52;&#x7684;&#x7EC4;&#x5408;&#xFF0C;&#x5373;&#x53EF;&#x770B;&#x6210;&#x4E00;&#x4E2A;&#x7EBF;&#x6027;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x3002;&#x5F97;&#x5230;&#x7684;&#x5206;&#x7C7B;&#x8D85;&#x5E73;&#x9762;&#x5C31;&#x4F1A;&#x6BD4;&#x8F83;&#x7B80;&#x5355;&#xFF0C;&#x4E0D;&#x4F1A;&#x51FA;&#x73B0;&#x8FC7;&#x62DF;&#x5408;&#x73B0;&#x8C61;&#x3002;</p>
        <img src="img/6.jpg" style="zoom:80%;">
        <h3 class="mume-header" id="dropout%E6%AD%A3%E5%88%99%E5%8C%96">Dropout&#x6B63;&#x5219;&#x5316;</h3>
        
        <p>Dropout&#x901A;&#x8FC7;&#x6BCF;&#x6B21;&#x8FED;&#x4EE3;&#x8BAD;&#x7EC3;&#x65F6;&#xFF0C;<strong>&#x968F;&#x673A;&#x9009;&#x62E9;&#x4E0D;&#x540C;&#x7684;&#x795E;&#x7ECF;&#x5143;</strong>&#xFF0C;&#x76F8;&#x5F53;&#x4E8E;&#x6BCF;&#x6B21;&#x90FD;&#x5728;&#x4E0D;&#x540C;&#x7684;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x4E0A;&#x8FDB;&#x884C;&#x8BAD;&#x7EC3;&#xFF0C;&#x80FD;&#x591F;&#x9632;&#x6B62;&#x8FC7;&#x62DF;&#x5408;&#x3002;</p>
        <p>&#x9664;&#x6B64;&#x4E4B;&#x5916;&#xFF0C;&#x8FD8;&#x53EF;&#x4EE5;&#x4ECE;&#x6743;&#x91CD;w&#x7684;&#x89D2;&#x5EA6;&#x6765;&#x89E3;&#x91CA;&#x4E3A;&#x4EC0;&#x4E48;dropout&#x80FD;&#x591F;&#x6709;&#x6548;&#x9632;&#x6B62;&#x8FC7;&#x62DF;&#x5408;&#x3002;&#x5BF9;&#x4E8E;&#x67D0;&#x4E2A;&#x795E;&#x7ECF;&#x5143;&#x6765;&#x8BF4;&#xFF0C;&#x67D0;&#x6B21;&#x8BAD;&#x7EC3;&#x65F6;&#xFF0C;&#x5B83;&#x7684;&#x67D0;&#x4E9B;&#x8F93;&#x5165;&#x5728;dropout&#x7684;&#x4F5C;&#x7528;&#x88AB;&#x8FC7;&#x6EE4;&#x4E86;&#x3002;&#x800C;&#x5728;&#x4E0B;&#x4E00;&#x6B21;&#x8BAD;&#x7EC3;&#x65F6;&#xFF0C;&#x53C8;&#x6709;&#x4E0D;&#x540C;&#x7684;&#x67D0;&#x4E9B;&#x8F93;&#x5165;&#x88AB;&#x8FC7;&#x6EE4;&#x3002;&#x7ECF;&#x8FC7;&#x591A;&#x6B21;&#x8BAD;&#x7EC3;&#x540E;&#xFF0C;&#x67D0;&#x4E9B;&#x8F93;&#x5165;&#x88AB;&#x8FC7;&#x6EE4;&#xFF0C;&#x67D0;&#x4E9B;&#x8F93;&#x5165;&#x88AB;&#x4FDD;&#x7559;&#x3002;&#x8FD9;&#x6837;&#xFF0C;&#x8BE5;&#x795E;&#x7ECF;&#x5143;&#x5C31;&#x4E0D;&#x4F1A;&#x53D7;&#x67D0;&#x4E2A;&#x8F93;&#x5165;&#x975E;&#x5E38;&#x5927;&#x7684;&#x5F71;&#x54CD;&#xFF0C;&#x5F71;&#x54CD;&#x88AB;&#x5747;&#x5300;&#x5316;&#x4E86;&#x3002;&#x4E5F;&#x5C31;&#x662F;&#x8BF4;&#xFF0C;&#x5BF9;&#x5E94;&#x7684;&#x6743;&#x91CD;w&#x4E0D;&#x4F1A;&#x5F88;&#x5927;&#x3002;&#x8FD9;&#x4ECE;&#x4ECE;&#x6548;&#x679C;&#x4E0A;&#x6765;&#x8BF4;&#xFF0C;&#x4E0E;L2 &#x6B63;&#x5219;&#x5316;&#x662F;&#x7C7B;&#x4F3C;&#x7684;&#xFF0C;&#x90FD;&#x662F;&#x5BF9;&#x6743;&#x91CD;w&#x8FDB;&#x884C;&#x201C;<strong>&#x60E9;&#x7F5A;</strong>&#x201D;&#xFF0C;&#x51CF;&#x5C0F;&#x4E86;w&#x7684;&#x503C;&#x3002;</p>
        <img src="img/2.jpg" style="zoom:80%;">
        <p>&#x603B;&#x7ED3;&#x4E00;&#x4E0B;&#xFF0C;&#x5BF9;&#x4E8E;&#x540C;&#x4E00;&#x7EC4;&#x8BAD;&#x7EC3;&#x6570;&#x636E;&#xFF0C;&#x5229;&#x7528;&#x4E0D;&#x540C;&#x7684;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x8BAD;&#x7EC3;&#x4E4B;&#x540E;&#xFF0C;&#x6C42;&#x5176;&#x8F93;&#x51FA;&#x7684;&#x5E73;&#x5747;&#x503C;&#x53EF;&#x4EE5;&#x51CF;&#x5C11;&#x8FC7;&#x62DF;&#x5408;&#x3002;Dropout&#x5C31;&#x662F;&#x5229;&#x7528;&#x8FD9;&#x4E2A;&#x539F;&#x7406;&#xFF0C;&#x6BCF;&#x6B21;&#x4E22;&#x6389;&#x4E00;&#x5B9A;&#x6570;&#x91CF;&#x7684;&#x9690;&#x85CF;&#x5C42;&#x795E;&#x7ECF;&#x5143;&#xFF0C;<strong>&#x76F8;&#x5F53;&#x4E8E;&#x5728;&#x4E0D;&#x540C;&#x7684;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x4E0A;&#x8FDB;&#x884C;&#x8BAD;&#x7EC3;</strong>&#xFF0C;&#x8FD9;&#x6837;&#x5C31;<strong>&#x51CF;&#x5C11;&#x4E86;&#x795E;&#x7ECF;&#x5143;&#x4E4B;&#x95F4;&#x7684;&#x4F9D;&#x8D56;&#x6027;</strong>&#xFF0C;&#x5373;&#x6BCF;&#x4E2A;&#x795E;&#x7ECF;&#x5143;&#x4E0D;&#x80FD;&#x4F9D;&#x8D56;&#x4E8E;&#x67D0;&#x51E0;&#x4E2A;&#x5176;&#x4ED6;&#x7684;&#x795E;&#x7ECF;&#x5143;&#xFF08;&#x6307;&#x5C42;&#x4E0E;&#x5C42;&#x4E4B;&#x95F4;&#x76F8;&#x8FDE;&#x63A5;&#x7684;&#x795E;&#x7ECF;&#x5143;&#xFF09;&#xFF0C;&#x4F7F;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x66F4;&#x52A0;&#x80FD;&#x5B66;&#x4E60;&#x5230;&#x4E0E;&#x5176;&#x4ED6;&#x795E;&#x7ECF;&#x5143;&#x4E4B;&#x95F4;&#x7684;&#x66F4;&#x52A0;&#x5065;&#x58EE;&#x7684;&#x7279;&#x5F81;&#x3002;</p>
        <h4 class="mume-header" id="%E6%B3%A8%E6%84%8F">&#x6CE8;&#x610F;&#xFF1A;</h4>
        
        <p>&#x9996;&#x5148;&#xFF0C;&#x4E0D;&#x540C;&#x9690;&#x85CF;&#x5C42;&#x7684;dropout&#x7CFB;&#x6570;keep_prob&#x53EF;&#x4EE5;&#x4E0D;&#x540C;&#x3002;&#x4E00;&#x822C;&#x6765;&#x8BF4;&#xFF0C;&#x795E;&#x7ECF;&#x5143;&#x8D8A;&#x591A;&#x7684;&#x9690;&#x85CF;&#x5C42;&#xFF0C;keep_out&#x53EF;&#x4EE5;&#x8BBE;&#x7F6E;&#x5F97;&#x5C0F;&#x4E00;&#x4E9B;&#xFF0C;&#x4F8B;&#x5982;0.5&#xFF1B;&#x795E;&#x7ECF;&#x5143;&#x8D8A;&#x5C11;&#x7684;&#x9690;&#x85CF;&#x5C42;&#xFF0C;keep_out&#x53EF;&#x4EE5;&#x8BBE;&#x7F6E;&#x7684;&#x5927;&#x4E00;&#x4E9B;&#xFF0C;&#x4F8B;&#x5982;0.8&#xFF0C;&#x8BBE;&#x7F6E;&#x662F;1&#x3002;</p>
        <p>&#x53E6;&#x5916;&#xFF0C;&#x5B9E;&#x9645;&#x5E94;&#x7528;&#x4E2D;&#xFF0C;&#x4E0D;&#x5EFA;&#x8BAE;&#x5BF9;&#x8F93;&#x5165;&#x5C42;&#x8FDB;&#x884C;dropout&#xFF0C;&#x5982;&#x679C;&#x8F93;&#x5165;&#x5C42;&#x7EF4;&#x5EA6;&#x5F88;&#x5927;&#xFF0C;&#x4F8B;&#x5982;&#x56FE;&#x7247;&#xFF0C;&#x90A3;&#x4E48;&#x53EF;&#x4EE5;&#x8BBE;&#x7F6E;dropout&#xFF0C;&#x4F46;keep_out&#x5E94;&#x8BBE;&#x7F6E;&#x7684;&#x5927;&#x4E00;&#x4E9B;&#xFF0C;&#x4F8B;&#x5982;0.8&#xFF0C;0.9&#x3002;&#x603B;&#x4F53;&#x6765;&#x8BF4;&#xFF0C;&#x5C31;&#x662F;&#x8D8A;&#x5BB9;&#x6613;&#x51FA;&#x73B0;overfitting&#x7684;&#x9690;&#x85CF;&#x5C42;&#xFF0C;&#x5176;keep_prob&#x5C31;&#x8BBE;&#x7F6E;&#x7684;&#x76F8;&#x5BF9;&#x5C0F;&#x4E00;&#x4E9B;&#x3002;&#x6CA1;&#x6709;&#x51C6;&#x786E;&#x56FA;&#x5B9A;&#x7684;&#x505A;&#x6CD5;&#xFF0C;&#x901A;&#x5E38;&#x53EF;&#x4EE5;&#x6839;&#x636E;validation&#x8FDB;&#x884C;&#x9009;&#x62E9;&#x3002;</p>
        <p>Dropout&#x5728;&#x7535;&#x8111;&#x89C6;&#x89C9;CV&#x9886;&#x57DF;&#x5E94;&#x7528;&#x6BD4;&#x8F83;&#x5E7F;&#x6CDB;&#xFF0C;&#x56E0;&#x4E3A;&#x8F93;&#x5165;&#x5C42;&#x7EF4;&#x5EA6;&#x8F83;&#x5927;&#xFF0C;&#x800C;&#x4E14;&#x6CA1;&#x6709;&#x8DB3;&#x591F;&#x591A;&#x7684;&#x6837;&#x672C;&#x6570;&#x91CF;&#x3002;&#x503C;&#x5F97;&#x6CE8;&#x610F;&#x7684;&#x662F;dropout&#x662F;&#x4E00;&#x79CD;regularization&#x6280;&#x5DE7;&#xFF0C;&#x7528;&#x6765;&#x9632;&#x6B62;&#x8FC7;&#x62DF;&#x5408;&#x7684;&#xFF0C;&#x6700;&#x597D;&#x53EA;&#x5728;&#x9700;&#x8981;regularization&#x7684;&#x65F6;&#x5019;&#x4F7F;&#x7528;dropout&#x3002;</p>
        <p>&#x4F7F;&#x7528;dropout&#x7684;&#x65F6;&#x5019;&#xFF0C;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;&#x7ED8;&#x5236;cost function&#x6765;&#x8FDB;&#x884C;debug&#xFF0C;&#x770B;&#x770B;dropout&#x662F;&#x5426;&#x6B63;&#x786E;&#x6267;&#x884C;&#x3002;&#x4E00;&#x822C;&#x505A;&#x6CD5;&#x662F;&#xFF0C;&#x5C06;&#x6240;&#x6709;&#x5C42;&#x7684;keep_prob&#x5168;&#x8BBE;&#x7F6E;&#x4E3A;1&#xFF0C;&#x518D;&#x7ED8;&#x5236;cost function&#xFF0C;&#x5373;&#x6DB5;&#x76D6;&#x6240;&#x6709;&#x795E;&#x7ECF;&#x5143;&#xFF0C;&#x770B;J&#x662F;&#x5426;&#x5355;&#x8C03;&#x4E0B;&#x964D;&#x3002;&#x4E0B;&#x4E00;&#x6B21;&#x8FED;&#x4EE3;&#x8BAD;&#x7EC3;&#x65F6;&#xFF0C;&#x518D;&#x5C06;keep_prob&#x8BBE;&#x7F6E;&#x4E3A;&#x5176;&#x5B83;&#x503C;&#x3002;</p>
        <p>&#x8BBE;&#x7F6E;&#x4E00;&#x5B9A;&#x6982;&#x7387;&#x53BB;&#x6389;&#x4E00;&#x4E9B;&#x70B9;&#xFF0C;&#x9632;&#x6B62;&#x8FC7;&#x5EA6;&#x62DF;&#x5408;&#xFF0C;&#x51CF;&#x5C11;&#x8FD0;&#x7B97;&#x3002;</p>
        <img src="img/QQ&#x622A;&#x56FE;20200814161558.jpg" style="zoom:50%;">
        <h4 class="mume-header" id="%E9%9A%8F%E6%9C%BA%E5%8F%8D%E5%90%91%E5%A4%B1%E6%B4%BB">&#x968F;&#x673A;&#x53CD;&#x5411;&#x5931;&#x6D3B;</h4>
        
        <p>&#x597D;&#x50CF;&#x6BCF;&#x6B21;&#x8FED;&#x4EE3;&#x540E;&#xFF0C;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x90FD;&#x4F1A;&#x53D8;&#x5F97;&#x6BD4;&#x4EE5;&#x524D;&#x66F4;&#x5C0F;&#xFF0C;&#x611F;&#x89C9;&#x4E0A;&#x597D;&#x50CF;&#x5C0F;&#x89C4;&#x6A21;&#x7684;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x6548;&#x679C;&#x662F;&#x4E00;&#x6837;&#x7684;&#x3002;&#x6211;&#x4EEC;&#x4ECE;&#x5355;&#x4E2A;&#x795E;&#x7ECF;&#x5143;&#x5165;&#x624B;&#xFF0C;&#x5982;&#x56FE;&#xFF0C;&#x8FD9;&#x4E2A;&#x5355;&#x5143;&#x7684;&#x5DE5;&#x4F5C;&#x5C31;&#x662F;&#x8F93;&#x5165;&#x5E76;&#x751F;&#x6210;&#x4E00;&#x4E9B;&#x6709;&#x610F;&#x4E49;&#x7684;&#x8F93;&#x51FA;&#xFF0C;&#x8FD9;&#x4E2A;&#x795E;&#x7ECF;&#x5143;&#x4E0D;&#x80FD;&#x4F9D;&#x9760;&#x4EFB;&#x4F55;&#x5355;&#x4E00;&#x7684;&#x7279;&#x5F81;&#x8F93;&#x5165;&#xFF0C;&#x56E0;&#x4E3A;&#x6240;&#x6709;&#x8F93;&#x5165;&#x90FD;&#x6709;&#x53EF;&#x80FD;&#x88AB;&#x6E05;&#x9664;&#x3002;&#x56E0;&#x6B64;&#x8BE5;&#x5355;&#x5143;&#x5E94;&#x8BE5;&#x901A;&#x8FC7;&#x8FD9;&#x79CD;&#x65B9;&#x5F0F;&#x79EF;&#x6781;&#x7684;&#x4F20;&#x64AD;&#x5F00;&#xFF0C;&#x5E76;&#x4E3A;&#x5355;&#x5143;&#x7684;&#x56DB;&#x4E2A;&#x8F93;&#x5165;&#x589E;&#x52A0;&#x4E00;&#x70B9;&#x6743;&#x91CD;&#x3002;</p>
        <p><img src="img/QQ%E6%88%AA%E5%9B%BE20200814164122.jpg" alt></p>
        <p>&#x62C5;&#x5FC3;&#x8FC7;&#x5EA6;&#x62DF;&#x5408;&#xFF0C;&#x5C31;&#x53EF;&#x4EE5;&#x628A;&#x53EF;&#x80FD;&#x4EA7;&#x751F;&#x8FC7;&#x62DF;&#x5408;&#x7684;&#x5927;&#x91CF;&#x795E;&#x7ECF;&#x5143;&#x7684;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x5C42;&#x7684;keep-prob&#x503C;&#x8BBE;&#x7F6E;&#x7684;&#x6BD4;&#x5176;&#x5B83;&#x5C42;&#x4F4E;&#xFF0C;&#x7F3A;&#x70B9;&#x662F;&#x4E3A;&#x4E86;&#x4F7F;&#x7528;&#x4EA4;&#x53C9;&#x9A8C;&#x8BC1;&#xFF0C;&#x4F60;&#x9700;&#x8981;&#x641C;&#x7D22;&#x66F4;&#x591A;&#x7684;&#x8D85;&#x7EA7;&#x53C2;&#x6570;&#x3002;&#x53E6;&#x4E00;&#x79CD;&#x662F;&#x5728;&#x67D0;&#x4E9B;&#x5C42;&#x4F7F;&#x7528;dropout&#xFF0C;&#x6709;&#x4E9B;&#x4E0D;&#x4F7F;&#x7528;&#xFF0C;&#x5E94;&#x7528;dropout&#x7684;&#x5C42;&#x53EA;&#x542B;&#x6709;&#x4E00;&#x4E2A;&#x8D85;&#x7EA7;&#x53C2;&#x6570;&#xFF08;hyper parameter&#xFF09;&#x3002;&#x3010;&#x9664;&#x4E86;&#x8BA1;&#x7B97;&#x673A;&#x89C6;&#x89C9;&#x9886;&#x57DF;&#xFF0C;&#x5176;&#x4ED6;&#x9886;&#x57DF;&#x5E94;&#x7528;&#x8F83;&#x5C11;&#x3011;&#x9664;&#x975E;&#x4E00;&#x76F4;&#x5B58;&#x5728;&#x8FC7;&#x62DF;&#x5408;&#x3002;</p>
        <h4 class="mume-header" id="%E7%BC%BA%E7%82%B9">&#x7F3A;&#x70B9;</h4>
        
        <p>cost&#x51FD;&#x6570;J&#x4E0D;&#x518D;&#x88AB;&#x660E;&#x786E;&#x5B9A;&#x4E49;&#x3002;</p>
        <p>&#x96BE;&#x4EE5;&#x590D;&#x67E5;&#x5176;&#x6027;&#x80FD;&#x3002;</p>
        <h3 class="mume-header" id="%E5%85%B6%E4%BB%96%E6%AD%A3%E5%88%99%E5%8C%96%E6%96%B9%E6%B3%95">&#x5176;&#x4ED6;&#x6B63;&#x5219;&#x5316;&#x65B9;&#x6CD5;</h3>
        
        <h4 class="mume-header" id="%E6%B3%9B%E5%8C%96">&#x6CDB;&#x5316;</h4>
        
        <p>&#x5047;&#x8BBE;&#x4F60;&#x6B63;&#x5728;&#x62DF;&#x5408;&#x732B;&#x54AA;&#x56FE;&#x7247;&#x5206;&#x7C7B;&#x5668;&#xFF0C;&#x4E3A;&#x4E86;&#x66F4;&#x597D;&#x5730;&#x6CDB;&#x5316;&#xFF0C;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x7FFB;&#x8F6C;&#x6216;&#x968F;&#x610F;&#x88C1;&#x526A;&#xFF0C;&#x65CB;&#x8F6C;&#x8FD9;&#x4E2A;&#x56FE;&#x50CF;&#xFF0C;&#x5C3D;&#x7BA1;&#x8FD9;&#x4E9B;&#x989D;&#x5916;&#x7684;&#x5047;&#x6570;&#x636E;&#x6CA1;&#x6709;&#x5168;&#x65B0;&#x7684;&#x6570;&#x636E;&#x90A3;&#x4E48;&#x591A;&#x4FE1;&#x606F;&#xFF0C;&#x4F46;&#x662F;&#x6211;&#x4EEC;&#x8FD9;&#x4E48;&#x505A;&#x57FA;&#x672C;&#x6CA1;&#x6709;&#x8BDD;&#x8D39;&#xFF0C;&#x4EE3;&#x4EF7;&#x51E0;&#x4E4E;&#x4E3A;0&#x3002;&#x3010;&#x9664;&#x4E86;&#x4E00;&#x4E9B;&#x5BF9;&#x6297;&#x6027;&#x4EE3;&#x4EF7;&#x3011;&#x4EE5;&#x8FD9;&#x79CD;&#x65B9;&#x5F0F;&#x6269;&#x589E;&#x7B97;&#x6CD5;&#x6570;&#x636E;&#xFF0C;&#x8FDB;&#x800C;&#x6B63;&#x5219;&#x5316;&#x6570;&#x636E;&#x96C6;&#xFF0C;&#x51CF;&#x5C11;&#x8FC7;&#x62DF;&#x5408;&#x6BD4;&#x8F83;&#x5EC9;&#x4EF7;&#x3002;</p>
        <p>&#x5F53;&#x7136;&#x5BF9;&#x4E8E;&#x67D0;&#x4E9B;&#x56FE;&#x50CF;&#x4E5F;&#x53EF;&#x4EE5;&#x8FDB;&#x884C;&#x9002;&#x5F53;&#x7684;&#x626D;&#x66F2;&#xFF0C;&#x6765;&#x8FDB;&#x884C;&#x6CDB;&#x5316;&#x5904;&#x7406;</p>
        <p><img src="img/QQ%E6%88%AA%E5%9B%BE20200814171541.jpg" alt></p>
        <p>&#x673A;&#x5668;&#x5B66;&#x4E60;&#x5305;&#x62EC;&#x51E0;&#x4E2A;&#x6B65;&#x9AA4;&#xFF0C;&#x5176;&#x4E2D;&#x4E00;&#x6B65;&#x662F;&#x9009;&#x62E9;&#x4E00;&#x4E2A;&#x7B97;&#x6CD5;&#x6765;&#x4F18;&#x5316;cost&#x51FD;&#x6570;J&#xFF0C;&#x6211;&#x4EEC;&#x6709;&#x8BB8;&#x591A;&#x5DE5;&#x5177;&#x6765;&#x89E3;&#x51B3;&#x8FD9;&#x4E2A;&#x95EE;&#x9898;&#xFF0C;&#x5982;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#xFF0C;Momentum&#xFF0C;RMSProp&#xFF0C;Adam&#x7B49;&#x7B49;&#x3002;</p>
        <p>&#x4F46;&#x662F;&#x4F18;&#x5316;J&#x540E;&#x6211;&#x4E5F;&#x4E0D;&#x60F3;&#x53D1;&#x751F;&#x8FC7;&#x62DF;&#x5408;&#xFF0C;&#x6211;&#x4EEC;&#x4E5F;&#x6709;&#x4E00;&#x4E9B;&#x5DE5;&#x5177;&#x6765;&#x89E3;&#x51B3;&#x8FD9;&#x4E2A;&#x95EE;&#x9898;&#xFF0C;&#x5982;&#x6B63;&#x5219;&#x5316;&#xFF0C;&#x6269;&#x589E;&#x6570;&#x636E;&#x7B49;&#x7B49;&#x3002;</p>
        <p>&#x5728;&#x673A;&#x5668;&#x5B66;&#x4E60;&#x4E2D;&#xFF0C;&#x8D85;&#x53C2;&#x6570;&#x6FC0;&#x589E;&#xFF0C;&#x9009;&#x51FA;&#x53EF;&#x884C;&#x7684;&#x7B97;&#x6CD5;&#x4E5F;&#x53D8;&#x5F97;&#x8D8A;&#x6765;&#x8D8A;&#x590D;&#x6742;&#x3002;&#x6211;&#x53D1;&#x73B0;&#xFF0C;&#x5982;&#x679C;&#x6211;&#x4EEC;&#x7528;&#x4E00;&#x7EC4;&#x5DE5;&#x5177;&#x4F18;&#x5316;&#x51FD;&#x6570;J,&#x673A;&#x5668;&#x5B66;&#x4E60;&#x5C31;&#x4F1A;&#x53D8;&#x5F97;&#x66F4;&#x7B80;&#x5355;&#x3002;&#x5728;&#x91CD;&#x70B9;&#x4F18;&#x5316;&#x4EE3;&#x4EF7;&#x51FD;&#x6570;J&#x65F6;&#xFF0C;&#x4F60;&#x53EA;&#x9700;&#x8981;&#x7559;&#x610F;w&#x548C;b&#xFF0C;J(w,b)&#x7684;&#x503C;&#x8D8A;&#x5C0F;&#x8D8A;&#x597D;&#x3002;&#x4F60;&#x53EA;&#x9700;&#x8981;&#x60F3;&#x529E;&#x6CD5;&#x51CF;&#x5C0F;&#x8FD9;&#x4E2A;&#x503C;&#xFF0C;&#x5176;&#x4ED6;&#x7684;&#x4E0D;&#x7528;&#x5173;&#x6CE8;&#x3002;&#x7136;&#x540E;&#xFF0C;&#x9884;&#x9632;&#x8FC7;&#x62DF;&#x5408;&#x8FD8;&#x6709;&#x5176;&#x4ED6;&#x4EFB;&#x52A1;&#xFF0C;&#x6362;&#x53E5;&#x8BDD;&#x8BF4;&#x5C31;&#x662F;&#x51CF;&#x5C11;&#x65B9;&#x5DEE;&#x3002;&#x8FD9;&#x4E2A;&#x539F;&#x7406;&#x6709;&#x65F6;&#x5019;&#x88AB;&#x79F0;&#x4E3A;**&#x201C;&#x6B63;&#x4EA4;&#x5316;&#x201D;**&#x3002;</p>
        <h4 class="mume-header" id="%E6%8F%90%E5%89%8D%E5%81%9C%E6%AD%A2">&#x63D0;&#x524D;&#x505C;&#x6B62;</h4>
        
        <p>&#x8BAD;&#x7EC3;&#x8FC7;&#x5EA6;&#x4F1A;&#x8FC7;&#x62DF;&#x5408;&#xFF0C;&#x6240;&#x4EE5;&#x6211;&#x4EEC;&#x5E94;&#x5F53;&#x63D0;&#x65E9;&#x505C;&#x6B62;&#x8BAD;&#x7EC3;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x3002;</p>
        <h5 class="mume-header" id="%E4%BC%98%E7%82%B9">&#x4F18;&#x70B9;</h5>
        
        <p>&#x53EA;&#x8FD0;&#x884C;&#x4E00;&#x6B21;&#x5761;&#x5EA6;&#x4E0B;&#x964D;&#xFF0C;&#x4F60;&#x53EF;&#x4EE5;&#x627E;&#x51FA;W&#x7684;&#x8F83;&#x5C0F;&#x503C;&#xFF0C;&#x4E2D;&#x95F4;&#x503C;&#x548C;&#x8F83;&#x5927;&#x503C;&#xFF0C;&#x800C;&#x65E0;&#x9700;&#x5C1D;&#x8BD5;L2&#x6B63;&#x5219;&#x5316;&#x8D85;&#x53C2;&#x6570;<span class="mathjax-exps">$\lambda$</span>&#x7684;&#x5F88;&#x591A;&#x503C;&#x3002;</p>
        <p><img src="img/QQ%E6%88%AA%E5%9B%BE20200814171714.jpg" alt></p>
        <h5 class="mume-header" id="%E7%BC%BA%E7%82%B9-1">&#x7F3A;&#x70B9;</h5>
        
        <p>&#x4E0D;&#x80FD;&#x72EC;&#x7ACB;&#x7684;&#x5904;&#x7406;&#x4E0A;&#x8FF0;&#x7684;&#x4E24;&#x4E2A;&#x95EE;&#x9898;&#xFF0C;&#x56E0;&#x4E3A;&#x63D0;&#x524D;&#x505C;&#x6B62;&#x4E86;&#x5FAA;&#x73AF;&#xFF0C;&#x4E5F;&#x5C31;&#x505C;&#x6B62;&#x4E86;&#x4F18;&#x5316;cost&#x51FD;&#x6570;J</p>
        <h4 class="mume-header" id="l2%E6%AD%A3%E5%88%99%E5%8C%96">L2&#x6B63;&#x5219;&#x5316;</h4>
        
        <p>&#x8FD9;&#x5BFC;&#x81F4;&#x8D85;&#x53C2;&#x641C;&#x7D22;&#x7A7A;&#x95F4;&#x66F4;&#x5BB9;&#x6613;&#x5206;&#x89E3;&#xFF0C;&#x4E5F;&#x66F4;&#x5BB9;&#x6613;&#x641C;&#x7D22;&#xFF0C;&#x4F46;&#x7F3A;&#x70B9;&#x662F;&#x4F60;&#x5FC5;&#x987B;&#x5C1D;&#x8BD5;&#x5F88;&#x591A;&#x6B63;&#x5219;&#x5316;&#x53C2;&#x6570;<span class="mathjax-exps">$\lambda$</span>&#x7684;&#x503C;&#x3002;&#x8FD9;&#x4E5F;&#x5BFC;&#x81F4;&#x641C;&#x7D22;&#x5927;&#x91CF;<span class="mathjax-exps">$\lambda$</span>&#x503C;&#x7684;&#x8BA1;&#x7B97;&#x4EE3;&#x4EF7;&#x592A;&#x9AD8;</p>
        <h2 class="mume-header" id="%E6%AD%A3%E5%88%99%E5%8C%96%E8%BE%93%E5%85%A5%E5%BD%92%E4%B8%80%E5%8C%96%E8%BE%93%E5%85%A5">&#x6B63;&#x5219;&#x5316;&#x8F93;&#x5165;/&#x5F52;&#x4E00;&#x5316;&#x8F93;&#x5165;</h2>
        
        <p>&#x8BAD;&#x7EC3;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x65F6;&#xFF0C;&#x5176;&#x4E2D;&#x4E00;&#x4E2A;&#x52A0;&#x901F;&#x8BAD;&#x7EC3;&#x7684;&#x65B9;&#x6CD5;&#x5C31;&#x662F;&#x5F52;&#x4E00;&#x5316;&#x8F93;&#x5165;&#x3002;</p>
        <p>&#x5047;&#x8BBE;&#xFF0C;&#x6211;&#x4EEC;&#x6709;&#x4E00;&#x4E2A;&#x8BAD;&#x7EC3;&#x96C6;&#xFF0C;&#x4ED6;&#x6709;&#x4E24;&#x4E2A;&#x8F93;&#x5165;&#x7279;&#x5F81;&#xFF0C;&#x6240;&#x4EE5;&#x8F93;&#x5165;&#x7279;&#x5F81;x&#x662F;&#x4E8C;&#x7EF4;&#x7684;&#x3002;</p>
        <p>&#x5F52;&#x4E00;&#x5316;&#x8F93;&#x5165;&#x5F80;&#x5F80;&#x6709;&#x4E24;&#x6B65;&#x3002;</p>
        <h3 class="mume-header" id="%E7%AC%AC%E4%B8%80%E6%AD%A5%E9%9B%B6%E5%9D%87%E5%80%BC%E5%8C%96">&#x7B2C;&#x4E00;&#x6B65;&#xFF1A;&#x96F6;&#x5747;&#x503C;&#x5316;</h3>
        
        <p></p><div class="mathjax-exps">$$\mu =\frac{1}{m}\sum^m_{i=1}x^{(i)}$$</div><p></p>
        <p></p><div class="mathjax-exps">$$x=x-\mu$$</div><p></p>
        <p>&#x610F;&#x601D;&#x662F;&#x79FB;&#x52A8;&#x8BAD;&#x7EC3;&#x96C6;&#xFF0C;&#x76F4;&#x5230;&#x5B83;&#x5B8C;&#x6210;&#x96F6;&#x5747;&#x503C;&#x5316;&#x3002;&#x3010;&#x6563;&#x843D;&#x5728;y=0&#x5468;&#x56F4;&#x3011;</p>
        <img src="img/QQ&#x622A;&#x56FE;20200814174326.jpg" style="zoom:60%;">
        <h3 class="mume-header" id="%E7%AC%AC%E4%BA%8C%E6%AD%A5%E5%BD%92%E4%B8%80%E5%8C%96%E6%96%B9%E5%B7%AEnormalize-variances">&#x7B2C;&#x4E8C;&#x6B65;&#xFF1A;&#x5F52;&#x4E00;&#x5316;&#x65B9;&#x5DEE;&#xFF08;Normalize Variances&#xFF09;</h3>
        
        <p>&#x6CE8;&#x610F;&#xFF1A;&#x7279;&#x5F81;x1&#x7684;&#x65B9;&#x5DEE;&#x6BD4;&#x7279;&#x5F81;x2&#x7684;&#x65B9;&#x5DEE;&#x5927;&#x5F97;&#x591A;&#x3002;&#x6211;&#x4EEC;&#x8981;&#x505A;&#x7684;&#x662F;&#x7ED9;<span class="mathjax-exps">$\sigma$</span>&#x8D4B;&#x503C;.<br>
        </p><div class="mathjax-exps">$$\sigma ^2=\frac{1}{m}\sum^M_{i=1} x^{(i)}**2$$</div><p></p>
        <p></p><div class="mathjax-exps">$$x/=\sigma ^2$$</div><p></p>
        <p><img src="img/QQ%E6%88%AA%E5%9B%BE20200814175050.jpg" alt></p>
        <p>&#x8FD9;&#x6837;&#x5C31;&#x80FD;&#x8F83;&#x597D;&#x7684;&#x5206;&#x5E03;&#x5728;&#x65B9;&#x5DEE;&#x8F83;&#x5C0F;&#x3010;&#x65B9;&#x5DEE;&#x5747;&#x4E3A;1&#x3011;&#x7684;&#x8303;&#x56F4;&#x5185;&#x4E86;&#x3002;&#x6240;&#x4EE5;&#xFF0C;&#x4E4B;&#x6240;&#x4EE5;&#x8981;&#x5BF9;&#x8F93;&#x5165;&#x8FDB;&#x884C;&#x6807;&#x51C6;&#x5316;&#x64CD;&#x4F5C;&#xFF0C;&#x4E3B;&#x8981;&#x662F;&#x4E3A;&#x4E86;&#x8BA9;&#x6240;&#x6709;&#x8F93;&#x5165;&#x5F52;&#x4E00;&#x5316;&#x540C;&#x6837;&#x7684;&#x5C3A;&#x5EA6;&#x4E0A;&#xFF0C;&#x65B9;&#x4FBF;&#x8FDB;&#x884C;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x7B97;&#x6CD5;&#x65F6;&#x80FD;&#x591F;&#x66F4;&#x5FEB;&#x66F4;&#x51C6;&#x786E;&#x5730;&#x627E;&#x5230;&#x5168;&#x5C40;&#x6700;&#x4F18;&#x89E3;&#x3002;</p>
        <p><strong>&#x63D0;&#x793A;&#xFF1A;<strong>&#x7531;&#x4E8E;&#x8BAD;&#x7EC3;&#x96C6;&#x8FDB;&#x884C;&#x4E86;&#x6807;&#x51C6;&#x5316;&#x5904;&#x7406;&#xFF0C;&#x90A3;&#x4E48;&#x5BF9;&#x4E8E;&#x6D4B;&#x8BD5;&#x96C6;&#x6216;&#x5728;&#x5B9E;&#x9645;&#x5E94;&#x7528;&#x65F6;&#xFF0C;&#x5E94;&#x8BE5;&#x4F7F;&#x7528;</strong>&#x540C;&#x6837;</strong>&#x7684;<span class="mathjax-exps">$&#x3BC;$</span>&#x548C;<span class="mathjax-exps">$&#x3C3;^2$</span>&#x5BF9;&#x5176;&#x8FDB;&#x884C;&#x6807;&#x51C6;&#x5316;&#x5904;&#x7406;&#x3002;&#x8FD9;&#x6837;&#x4FDD;&#x8BC1;&#x4E86;&#x8BAD;&#x7EC3;&#x96C6;&#x5408;&#x6D4B;&#x8BD5;&#x96C6;&#x7684;&#x6807;&#x51C6;&#x5316;&#x64CD;&#x4F5C;&#x4E00;&#x81F4;&#x3002;&#x56E0;&#x4E3A;&#x6211;&#x4EEC;&#x5E0C;&#x671B;&#x80FD;&#x5F97;&#x5230;&#x76F8;&#x540C;&#x7684;&#x6570;&#x636E;&#x8F6C;&#x6362;&#xFF0C;&#x6240;&#x4EE5;&#x4E0D;&#x8BBA;<span class="mathjax-exps">$\mu$</span>&#x548C;<span class="mathjax-exps">$\sigma ^2$</span>&#x7684;&#x503C;&#x662F;&#x4EC0;&#x4E48;&#xFF0C;&#x8FD9;&#x4E24;&#x4E2A;x&#x76F8;&#x5173;&#x7684;&#x516C;&#x5F0F;&#x4E2D;&#x90FD;&#x4F1A;&#x7528;&#x5230;&#x5B83;&#xFF0C;&#x6240;&#x4EE5;&#x4F60;&#x8981;&#x7528;&#x76F8;&#x540C;&#x65B9;&#x6CD5;&#x8C03;&#x6574;&#x6D4B;&#x8BD5;&#x96C6;&#x3002;&#x800C;&#x4E0D;&#x662F;&#x5206;&#x522B;&#x9884;&#x4F30;&#x8BAD;&#x7EC3;&#x96C6;&#x548C;&#x6D4B;&#x8BD5;&#x96C6;&#x7684;<span class="mathjax-exps">$\mu$</span>&#x548C;<span class="mathjax-exps">$\sigma ^2$</span>&#x3002;</p>
        <h3 class="mume-header" id="%E4%BE%8B%E5%AD%90">&#x4F8B;&#x5B50;&#xFF1A;</h3>
        
        <p>&#x5982;&#x679C;<span class="mathjax-exps">$x_1\in(0, 1000),x_2\in(0,1)$</span>&#xFF0C;&#x7ED3;&#x679C;&#x662F;&#x53C2;&#x6570;w1&#x548C;w2&#x503C;&#x7684;&#x8303;&#x56F4;&#x6216;&#x6BD4;&#x7387;&#x5C06;&#x4F1A;&#x975E;&#x5E38;&#x4E0D;&#x540C;&#x3002;</p>
        <p>&#x5982;&#x679C;&#x4E0D;&#x8FDB;&#x884C;&#x6807;&#x51C6;&#x5316;&#x5904;&#x7406;&#xFF0C;x1&#x4E0E;x2&#x4E4B;&#x95F4;&#x5206;&#x5E03;&#x6781;&#x4E0D;&#x5E73;&#x8861;&#xFF0C;&#x8BAD;&#x7EC3;&#x5F97;&#x5230;&#x7684;w1&#x548C;w2&#x4E5F;&#x4F1A;&#x5728;&#x6570;&#x91CF;&#x7EA7;&#x4E0A;&#x5DEE;&#x522B;&#x5F88;&#x5927;&#x3002;&#x8FD9;&#x6837;&#x5BFC;&#x81F4;&#x7684;&#x7ED3;&#x679C;&#x662F;cost function&#x4E0E;w&#x548C;b&#x7684;&#x5173;&#x7CFB;&#x53EF;&#x80FD;&#x662F;&#x4E00;&#x4E2A;&#x975E;&#x5E38;&#x7EC6;&#x957F;&#x7684;&#x692D;&#x5706;&#x5F62;&#x7897;&#x3002;&#x5BF9;&#x5176;&#x8FDB;&#x884C;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x7B97;&#x6CD5;&#x65F6;&#xFF0C;&#x7531;&#x4E8E;w1&#x548C;w2&#x6570;&#x503C;&#x5DEE;&#x5F02;&#x5F88;&#x5927;&#xFF0C;&#x53EA;&#x80FD;&#x9009;&#x62E9;&#x5F88;&#x5C0F;&#x7684;&#x5B66;&#x4E60;&#x56E0;&#x5B50;&#x3B1;&#xFF0C;&#x6765;&#x907F;&#x514D;J&#x53D1;&#x751F;&#x632F;&#x8361;&#x3002;&#x4E00;&#x65E6;&#x3B1;&#x8F83;&#x5927;&#xFF0C;&#x5FC5;&#x7136;&#x53D1;&#x751F;&#x632F;&#x8361;&#xFF0C;J&#x4E0D;&#x518D;&#x5355;&#x8C03;&#x4E0B;&#x964D;&#x3002;&#x5982;&#x4E0B;&#x5DE6;&#x56FE;&#x6240;&#x793A;&#x3002;</p>
        <p>&#x5982;&#x679C;&#x8FDB;&#x884C;&#x4E86;&#x6807;&#x51C6;&#x5316;&#x64CD;&#x4F5C;&#xFF0C;x1&#x4E0E;x2&#x5206;&#x5E03;&#x5747;&#x5300;&#xFF0C;w1&#x548C;w2&#x6570;&#x503C;&#x5DEE;&#x522B;&#x4E0D;&#x5927;&#xFF0C;&#x5F97;&#x5230;&#x7684;cost&#x51FD;&#x6570;&#x4E0E;w&#x548C;b&#x7684;&#x5173;&#x7CFB;&#x662F;&#x7C7B;&#x4F3C;&#x5706;&#x5F62;&#x7897;&#x3002;&#x5BF9;&#x5176;&#x8FDB;&#x884C;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x7B97;&#x6CD5;&#x65F6;&#xFF0C;&#x3B1;&#x53EF;&#x4EE5;&#x9009;&#x62E9;&#x76F8;&#x5BF9;&#x5927;&#x4E00;&#x4E9B;&#xFF0C;&#x4E14;J&#x4E00;&#x822C;&#x4E0D;&#x4F1A;&#x53D1;&#x751F;&#x632F;&#x8361;&#xFF0C;&#x4FDD;&#x8BC1;&#x4E86;J&#x662F;&#x5355;&#x8C03;&#x4E0B;&#x964D;&#x7684;&#x3002;&#x5982;&#x4E0B;&#x53F3;&#x56FE;&#x6240;&#x793A;&#x3002;</p>
        <img src="img/3.jpg" style="zoom:80%;">
        <p>&#x53E6;&#x5916;&#x4E00;&#x79CD;&#x60C5;&#x51B5;&#xFF0C;&#x5982;&#x679C;&#x8F93;&#x5165;&#x7279;&#x5F81;&#x4E4B;&#x95F4;&#x7684;&#x8303;&#x56F4;&#x672C;&#x6765;&#x5C31;&#x6BD4;&#x8F83;&#x63A5;&#x8FD1;&#xFF0C;&#x90A3;&#x4E48;&#x4E0D;&#x8FDB;&#x884C;&#x6807;&#x51C6;&#x5316;&#x64CD;&#x4F5C;&#x4E5F;&#x662F;&#x6CA1;&#x6709;&#x592A;&#x5927;&#x5F71;&#x54CD;&#x7684;&#x3002;&#x4F46;&#x662F;&#xFF0C;&#x6807;&#x51C6;&#x5316;&#x5904;&#x7406;&#x5728;&#x5927;&#x591A;&#x6570;&#x573A;&#x5408;&#x4E0B;&#x8FD8;&#x662F;&#x503C;&#x5F97;&#x63A8;&#x8350;&#x7684;&#x3002;</p>
        <h2 class="mume-header" id="%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1%E4%B8%8E%E6%A2%AF%E5%BA%A6%E7%88%86%E7%82%B8">&#x68AF;&#x5EA6;&#x6D88;&#x5931;&#x4E0E;&#x68AF;&#x5EA6;&#x7206;&#x70B8;</h2>
        
        <p>&#x8BAD;&#x7EC3;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#xFF0C;&#x5C24;&#x5176;&#x662F;&#x6DF1;&#x5EA6;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x6240;&#x9762;&#x4E34;&#x7684;&#x7684;&#x95EE;&#x9898;&#x662F;&#xFF0C;&#x68AF;&#x5EA6;&#x6D88;&#x5931;&#x6216;&#x68AF;&#x5EA6;&#x7206;&#x70B8;&#xFF0C;&#x6307;&#x5BFC;&#x6570;&#x4F1A;&#x53D8;&#x5F97;&#x975E;&#x5E38;&#x5927;&#x6216;&#x8005;&#x975E;&#x5E38;&#x5C0F;&#xFF0C;&#x8FD9;&#x663E;&#x8457;&#x5730;&#x52A0;&#x5927;&#x4E86;&#x8BAD;&#x7EC3;&#x7684;&#x96BE;&#x5EA6;&#xFF0C;&#x672C;&#x7AE0;&#x4F60;&#x5C06;&#x4F1A;&#x4E86;&#x89E3;&#x68AF;&#x5EA6;&#x6D88;&#x5931;&#x4E0E;&#x68AF;&#x5EA6;&#x7206;&#x70B8;&#x7684;&#x771F;&#x6B63;&#x542B;&#x4E49;&#xFF0C;&#x4EE5;&#x53CA;&#x5982;&#x4F55;&#x66F4;&#x52A0;&#x660E;&#x667A;&#x7684;&#x9009;&#x62E9;&#x968F;&#x673A;&#x521D;&#x59CB;&#x5316;&#x6743;&#x91CD;&#x3002;&#x5047;&#x8BBE;&#x4F60;&#x6B63;&#x5728;&#x8BAD;&#x7EC3;&#x8FD9;&#x6837;&#x4E00;&#x4E2A;&#x6781;&#x6DF1;&#x7684;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x3002;</p>
        <p>&#x4E3E;&#x4E2A;&#x4F8B;&#x5B50;&#x6765;&#x8BF4;&#x660E;&#xFF0C;&#x5047;&#x8BBE;&#x4E00;&#x4E2A;&#x591A;&#x5C42;&#x7684;&#x6BCF;&#x5C42;&#x53EA;&#x5305;&#x542B;&#x4E24;&#x4E2A;&#x795E;&#x7ECF;&#x5143;&#x7684;&#x6DF1;&#x5EA6;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x6A21;&#x578B;&#xFF0C;&#x5982;&#x4E0B;&#x56FE;&#x6240;&#x793A;&#xFF1A;</p>
        <img src="img/4.jpg" style="zoom:80%;">
        <p>&#x4E3A;&#x4E86;&#x7B80;&#x5316;&#x590D;&#x6742;&#x5EA6;&#xFF0C;&#x4FBF;&#x4E8E;&#x5206;&#x6790;&#xFF0C;&#x6211;&#x4EEC;&#x4EE4;&#x5404;&#x5C42;&#x7684;&#x6FC0;&#x6D3B;&#x51FD;&#x6570;&#x4E3A;&#x7EBF;&#x6027;&#x51FD;&#x6570;&#xFF0C;&#x5373;<span class="mathjax-exps">$g(Z)=Z$</span>&#x3002;&#x4E14;&#x5FFD;&#x7565;&#x5404;&#x5C42;&#x5E38;&#x6570;&#x9879;b&#x7684;&#x5F71;&#x54CD;&#xFF0C;&#x4EE4;b&#x5168;&#x90E8;&#x4E3A;&#x96F6;&#x3002;&#x90A3;&#x4E48;&#xFF0C;&#x8BE5;&#x7F51;&#x7EDC;&#x7684;&#x9884;&#x6D4B;&#x8F93;&#x51FA;<span class="mathjax-exps">$\hat Y$</span>&#x4E3A;&#xFF1A;</p>
        <p><span class="mathjax-exps">$\hat Y=W^{[L]}W^{[L&#x2212;1]}&#x22EF;W^{[1]}X$</span></p>
        <p>&#x5982;&#x679C;&#x5404;&#x5C42;&#x6743;&#x91CD;<span class="mathjax-exps">$W^{[l]}$</span>&#x7684;&#x5143;&#x7D20;&#x90FD;&#x7A0D;&#x5927;&#x4E8E;1&#xFF0C;&#x4F8B;&#x5982;1.5&#xFF0C;&#x5219;&#x9884;&#x6D4B;&#x8F93;&#x51FA;<span class="mathjax-exps">$\hat Y$</span>&#x5C06;&#x6B63;&#x6BD4;&#x4E8E;<span class="mathjax-exps">$1.5^L$</span>&#x3002;L&#x8D8A;&#x5927;&#xFF0C;<span class="mathjax-exps">$\hat Y$</span>&#x8D8A;&#x5927;&#xFF0C;&#x4E14;&#x5448;&#x6307;&#x6570;&#x578B;&#x589E;&#x957F;&#x3002;&#x6211;&#x4EEC;&#x79F0;&#x4E4B;&#x4E3A;&#x6570;&#x503C;&#x7206;&#x70B8;&#x3002;&#x76F8;&#x53CD;&#xFF0C;&#x5982;&#x679C;&#x5404;&#x5C42;&#x6743;&#x91CD;<span class="mathjax-exps">$W^{[l]}$</span>&#x7684;&#x5143;&#x7D20;&#x90FD;&#x7A0D;&#x5C0F;&#x4E8E;1&#xFF0C;&#x4F8B;&#x5982;0.5&#xFF0C;&#x5219;&#x9884;&#x6D4B;&#x8F93;&#x51FA;<span class="mathjax-exps">$\hat Y$</span>&#x5C06;&#x6B63;&#x6BD4;&#x4E8E;<span class="mathjax-exps">$0.5^L$</span>&#x3002;&#x7F51;&#x7EDC;&#x5C42;&#x6570;L&#x8D8A;&#x591A;&#xFF0C;<span class="mathjax-exps">$\hat Y$</span>&#x5448;&#x6307;&#x6570;&#x578B;&#x51CF;&#x5C0F;&#x3002;&#x6211;&#x4EEC;&#x79F0;&#x4E4B;&#x4E3A;&#x6570;&#x503C;&#x6D88;&#x5931;&#x3002;</p>
        <p>&#x4E5F;&#x5C31;&#x662F;&#x8BF4;&#xFF0C;&#x5982;&#x679C;&#x5404;&#x5C42;&#x6743;&#x91CD;<span class="mathjax-exps">$W^{[l]}$</span>&#x90FD;&#x5927;&#x4E8E;1&#x6216;&#x8005;&#x90FD;&#x5C0F;&#x4E8E;1&#xFF0C;&#x90A3;&#x4E48;&#x5404;&#x5C42;&#x6FC0;&#x6D3B;&#x51FD;&#x6570;&#x7684;&#x8F93;&#x51FA;&#x5C06;&#x968F;&#x7740;&#x5C42;&#x6570;ll&#x7684;&#x589E;&#x52A0;&#xFF0C;&#x5448;&#x6307;&#x6570;&#x578B;&#x589E;&#x5927;&#x6216;&#x51CF;&#x5C0F;&#x3002;&#x5F53;&#x5C42;&#x6570;&#x5F88;&#x5927;&#x65F6;&#xFF0C;&#x51FA;&#x73B0;&#x6570;&#x503C;&#x7206;&#x70B8;&#x6216;&#x6D88;&#x5931;&#x3002;&#x540C;&#x6837;&#xFF0C;&#x8FD9;&#x79CD;&#x60C5;&#x51B5;&#x4E5F;&#x4F1A;&#x5F15;&#x8D77;&#x68AF;&#x5EA6;&#x5448;&#x73B0;&#x540C;&#x6837;&#x7684;&#x6307;&#x6570;&#x578B;&#x589E;&#x5927;&#x6216;&#x51CF;&#x5C0F;&#x7684;&#x53D8;&#x5316;&#x3002;L&#x975E;&#x5E38;&#x5927;&#x65F6;&#xFF0C;&#x4F8B;&#x5982;L=150&#xFF0C;&#x5219;&#x68AF;&#x5EA6;&#x4F1A;&#x975E;&#x5E38;&#x5927;&#x6216;&#x975E;&#x5E38;&#x5C0F;&#xFF0C;&#x5F15;&#x8D77;&#x6BCF;&#x6B21;&#x66F4;&#x65B0;&#x7684;&#x6B65;&#x8FDB;&#x957F;&#x5EA6;&#x8FC7;&#x5927;&#x6216;&#x8005;&#x8FC7;&#x5C0F;&#xFF0C;&#x8FD9;&#x8BA9;&#x8BAD;&#x7EC3;&#x8FC7;&#x7A0B;&#x5341;&#x5206;&#x56F0;&#x96BE;&#x3002;</p>
        <h2 class="mume-header" id="%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E6%9D%83%E9%87%8D%E5%88%9D%E5%A7%8B%E5%8C%96">&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x7684;&#x6743;&#x91CD;&#x521D;&#x59CB;&#x5316;</h2>
        
        <p>&#x6700;&#x7EC8;&#xFF0C;&#x9488;&#x5BF9;&#x8BE5;&#x95EE;&#x9898;&#xFF0C;&#x6211;&#x4EEC;&#x60F3;&#x51FA;&#x4E86;&#x4E00;&#x4E2A;&#x4E0D;&#x5B8C;&#x6574;&#x7684;&#x89E3;&#x51B3;&#x65B9;&#x6848;&#xFF0C;&#x867D;&#x7136;&#x4E0D;&#x80FD;&#x5F7B;&#x5E95;&#x89E3;&#x51B3;&#x95EE;&#x9898;&#xFF0C;&#x5374;&#x5F88;&#x6709;&#x7528;&#x3002;&#x6709;&#x52A9;&#x4E8E;&#x6211;&#x4EEC;&#x4E3A;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x66F4;&#x52A0;&#x8C28;&#x614E;&#x5730;&#x9009;&#x62E9;&#x968F;&#x673A;&#x521D;&#x59CB;&#x5316;&#x53C2;&#x6570;&#x3002;</p>
        <p>&#x8FD9;&#x4E2A;&#x65B9;&#x6CD5;&#x5C31;&#x662F;&#x5BF9;&#x6743;&#x91CD;w&#x8FDB;&#x884C;&#x4E00;&#x4E9B;&#x521D;&#x59CB;&#x5316;&#x5904;&#x7406;&#x3002;</p>
        <p>&#x5728;&#x8FD9;&#x91CC;&#xFF0C;&#x6211;&#x4EEC;&#x4E0D;&#x59A8;&#x4EE5;&#x5355;&#x4E2A;&#x795E;&#x7ECF;&#x5143;&#x4E3A;&#x4F8B;&#xFF0C;&#x8BBE;&#x5176;&#x7684;&#x8F93;&#x5165;&#x4E2A;&#x6570;&#x4E3A;n&#xFF0C;&#x5176;&#x8F93;&#x51FA;&#x4E3A;&#x3010;&#x8FD9;&#x91CC;&#x5FFD;&#x7565;&#x4E86;&#x5E38;&#x6570;&#x9879;b&#x3011;&#xFF1A;</p>
        <p></p><div class="mathjax-exps">$$z=w_1x_1+w_2x_2+&#x22EF;+w_nx_n$$</div><p></p>
        <p></p><div class="mathjax-exps">$$a=g(z)$$</div><p></p>
        <img src="img/1.jpg" style="zoom:50%;">
        <p>&#x4E3A;&#x4E86;z&#x9632;&#x6B62;&#x8FC7;&#x5927;&#x6216;&#x8FC7;&#x5C0F;&#xFF0C;&#x5C31;&#x8981;&#x4F7F;w&#x4E0E;n&#x76F8;&#x5173;&#x8054;&#xFF0C;&#x4E14;n&#x8D8A;&#x5927;&#xFF0C;w&#x5E94;&#x8BE5;&#x8D8A;&#x5C0F;&#x624D;&#x597D;&#x3002;&#x8FD9;&#x6837;&#x80FD;&#x591F;&#x4FDD;&#x8BC1;z&#x4E0D;&#x4F1A;&#x8FC7;&#x5927;&#x3002;</p>
        <p>&#x6240;&#x4EE5;&#x6309;&#x7167;&#x8FD9;&#x4E2A;&#x89C4;&#x5B9A;&#xFF0C;&#x8FD9;&#x91CC;&#x63D0;&#x4F9B;&#x4E86;&#x4E00;&#x79CD;&#x65B9;&#x6CD5;&#xFF0C;&#x5C31;&#x662F;&#x5728;&#x521D;&#x59CB;&#x5316;w&#x65F6;&#xFF0C;&#x4EE4;&#x5176;&#x65B9;&#x5DEE;&#x4E3A;<span class="mathjax-exps">$\frac1 n$</span>&#x3002;&#x76F8;&#x5E94;&#x7684;python&#x4F2A;&#x4EE3;&#x7801;&#x4E3A;&#xFF1A;</p>
        <pre data-role="codeBlock" data-info="python" class="language-python">w<span class="token punctuation">[</span>l<span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>n<span class="token punctuation">[</span>l<span class="token punctuation">]</span><span class="token punctuation">,</span>n<span class="token punctuation">[</span>l<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">*</span>np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">/</span>n<span class="token punctuation">[</span>l<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> 
        </pre><p>&#x5982;&#x679C;&#x6FC0;&#x6D3B;&#x51FD;&#x6570;&#x662F;tanh&#xFF0C;&#x4E00;&#x822C;&#x9009;&#x62E9;&#x4E0A;&#x9762;&#x7684;&#x521D;&#x59CB;&#x5316;&#x65B9;&#x6CD5;&#x3002;</p>
        <p>&#x5982;&#x679C;&#x6FC0;&#x6D3B;&#x51FD;&#x6570;&#x662F;ReLU&#xFF0C;&#x6743;&#x91CD;w&#x7684;&#x521D;&#x59CB;&#x5316;&#x4E00;&#x822C;&#x4EE4;&#x5176;&#x65B9;&#x5DEE;&#x4E3A;<span class="mathjax-exps">$\frac 2 n$</span>&#xFF1A;</p>
        <pre data-role="codeBlock" data-info="python" class="language-python">w<span class="token punctuation">[</span>l<span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>n<span class="token punctuation">[</span>l<span class="token punctuation">]</span><span class="token punctuation">,</span>n<span class="token punctuation">[</span>l<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">*</span>np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span><span class="token number">2</span><span class="token operator">/</span>n<span class="token punctuation">[</span>l<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> 
        </pre><p>&#x9664;&#x6B64;&#x4E4B;&#x5916;&#xFF0C;Yoshua Bengio&#x63D0;&#x51FA;&#x4E86;&#x53E6;&#x5916;&#x4E00;&#x79CD;&#x521D;&#x59CB;&#x5316;w&#x7684;&#x65B9;&#x6CD5;&#xFF0C;&#x4EE4;&#x5176;&#x65B9;&#x5DEE;&#x4E3A;<span class="mathjax-exps">$\frac{2}{n^{[l&#x2212;1]}+n^{[l]}}$</span>&#xFF1A;</p>
        <pre data-role="codeBlock" data-info="python" class="language-python">w<span class="token punctuation">[</span>l<span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>n<span class="token punctuation">[</span>l<span class="token punctuation">]</span><span class="token punctuation">,</span>n<span class="token punctuation">[</span>l<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">*</span>np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span><span class="token number">2</span><span class="token operator">/</span>n<span class="token punctuation">[</span>l<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">+</span>n<span class="token punctuation">[</span>l<span class="token punctuation">]</span><span class="token punctuation">)</span> 
        </pre><p>&#x81F3;&#x4E8E;&#x9009;&#x62E9;&#x54EA;&#x79CD;&#x521D;&#x59CB;&#x5316;&#x65B9;&#x6CD5;&#x56E0;&#x4EBA;&#x800C;&#x5F02;&#xFF0C;&#x53EF;&#x4EE5;&#x6839;&#x636E;&#x4E0D;&#x540C;&#x7684;&#x6FC0;&#x6D3B;&#x51FD;&#x6570;&#x9009;&#x62E9;&#x4E0D;&#x540C;&#x65B9;&#x6CD5;&#x3002;&#x53E6;&#x5916;&#xFF0C;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x5BF9;&#x8FD9;&#x4E9B;&#x521D;&#x59CB;&#x5316;&#x65B9;&#x6CD5;&#x4E2D;&#x8BBE;&#x7F6E;&#x67D0;&#x4E9B;&#x53C2;&#x6570;&#xFF0C;&#x4F5C;&#x4E3A;&#x8D85;&#x53C2;&#x6570;&#xFF0C;&#x901A;&#x8FC7;&#x9A8C;&#x8BC1;&#x96C6;&#x8FDB;&#x884C;&#x9A8C;&#x8BC1;&#xFF0C;&#x5F97;&#x5230;&#x6700;&#x4F18;&#x53C2;&#x6570;&#xFF0C;&#x6765;&#x4F18;&#x5316;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x3002;</p>
        <p>&#x8FD9;&#x4E2A;&#x65B9;&#x6CD5;&#x786E;&#x5B9E;&#x6709;&#x6548;&#x7684;&#x5728;&#x4E00;&#x5B9A;&#x7A0B;&#x5EA6;&#x4E0A;&#x89E3;&#x51B3;&#x4E86;&#x68AF;&#x5EA6;&#x7206;&#x70B8;&#x6216;&#x6D88;&#x5931;&#x7684;&#x95EE;&#x9898;&#xFF0C;&#x56E0;&#x4E3A;&#x5B83;&#x7ED9;&#x6743;&#x91CD;&#x77E9;&#x9635;W&#x8BBE;&#x7F6E;&#x4E86;&#x5408;&#x7406;&#x503C;</p>
        <h2 class="mume-header" id="%E6%A2%AF%E5%BA%A6%E6%95%B0%E5%80%BC%E9%80%BC%E8%BF%91">&#x68AF;&#x5EA6;&#x6570;&#x503C;&#x903C;&#x8FD1;</h2>
        
        <p>&#x53CD;&#x5411;&#x4F20;&#x64AD;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x6709;&#x4E00;&#x9879;&#x91CD;&#x8981;&#x7684;&#x6D4B;&#x8BD5;&#x662F;&#x68AF;&#x5EA6;&#x68C0;&#x9A8C;&#x3002;&#x5176;&#x76EE;&#x7684;&#x662F;&#x68C0;&#x67E5;&#x9A8C;&#x8BC1;&#x53CD;&#x5411;&#x4F20;&#x64AD;&#x8FC7;&#x7A0B;&#x4E2D;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x7B97;&#x6CD5;&#x662F;&#x5426;&#x6B63;&#x786E;&#x3002;</p>
        <p>&#x5229;&#x7528;&#x5FAE;&#x5206;&#x601D;&#x60F3;&#xFF0C;&#x51FD;&#x6570;f&#x5728;&#x70B9;&#x3B8;&#x5904;&#x7684;&#x68AF;&#x5EA6;&#x53EF;&#x4EE5;&#x8868;&#x793A;&#x6210;&#xFF1A;</p>
        <p></p><div class="mathjax-exps">$$g(&#x3B8;)=\frac {f(&#x3B8;+&#x3B5;)&#x2212;f(&#x3B8;&#x2212;&#x3B5;)} {2&#x3B5;}$$</div><p></p>
        <p>&#x5176;&#x4E2D;&#xFF0C;&#x3B5;&gt;0&#xFF0C;&#x4E14;&#x8DB3;&#x591F;&#x5C0F;&#x3002;</p>
        <h2 class="mume-header" id="%E6%A2%AF%E5%BA%A6%E6%A3%80%E9%AA%8C">&#x68AF;&#x5EA6;&#x68C0;&#x9A8C;</h2>
        
        <p>&#x901A;&#x8FC7;&#x68AF;&#x5EA6;&#x68C0;&#x9A8C;&#xFF0C;&#x6211;&#x4EEC;&#x80FD;&#x591F;&#x5F88;&#x65B9;&#x4FBF;&#x7684;&#x6765;&#x53D1;&#x73B0;&#x53CD;&#x9988;&#x5B9E;&#x65BD;&#x8FC7;&#x7A0B;&#x4E2D;&#x7684;bug&#x3002;</p>
        <p>&#x68AF;&#x5EA6;&#x68C0;&#x67E5;&#x9996;&#x5148;&#x8981;&#x505A;&#x7684;&#x662F;&#x5206;&#x522B;&#x5C06;<span class="mathjax-exps">$W^{[1]},b^{[1]},&#x22EF;,W^{[L]},b^{[L]}$</span>&#x8FD9;&#x4E9B;&#x77E9;&#x9635;&#x6784;&#x6210;&#x4E00;&#x4E2A;&#x5DE8;&#x5927;&#x7684;&#x4E00;&#x7EF4;&#x5411;&#x91CF;&#xFF0C;&#x7136;&#x540E;&#x5C06;&#x8FD9;&#x4E9B;&#x4E00;&#x7EF4;&#x5411;&#x91CF;&#x7EC4;&#x5408;&#x8D77;&#x6765;&#x6784;&#x6210;&#x4E00;&#x4E2A;&#x66F4;&#x5927;&#x7684;&#x4E00;&#x7EF4;&#x5411;&#x91CF;<span class="mathjax-exps">$&#x3B8;$</span>&#x3002;&#x8FD9;&#x6837;cost &#x51FD;&#x6570;<span class="mathjax-exps">$J(W^{[1]},b^{[1]},&#x22EF;,W^{[L]},b^{[L]})$</span>&#x5C31;&#x53EF;&#x4EE5;&#x8868;&#x793A;&#x6210;<span class="mathjax-exps">$J(&#x3B8;)$</span>&#x3002;&#x5F53;&#x7136;&#x6211;&#x4EEC;&#x4E5F;&#x53EF;&#x4EE5;&#x628A;&#x8FD9;&#x4E2A;&#x8D85;&#x5927;&#x5411;&#x91CF;&#x62C6;&#x5F00;&#x4E3A;<span class="mathjax-exps">$J(&#x3B8;_1,&#x3B8;_2,&#x22EF;)$</span></p>
        <p>&#x7136;&#x540E;&#x5C06;&#x53CD;&#x5411;&#x4F20;&#x64AD;&#x8FC7;&#x7A0B;&#x901A;&#x8FC7;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x7B97;&#x6CD5;&#x5F97;&#x5230;&#x7684;<span class="mathjax-exps">$dW^{[1]},db^{[1]},&#x22EF;,dW^{[L]},db^{[L]}$</span>&#x6309;&#x7167;&#x4E00;&#x6837;&#x7684;&#x987A;&#x5E8F;&#x6784;&#x9020;&#x6210;&#x4E00;&#x4E2A;&#x4E00;&#x7EF4;&#x5411;&#x91CF;<span class="mathjax-exps">$d&#x3B8;$</span>&#x3002;<span class="mathjax-exps">$d&#x3B8;$</span>&#x7684;&#x7EF4;&#x5EA6;&#x4E0E;<span class="mathjax-exps">$&#x3B8;$</span>&#x4E00;&#x81F4;&#x3002;</p>
        <p>&#x63A5;&#x7740;&#x5229;&#x7528;<span class="mathjax-exps">$J(&#x3B8;)$</span>&#x5BF9;&#x6BCF;&#x4E2A;<span class="mathjax-exps">$&#x3B8;_i$</span>&#x8BA1;&#x7B97;&#x8FD1;&#x4F3C;&#x68AF;&#x5EA6;&#xFF0C;&#x5176;&#x503C;&#x4E0E;&#x53CD;&#x5411;&#x4F20;&#x64AD;&#x7B97;&#x6CD5;&#x5F97;&#x5230;&#x7684;<span class="mathjax-exps">$d&#x3B8;_i$</span>&#x76F8;&#x6BD4;&#x8F83;&#xFF0C;&#x68C0;&#x67E5;&#x662F;&#x5426;&#x4E00;&#x81F4;&#x3002;&#x4F8B;&#x5982;&#xFF0C;&#x5BF9;&#x4E8E;&#x7B2C;i&#x4E2A;&#x5143;&#x7D20;&#xFF0C;&#x8FD1;&#x4F3C;&#x68AF;&#x5EA6;&#x4E3A;&#xFF1A;</p>
        <p></p><div class="mathjax-exps">$$d&#x3B8;_{approx}[i]=\frac{J(&#x3B8;_1,&#x3B8;_2,&#x22EF;,&#x3B8;_{i+&#x3B5;},&#x22EF;)&#x2212;J(&#x3B8;_1,&#x3B8;_2,&#x22EF;,&#x3B8;_{i&#x2212;&#x3B5;},&#x22EF;)}{2&#x3B5;}$$</div><p></p>
        <p>&#x8BA1;&#x7B97;&#x5B8C;&#x6240;&#x6709;<span class="mathjax-exps">$&#x3B8;_i$</span>&#x7684;&#x8FD1;&#x4F3C;&#x68AF;&#x5EA6;&#x540E;&#xFF0C;&#x53EF;&#x4EE5;&#x8BA1;&#x7B97;<span class="mathjax-exps">$d&#x3B8;_{approx}$</span>&#x4E0E;<span class="mathjax-exps">$d&#x3B8;$</span>&#x7684;&#x6B27;&#x6C0F;&#xFF08;Euclidean&#xFF09;&#x8DDD;&#x79BB;&#x6765;&#x6BD4;&#x8F83;&#x4E8C;&#x8005;&#x7684;&#x76F8;&#x4F3C;&#x5EA6;&#x3002;&#x516C;&#x5F0F;&#x5982;&#x4E0B;&#xFF1A;</p>
        <p></p><div class="mathjax-exps">$$\frac{||d&#x3B8;_{approx}&#x2212;d&#x3B8;||_2}{||d&#x3B8;_{approx}||_2+||d&#x3B8;||_2}$$</div><p></p>
        <p>&#x4E00;&#x822C;&#x6765;&#x8BF4;&#xFF0C;&#x5982;&#x679C;&#x6B27;&#x6C0F;&#x8DDD;&#x79BB;&#x8D8A;&#x5C0F;&#xFF0C;&#x4F8B;&#x5982;<span class="mathjax-exps">$10^{&#x2212;7}$</span>&#xFF0C;&#x751A;&#x81F3;&#x66F4;&#x5C0F;&#xFF0C;&#x5219;&#x8868;&#x660E;<span class="mathjax-exps">$d&#x3B8;_approx$</span>&#x4E0E;<span class="mathjax-exps">$d&#x3B8;$</span>&#x8D8A;&#x63A5;&#x8FD1;&#xFF0C;&#x5373;&#x53CD;&#x5411;&#x68AF;&#x5EA6;&#x8BA1;&#x7B97;&#x662F;&#x6B63;&#x786E;&#x7684;&#xFF0C;&#x6CA1;&#x6709;bugs&#x3002;</p>
        <p>&#x5982;&#x679C;&#x6B27;&#x6C0F;&#x8DDD;&#x79BB;&#x8F83;&#x5927;&#xFF0C;&#x4F8B;&#x5982;<span class="mathjax-exps">$10^{&#x2212;5}$</span>&#xFF0C;&#x5219;&#x8868;&#x660E;&#x68AF;&#x5EA6;&#x8BA1;&#x7B97;&#x53EF;&#x80FD;&#x51FA;&#x73B0;&#x95EE;&#x9898;&#xFF0C;&#x9700;&#x8981;&#x518D;&#x6B21;&#x68C0;&#x67E5;&#x662F;&#x5426;&#x6709;bug&#x5B58;&#x5728;&#x3002;</p>
        <p>&#x5982;&#x679C;&#x6B27;&#x6C0F;&#x8DDD;&#x79BB;&#x5F88;&#x5927;&#xFF0C;&#x4F8B;&#x5982;<span class="mathjax-exps">$10^{&#x2212;3}$</span>&#xFF0C;&#x751A;&#x81F3;&#x66F4;&#x5927;&#xFF0C;&#x5219;&#x8868;&#x660E;<span class="mathjax-exps">$d&#x3B8;_approx$</span>&#x4E0E;<span class="mathjax-exps">$d&#x3B8;$</span>&#x5DEE;&#x522B;&#x5F88;&#x5927;&#xFF0C;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x8BA1;&#x7B97;&#x8FC7;&#x7A0B;&#x6709;bug&#xFF0C;&#x9700;&#x8981;&#x4ED4;&#x7EC6;&#x68C0;&#x67E5;&#x3002;</p>
        <h2 class="mume-header" id="%E5%AE%9E%E6%96%BD%E6%A2%AF%E5%BA%A6%E6%A3%80%E9%AA%8C%E7%9A%84%E5%AE%9E%E7%94%A8%E6%8A%80%E5%B7%A7%E5%92%8C%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9">&#x5B9E;&#x65BD;&#x68AF;&#x5EA6;&#x68C0;&#x9A8C;&#x7684;&#x5B9E;&#x7528;&#x6280;&#x5DE7;&#x548C;&#x6CE8;&#x610F;&#x4E8B;&#x9879;</h2>
        
        <p>&#x5728;&#x8FDB;&#x884C;&#x68AF;&#x5EA6;&#x68C0;&#x67E5;&#x7684;&#x8FC7;&#x7A0B;&#x4E2D;&#x6709;&#x51E0;&#x70B9;&#x9700;&#x8981;&#x6CE8;&#x610F;&#x7684;&#x5730;&#x65B9;&#xFF1A;</p>
        <ul>
        <li><strong>&#x4E0D;&#x8981;&#x5728;&#x6574;&#x4E2A;&#x8BAD;&#x7EC3;&#x8FC7;&#x7A0B;&#x4E2D;&#x90FD;&#x8FDB;&#x884C;&#x68AF;&#x5EA6;&#x68C0;&#x67E5;&#xFF0C;&#x4EC5;&#x4EC5;&#x4F5C;&#x4E3A;debug&#x4F7F;&#x7528;&#x3002;</strong></li>
        <li><strong>&#x5982;&#x679C;&#x68AF;&#x5EA6;&#x68C0;&#x67E5;&#x51FA;&#x73B0;&#x9519;&#x8BEF;&#xFF0C;&#x627E;&#x5230;&#x5BF9;&#x5E94;&#x51FA;&#x9519;&#x7684;&#x68AF;&#x5EA6;&#xFF0C;&#x68C0;&#x67E5;&#x5176;&#x63A8;&#x5BFC;&#x662F;&#x5426;&#x51FA;&#x73B0;&#x9519;&#x8BEF;&#x3002;</strong></li>
        <li><strong>&#x6CE8;&#x610F;&#x4E0D;&#x8981;&#x5FFD;&#x7565;&#x6B63;&#x5219;&#x5316;&#x9879;&#xFF0C;&#x8BA1;&#x7B97;&#x8FD1;&#x4F3C;&#x68AF;&#x5EA6;&#x7684;&#x65F6;&#x5019;&#x8981;&#x5305;&#x62EC;&#x8FDB;&#x53BB;&#x3002;</strong></li>
        <li><strong>&#x68AF;&#x5EA6;&#x68C0;&#x67E5;&#x65F6;&#x5173;&#x95ED;dropout&#xFF0C;&#x68C0;&#x67E5;&#x5B8C;&#x6BD5;&#x540E;&#x518D;&#x6253;&#x5F00;dropout&#x3002;</strong></li>
        <li><strong>&#x968F;&#x673A;&#x521D;&#x59CB;&#x5316;&#x65F6;&#x8FD0;&#x884C;&#x68AF;&#x5EA6;&#x68C0;&#x67E5;&#xFF0C;&#x7ECF;&#x8FC7;&#x4E00;&#x4E9B;&#x8BAD;&#x7EC3;&#x540E;&#x518D;&#x8FDB;&#x884C;&#x68AF;&#x5EA6;&#x68C0;&#x67E5;&#xFF08;&#x4E0D;&#x5E38;&#x7528;&#xFF09;&#x3002;</strong></li>
        </ul>
        <h1 class="mume-header" id="%E7%BB%83%E4%B9%A0%E6%A0%B7%E4%BE%8B">&#x7EC3;&#x4E60;&#x6837;&#x4F8B;</h1>
        
        <h2 class="mume-header" id="%E5%88%9D%E5%A7%8B%E5%8C%96">&#x521D;&#x59CB;&#x5316;</h2>
        
        <p>&#x9762;&#x5BF9;&#x4E00;&#x4E2A;&#x65B0;&#x7684;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x4F60;&#x7A76;&#x7ADF;&#x600E;&#x4E48;&#x9009;&#x62E9;&#x521D;&#x59CB;&#x5316;&#xFF1F;&#x5728;&#x8FD9;&#x91CC;&#xFF0C;&#x4F60;&#x4F1A;&#x770B;&#x5230;&#x4E0D;&#x540C;&#x7684;&#x521D;&#x59CB;&#x5316;&#x4F1A;&#x5E26;&#x6765;&#x4E0D;&#x540C;&#x7684;&#x7ED3;&#x679C;&#x3002;</p>
        <p>&#x7CBE;&#x5FC3;&#x9009;&#x62E9;&#x7684;&#x521D;&#x59CB;&#x5316;&#x53EF;&#x4EE5;&#xFF1A;</p>
        <ul>
        <li>&#x52A0;&#x5FEB;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x7684;&#x6536;&#x655B;</li>
        <li>&#x589E;&#x52A0;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x6536;&#x655B;&#x5230;&#x8F83;&#x4F4E;&#x7684;&#x8BAD;&#x7EC3;&#xFF08;&#x548C;&#x6CDB;&#x5316;&#xFF09;&#x9519;&#x8BEF;&#x7684;&#x51E0;&#x7387;</li>
        </ul>
        <pre data-role="codeBlock" data-info="python" class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
        <span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
        <span class="token keyword">import</span> sklearn
        <span class="token keyword">import</span> sklearn<span class="token punctuation">.</span>datasets
        <span class="token keyword">from</span> init_utils <span class="token keyword">import</span> sigmoid<span class="token punctuation">,</span> relu<span class="token punctuation">,</span> compute_loss<span class="token punctuation">,</span> forward_propagation<span class="token punctuation">,</span> backward_propagation
        <span class="token keyword">from</span> init_utils <span class="token keyword">import</span> update_parameters<span class="token punctuation">,</span> predict<span class="token punctuation">,</span> load_dataset<span class="token punctuation">,</span> plot_decision_boundary<span class="token punctuation">,</span> predict_dec
        
        <span class="token operator">%</span>matplotlib inline
        <span class="token comment"># &#x8BBE;&#x7F6E;&#x56FE;&#x7684;&#x9ED8;&#x8BA4;&#x5927;&#x5C0F;</span>
        plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">&apos;figure.figsize&apos;</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">7.0</span><span class="token punctuation">,</span> <span class="token number">4.0</span><span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">&apos;image.interpolation&apos;</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">&apos;nearest&apos;</span>
        plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">&apos;image.cmap&apos;</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">&apos;gray&apos;</span>
        
        <span class="token comment"># &#x52A0;&#x8F7D;&#x6570;&#x636E;&#x56FE;&#x6837;: &#x5728;&#x5708;&#x4E2D;&#x7684;&#x84DD;/&#x7EA2;&#x70B9;</span>
        train_X<span class="token punctuation">,</span> train_Y<span class="token punctuation">,</span> test_X<span class="token punctuation">,</span> test_Y <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token punctuation">)</span>
        </pre><h3 class="mume-header" id="%E6%95%B0%E6%8D%AE%E5%9B%BE%E6%A0%B7">&#x6570;&#x636E;&#x56FE;&#x6837;</h3>
        
        <p><img src="img/QQ%E6%88%AA%E5%9B%BE20200816152119.jpg" alt></p>
        <h3 class="mume-header" id="%E7%9B%AE%E6%A0%87">&#x76EE;&#x6807;</h3>
        
        <p>&#x4F60;&#x9700;&#x8981;&#x4E00;&#x4E2A;&#x5206;&#x7C7B;&#x5668;&#x53BB;&#x533A;&#x5206;&#x84DD;&#x70B9;&#x548C;&#x7EA2;&#x70B9;</p>
        <h3 class="mume-header" id="%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B">&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x6A21;&#x578B;</h3>
        
        <h4 class="mume-header" id="%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81">&#x6A21;&#x578B;&#x4EE3;&#x7801;</h4>
        
        <pre data-role="codeBlock" data-info="python" class="language-python"><span class="token keyword">def</span> <span class="token function">model</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">,</span> learning_rate <span class="token operator">=</span> <span class="token number">0.01</span><span class="token punctuation">,</span> num_iterations <span class="token operator">=</span> <span class="token number">15000</span><span class="token punctuation">,</span> print_cost <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span> initialization <span class="token operator">=</span> <span class="token string">&quot;he&quot;</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token triple-quoted-string string">&quot;&quot;&quot;
            Implements a three-layer neural network: LINEAR-&gt;RELU-&gt;LINEAR-&gt;RELU-&gt;LINEAR-&gt;SIGMOID.
            
            Arguments:
            X -- input data, of shape (2, number of examples)
            Y -- true &quot;label&quot; vector (containing 0 for red dots; 1 for blue dots), of shape (1, number of examples)
            learning_rate -- learning rate for gradient descent 
            num_iterations -- number of iterations to run gradient descent
            print_cost -- if True, print the cost every 1000 iterations
            initialization -- flag to choose which initialization to use (&quot;zeros&quot;,&quot;random&quot; or &quot;he&quot;)
            
            Returns:
            parameters -- parameters learnt by the model
            &quot;&quot;&quot;</span>
                
            grads <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
            costs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token comment"># &#x8FFD;&#x8E2A;&#x6210;&#x672C;</span>
            m <span class="token operator">=</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token comment"># &#x6837;&#x672C;&#x6570;</span>
            layers_dims <span class="token operator">=</span> <span class="token punctuation">[</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>
            
            <span class="token comment"># &#x521D;&#x59CB;&#x5316;&#x53C2;&#x6570;&#x8BCD;&#x5178;</span>
            <span class="token keyword">if</span> initialization <span class="token operator">==</span> <span class="token string">&quot;zeros&quot;</span><span class="token punctuation">:</span>
                parameters <span class="token operator">=</span> initialize_parameters_zeros<span class="token punctuation">(</span>layers_dims<span class="token punctuation">)</span>
            <span class="token keyword">elif</span> initialization <span class="token operator">==</span> <span class="token string">&quot;random&quot;</span><span class="token punctuation">:</span>
                parameters <span class="token operator">=</span> initialize_parameters_random<span class="token punctuation">(</span>layers_dims<span class="token punctuation">)</span>
            <span class="token keyword">elif</span> initialization <span class="token operator">==</span> <span class="token string">&quot;he&quot;</span><span class="token punctuation">:</span>
                parameters <span class="token operator">=</span> initialize_parameters_he<span class="token punctuation">(</span>layers_dims<span class="token punctuation">)</span>
        
            <span class="token comment"># &#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x5FAA;&#x73AF;</span>
        
            <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> num_iterations<span class="token punctuation">)</span><span class="token punctuation">:</span>
        
                <span class="token comment"># &#x524D;&#x9988;: LINEAR -&gt; RELU -&gt; LINEAR -&gt; RELU -&gt; LINEAR -&gt; SIGMOID.&#x3010;2&#x5C42;&#x3011;</span>
                a3<span class="token punctuation">,</span> cache <span class="token operator">=</span> forward_propagation<span class="token punctuation">(</span>X<span class="token punctuation">,</span> parameters<span class="token punctuation">)</span>
                
                <span class="token comment"># &#x6210;&#x672C;</span>
                cost <span class="token operator">=</span> compute_loss<span class="token punctuation">(</span>a3<span class="token punctuation">,</span> Y<span class="token punctuation">)</span>
        
                <span class="token comment"># &#x53CD;&#x9988;</span>
                grads <span class="token operator">=</span> backward_propagation<span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">,</span> cache<span class="token punctuation">)</span>
                
                <span class="token comment"># &#x66F4;&#x65B0;&#x53C2;&#x6570;</span>
                parameters <span class="token operator">=</span> update_parameters<span class="token punctuation">(</span>parameters<span class="token punctuation">,</span> grads<span class="token punctuation">,</span> learning_rate<span class="token punctuation">)</span>
                
                <span class="token comment"># &#x6BCF;1000&#x6B21;&#x6253;&#x5370;&#x6210;&#x672C;</span>
                <span class="token keyword">if</span> print_cost <span class="token keyword">and</span> i <span class="token operator">%</span> <span class="token number">1000</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;Cost after iteration {}: {}&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span> cost<span class="token punctuation">)</span><span class="token punctuation">)</span>
                    costs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>cost<span class="token punctuation">)</span>
                    
            <span class="token comment"># &#x7ED8;&#x51FA;&#x6210;&#x672C;&#x56FE;&#x50CF;</span>
            plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>costs<span class="token punctuation">)</span>
            plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">&apos;cost&apos;</span><span class="token punctuation">)</span>
            plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">&apos;iterations (per hundreds)&apos;</span><span class="token punctuation">)</span>
            plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">&quot;Learning rate =&quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>learning_rate<span class="token punctuation">)</span><span class="token punctuation">)</span>
            plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
            
            <span class="token keyword">return</span> parameters
        </pre><h3 class="mume-header" id="%E4%B8%89%E7%A7%8D%E5%88%9D%E5%A7%8B%E5%8C%96%E6%96%B9%E6%B3%95"><strong>&#x4E09;&#x79CD;&#x521D;&#x59CB;&#x5316;&#x65B9;&#x6CD5;</strong></h3>
        
        <ul>
        <li>
        <p><strong>&#x96F6;&#x521D;&#x59CB;&#x5316;</strong> &#xFF1A;<code>initialization = &quot;zeros&quot;</code></p>
        </li>
        <li>
        <p><strong>&#x968F;&#x673A;&#x521D;&#x59CB;&#x5316;</strong> &#xFF1A; <code>initialization = &quot;random&quot;</code></p>
        <p>&#x5C06;&#x6743;&#x91CD;w&#x521D;&#x59CB;&#x5316;&#x4E3A;&#x5F88;&#x5927;&#x7684;&#x968F;&#x673A;&#x503C;&#x3002;</p>
        </li>
        <li>
        <p><strong>He&#x521D;&#x59CB;&#x5316;</strong> &#xFF1A; <code>initialization = &quot;he&quot;</code></p>
        <p>&#x521D;&#x59CB;&#x5316;&#x6743;&#x91CD;w&#x4E3A;&#x5728;He&#x7B49;&#x4EBA;2015&#x5E74;&#x7684;&#x4E00;&#x7BC7;&#x8BBA;&#x6587;&#x63D0;&#x51FA;&#x7684;&#x8303;&#x56F4;&#x5185;&#x7684;&#x968F;&#x673A;&#x503C;&#x3002;</p>
        </li>
        </ul>
        <h3 class="mume-header" id="%E9%9B%B6%E5%88%9D%E5%A7%8B%E5%8C%96">&#x96F6;&#x521D;&#x59CB;&#x5316;</h3>
        
        <pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment"># GRADED FUNCTION: initialize_parameters_zeros </span>
        
        <span class="token keyword">def</span> <span class="token function">initialize_parameters_zeros</span><span class="token punctuation">(</span>layers_dims<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token triple-quoted-string string">&quot;&quot;&quot;
            Arguments:
            layer_dims -- python array (list) containing the size of each layer.
            
            Returns:
            parameters -- python dictionary containing your parameters &quot;W1&quot;, &quot;b1&quot;, ..., &quot;WL&quot;, &quot;bL&quot;:
                            W1 -- weight matrix of shape (layers_dims[1], layers_dims[0])
                            b1 -- bias vector of shape (layers_dims[1], 1)
                            ...
                            WL -- weight matrix of shape (layers_dims[L], layers_dims[L-1])
                            bL -- bias vector of shape (layers_dims[L], 1)
            &quot;&quot;&quot;</span>
            
            parameters <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
            L <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>layers_dims<span class="token punctuation">)</span>            <span class="token comment"># number of layers in the network</span>
            
            <span class="token keyword">for</span> l <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> L<span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token comment">### START CODE HERE ### (&#x2248; 2 lines of code)</span>
                parameters<span class="token punctuation">[</span><span class="token string">&apos;W&apos;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>l<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>layers_dims<span class="token punctuation">[</span>l<span class="token punctuation">]</span><span class="token punctuation">,</span> layers_dims<span class="token punctuation">[</span>l<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                parameters<span class="token punctuation">[</span><span class="token string">&apos;b&apos;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>l<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>
                <span class="token comment">### END CODE HERE ###</span>
            <span class="token keyword">return</span> parameters
        </pre><h4 class="mume-header" id="%E6%A3%80%E6%B5%8B%E6%95%88%E6%9E%9C">&#x68C0;&#x6D4B;&#x6548;&#x679C;</h4>
        
        <pre data-role="codeBlock" data-info="python" class="language-python">parameters <span class="token operator">=</span> model<span class="token punctuation">(</span>train_X<span class="token punctuation">,</span> train_Y<span class="token punctuation">,</span> initialization <span class="token operator">=</span> <span class="token string">&quot;zeros&quot;</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&quot;On the train set:&quot;</span><span class="token punctuation">)</span>
        predictions_train <span class="token operator">=</span> predict<span class="token punctuation">(</span>train_X<span class="token punctuation">,</span> train_Y<span class="token punctuation">,</span> parameters<span class="token punctuation">)</span>
        <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&quot;On the test set:&quot;</span><span class="token punctuation">)</span>
        predictions_test <span class="token operator">=</span> predict<span class="token punctuation">(</span>test_X<span class="token punctuation">,</span> test_Y<span class="token punctuation">,</span> parameters<span class="token punctuation">)</span>
        </pre><pre data-role="codeBlock" data-info class="language-"><code>Cost after iteration 0: 0.6931471805599453
        Cost after iteration 1000: 0.6931471805599453
        ....
        Cost after iteration 14000: 0.6931471805599453
        </code></pre><img src="img/QQ&#x622A;&#x56FE;20200816153828.jpg" style="zoom:60%;">
        <p>&#x6027;&#x80FD;&#x975E;&#x5E38;&#x7CDF;&#x7CD5;&#xFF0C;cost &#x5E76;&#x6CA1;&#x6709;&#x771F;&#x6B63;&#x964D;&#x4F4E;&#xFF0C;&#x7B97;&#x6CD5;&#x4E5F;&#x6CA1;&#x6709;&#x6BD4;&#x968F;&#x673A;&#x731C;&#x6D4B;&#x66F4;&#x597D;&#x3002;&#x4E3A;&#x4E86;&#x66F4;&#x597D;&#x5730;&#x7406;&#x89E3;&#x4E3A;&#x4EC0;&#x4E48;&#x4F1A;&#x8FD9;&#x6837;&#xFF0C;&#x4E0B;&#x9762;&#x68C0;&#x67E5;&#x9884;&#x6D4B;&#x548C;&#x51B3;&#x7B56;&#x8FB9;&#x754C;&#x7684;&#x7EC6;&#x8282;&#x3002;</p>
        <h4 class="mume-header" id="%E8%AF%84%E4%BB%B7">&#x8BC4;&#x4EF7;</h4>
        
        <h5 class="mume-header" id="%E6%95%88%E6%9E%9C%E5%9B%BE%E6%A0%B7">&#x6548;&#x679C;&#x56FE;&#x6837;</h5>
        
        <pre data-role="codeBlock" data-info="python" class="language-python"><span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&quot;predictions_train = &quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>predictions_train<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&quot;predictions_test = &quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>predictions_test<span class="token punctuation">)</span><span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">&quot;Model with Zeros initialization&quot;</span><span class="token punctuation">)</span>
        axes <span class="token operator">=</span> plt<span class="token punctuation">.</span>gca<span class="token punctuation">(</span><span class="token punctuation">)</span>
        axes<span class="token punctuation">.</span>set_xlim<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.5</span><span class="token punctuation">,</span><span class="token number">1.5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        axes<span class="token punctuation">.</span>set_ylim<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.5</span><span class="token punctuation">,</span><span class="token number">1.5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        plot_decision_boundary<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> predict_dec<span class="token punctuation">(</span>parameters<span class="token punctuation">,</span> x<span class="token punctuation">.</span>T<span class="token punctuation">)</span><span class="token punctuation">,</span> train_X<span class="token punctuation">,</span> train_Y<span class="token punctuation">)</span>
        </pre><pre data-role="codeBlock" data-info class="language-"><code>predictions_train = [[0 0 ... 0 0 0 0]]
        predictions_test =  [[0 0 ... 0 0 0 0]]
        </code></pre><img src="img/QQ&#x622A;&#x56FE;20200816154321.jpg" style="zoom:60%;">
        <p>&#x6A21;&#x578B;&#x5C06;&#x6BCF;&#x4E2A;&#x6837;&#x4F8B;&#x90FD;&#x9884;&#x6D4B;&#x4E3A;&#x4E86;0.</p>
        <p>&#x4E00;&#x822C;&#x6765;&#x8BF4;&#xFF0C;&#x5C06;&#x6240;&#x6709;&#x6743;&#x91CD;&#x521D;&#x59CB;&#x5316;&#x4E3A;&#x96F6;&#x5C06;&#x5BFC;&#x81F4;&#x7F51;&#x7EDC;&#x65E0;&#x6CD5;&#x7834;&#x574F;&#x5BF9;&#x79F0;&#x6027;&#x3002;&#x8FD9;&#x610F;&#x5473;&#x7740;&#x6BCF;&#x4E00;&#x5C42;&#x7684;&#x6BCF;&#x4E2A;&#x795E;&#x7ECF;&#x5143;&#x90FD;&#x4F1A;&#x5B66;&#x5230;&#x76F8;&#x540C;&#x7684;&#x4E1C;&#x897F;&#xFF0C;&#x800C;&#x4E14;&#x4F60;&#x4E5F;&#x53EF;&#x80FD;&#x7528; <span class="mathjax-exps">$n^{[l]}=1$</span>&#x5728;&#x6BCF;&#x5C42;&#x7F51;&#x7EDC;&#x8BAD;&#x7EC3;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#xFF0C;&#x7F51;&#x7EDC;&#x5E76;&#x4E0D;&#x6BD4;&#x7EBF;&#x6027;&#x5206;&#x7C7B;&#x5668;&#x5982;&#x903B;&#x8F91;&#x56DE;&#x5F52;&#x66F4;&#x5F3A;&#x5927;.</p>
        <h3 class="mume-header" id="%E6%B3%A8%E6%84%8F-1">&#x6CE8;&#x610F;&#xFF1A;</h3>
        
        <ul>
        <li>&#x5E94;&#x8BE5;&#x968F;&#x673A;&#x521D;&#x59CB;&#x5316;&#x6743;&#x91CD; <span class="mathjax-exps">$W^{[l]}$</span> &#x53BB;&#x7834;&#x574F;&#x7F51;&#x7EDC;&#x7684;&#x5BF9;&#x79F0;&#x6027;&#x3002;</li>
        <li>&#x4F46;&#x662F;&#x504F;&#x7F6E; <span class="mathjax-exps">$b^{[l]}$</span> &#x4ECD;&#x7136;&#x53EF;&#x4EE5;&#x521D;&#x59CB;&#x5316;&#x4E3A;0&#x3002;&#x56E0;&#x4E3A;&#x53EA;&#x8981;&#x6743;&#x91CD; <span class="mathjax-exps">$W^{[l]}$</span> &#x88AB;&#x968F;&#x673A;&#x521D;&#x59CB;&#x5316;&#xFF0C;&#x5BF9;&#x79F0;&#x6027;&#x5C31;&#x5DF2;&#x7ECF;&#x88AB;&#x6253;&#x7834;&#x4E86;&#x3002;</li>
        </ul>
        <h3 class="mume-header" id="%E9%9A%8F%E6%9C%BA%E5%88%9D%E5%A7%8B%E5%8C%96">&#x968F;&#x673A;&#x521D;&#x59CB;&#x5316;</h3>
        
        <p>&#x4E3A;&#x4E86;&#x6253;&#x7834;&#x5BF9;&#x79F0;&#xFF0C;&#x9700;&#x8981;&#x968F;&#x673A;&#x521D;&#x59CB;&#x5316;&#x6743;&#x91CD;&#x3002;&#x968F;&#x673A;&#x521D;&#x59CB;&#x5316;&#x540E;&#xFF0C;&#x6BCF;&#x4E2A;&#x795E;&#x7ECF;&#x5143;&#x53EF;&#x4EE5;&#x7EE7;&#x7EED;&#x5B66;&#x4E60;&#x5176;&#x8F93;&#x5165;&#x7684;&#x4E0D;&#x540C;&#x529F;&#x80FD;&#x3002;&#x5728;&#x8FD9;&#x4E2A;&#x7EC3;&#x4E60;&#x4E2D;&#xFF0C;&#x4F60;&#x4F1A;&#x770B;&#x5230;&#x5982;&#x679C;&#x6743;&#x91CD;&#x88AB;&#x521D;&#x59CB;&#x5316;&#x4E3A;&#x5F88;&#x5927;&#x7684;&#x503C;&#x5C06;&#x4F1A;&#x53D1;&#x751F;&#x4EC0;&#x4E48;&#x3002;</p>
        <pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment"># GRADED FUNCTION: initialize_parameters_random</span>
        
        <span class="token keyword">def</span> <span class="token function">initialize_parameters_random</span><span class="token punctuation">(</span>layers_dims<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token triple-quoted-string string">&quot;&quot;&quot;
            Arguments:
            layer_dims -- python array (list) containing the size of each layer.
            
            Returns:
            parameters -- python dictionary containing your parameters &quot;W1&quot;, &quot;b1&quot;, ..., &quot;WL&quot;, &quot;bL&quot;:
                            W1 -- weight matrix of shape (layers_dims[1], layers_dims[0])
                            b1 -- bias vector of shape (layers_dims[1], 1)
                            ...
                            WL -- weight matrix of shape (layers_dims[L], layers_dims[L-1])
                            bL -- bias vector of shape (layers_dims[L], 1)
            &quot;&quot;&quot;</span>
            
            np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>               <span class="token comment"># &#x786E;&#x5B9A;&#x968F;&#x673A;&#x79CD;&#x5B50;</span>
            parameters <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
            L <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>layers_dims<span class="token punctuation">)</span>            <span class="token comment"># &#x5C42;&#x6570;</span>
            
            <span class="token keyword">for</span> l <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> L<span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token comment">### START CODE HERE ### (&#x2248; 2 lines of code)</span>
                parameters<span class="token punctuation">[</span><span class="token string">&apos;W&apos;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>l<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>layers_dims<span class="token punctuation">[</span>l<span class="token punctuation">]</span><span class="token punctuation">,</span> layers_dims<span class="token punctuation">[</span>l<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">10</span>
                parameters<span class="token punctuation">[</span><span class="token string">&apos;b&apos;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>l<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>layers_dims<span class="token punctuation">[</span>l<span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token comment">### END CODE HERE ###</span>
        
            <span class="token keyword">return</span> parameters
        </pre><h4 class="mume-header" id="%E6%A3%80%E6%B5%8B%E6%95%88%E6%9E%9C-1">&#x68C0;&#x6D4B;&#x6548;&#x679C;</h4>
        
        <pre data-role="codeBlock" data-info="python" class="language-python">parameters <span class="token operator">=</span> model<span class="token punctuation">(</span>train_X<span class="token punctuation">,</span> train_Y<span class="token punctuation">,</span> initialization <span class="token operator">=</span> <span class="token string">&quot;random&quot;</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&quot;On the train set:&quot;</span><span class="token punctuation">)</span>
        predictions_train <span class="token operator">=</span> predict<span class="token punctuation">(</span>train_X<span class="token punctuation">,</span> train_Y<span class="token punctuation">,</span> parameters<span class="token punctuation">)</span>
        <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&quot;On the test set:&quot;</span><span class="token punctuation">)</span>
        predictions_test <span class="token operator">=</span> predict<span class="token punctuation">(</span>test_X<span class="token punctuation">,</span> test_Y<span class="token punctuation">,</span> parameters<span class="token punctuation">)</span>
        </pre><h5 class="mume-header" id="%E7%BB%93%E6%9E%9C">&#x7ED3;&#x679C;</h5>
        
        <pre data-role="codeBlock" data-info class="language-"><code>Cost after iteration 0: inf
        Cost after iteration 1000: 0.6239567039908781
        Cost after iteration 2000: 0.5978043872838292
        Cost after iteration 3000: 0.563595830364618
        Cost after iteration 4000: 0.5500816882570866
        Cost after iteration 5000: 0.5443417928662615
        Cost after iteration 6000: 0.5373553777823036
        Cost after iteration 7000: 0.4700141958024487
        Cost after iteration 8000: 0.3976617665785177
        Cost after iteration 9000: 0.39344405717719166
        Cost after iteration 10000: 0.39201765232720626
        Cost after iteration 11000: 0.38910685278803786
        Cost after iteration 12000: 0.38612995897697244
        Cost after iteration 13000: 0.3849735792031832
        Cost after iteration 14000: 0.38275100578285265
        </code></pre><img src="img/QQ&#x622A;&#x56FE;20200816155146.jpg" style="zoom:60%;">
        <p>&#x5F53;&#x7136;&#xFF0C;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x770B;&#x89C1;&#x4E00;&#x5F00;&#x59CB;&#x62A5;&#x7684;cost&#x6210;&#x672C;&#x6570;&#x636E;&#x662F;inf&#xFF0C;&#x8FD9;&#x662F;&#x56E0;&#x4E3A;&#x6570;&#x503C;&#x820D;&#x5165;&#xFF09;; &#x4E00;&#x4E2A;&#x66F4;&#x590D;&#x6742;&#x7684;&#x5B9E;&#x73B0;&#x53EF;&#x4EE5;&#x89E3;&#x51B3;&#x8FD9;&#x4E2A;&#x95EE;&#x9898;&#xFF0C;&#x4F46;&#x8FD9;&#x548C;&#x6211;&#x4EEC;&#x7684;&#x76EE;&#x7684;&#x76F8;&#x5173;&#x4E0D;&#x5927;&#x6240;&#x4EE5;&#x65E0;&#x9700;&#x7406;&#x4F1A;&#x3002;</p>
        <p>&#x4E0D;&#x7BA1;&#x600E;&#x6837;&#xFF0C;&#x6A21;&#x578B;&#x770B;&#x8D77;&#x6765;&#x5DF2;&#x7ECF;<strong>&#x5931;&#x53BB;&#x4E86;&#x5BF9;&#x79F0;&#x6027;</strong>&#xFF0C;&#x5B83;&#x7ED9;&#x51FA;&#x4E86;&#x66F4;&#x597D;&#x7684;&#x7ED3;&#x679C;&#x3002;&#x76F8;&#x6BD4;&#x4EE5;&#x524D;&#xFF0C;&#x5B83;&#x4E0D;&#x4F1A;&#x8F93;&#x51FA;&#x5168;0&#x3002;</p>
        <h4 class="mume-header" id="%E8%AF%84%E4%BB%B7-1">&#x8BC4;&#x4EF7;</h4>
        
        <pre data-role="codeBlock" data-info="python" class="language-python"><span class="token keyword">print</span> <span class="token punctuation">(</span>predictions_train<span class="token punctuation">)</span>
        <span class="token keyword">print</span> <span class="token punctuation">(</span>predictions_test<span class="token punctuation">)</span>
        </pre><pre data-role="codeBlock" data-info class="language-"><code>[[1 0 1 1 0 0 1 1 1 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1 1 1 0 1 1 0 0 1
          1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1 1 0 1 0 1 1 1 1 0
          0 0 0 0 1 0 1 0 1 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1 0 1 1 0 1 0 1 1 0 1 1 0
          1 0 1 1 0 0 1 0 0 1 1 0 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0
          0 0 1 0 1 0 1 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1
          1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 0 1 1 1 0 1 0 1 0 0 1
          0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 1 1 0 1 1
          1 1 0 1 1 0 1 1 1 0 0 1 0 0 0 1 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 1 1 1
          1 1 1 1 0 0 0 1 1 1 1 0]]
        [[1 1 1 1 0 1 0 1 1 0 1 1 1 0 0 0 0 1 0 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 1
          0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 0
          1 1 1 1 1 0 1 0 0 1 0 0 0 1 1 0 1 1 0 0 0 1 1 0 1 1 0 0]]
        </code></pre><h5 class="mume-header" id="%E6%95%88%E6%9E%9C%E5%9B%BE%E6%A0%B7-1">&#x6548;&#x679C;&#x56FE;&#x6837;</h5>
        
        <pre data-role="codeBlock" data-info="python" class="language-python">plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">&quot;Model with large random initialization&quot;</span><span class="token punctuation">)</span>
        axes <span class="token operator">=</span> plt<span class="token punctuation">.</span>gca<span class="token punctuation">(</span><span class="token punctuation">)</span>
        axes<span class="token punctuation">.</span>set_xlim<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.5</span><span class="token punctuation">,</span><span class="token number">1.5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        axes<span class="token punctuation">.</span>set_ylim<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.5</span><span class="token punctuation">,</span><span class="token number">1.5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        plot_decision_boundary<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> predict_dec<span class="token punctuation">(</span>parameters<span class="token punctuation">,</span> x<span class="token punctuation">.</span>T<span class="token punctuation">)</span><span class="token punctuation">,</span> train_X<span class="token punctuation">,</span> train_Y<span class="token punctuation">)</span>
        </pre><p><img src="img/QQ%E6%88%AA%E5%9B%BE20200816160100.jpg" alt></p>
        <h5 class="mume-header" id="%E7%89%B9%E7%82%B9">&#x7279;&#x70B9;</h5>
        
        <ul>
        <li>&#x56E0;&#x4E3A;&#x91C7;&#x7528;&#x4E86;&#x5927;&#x578B;&#x7684;<strong>&#x968F;&#x673A;&#x6743;&#x91CD;</strong>&#xFF0C;&#x6210;&#x672C;&#x4E00;&#x5F00;&#x59CB;&#x4F1A;&#x7279;&#x522B;&#x5927;&#x3002;
        <ul>
        <li>&#x6700;&#x540E;&#x4E00;&#x4E2A;&#x6FC0;&#x6D3B;&#x51FD;&#x6570;sigmoid&#x51FD;&#x6570;&#x5BFC;&#x81F4;&#x4E86;&#x7ED3;&#x679C;&#x5728;(0,1)&#x533A;&#x95F4;&#xFF0C;&#x5F53;&#x8FD9;&#x4E2A;&#x4F8B;&#x5B50;&#x51FA;&#x9519;&#x65F6;&#xFF0C;&#x5B83;&#x4F1A;&#x9020;&#x6210;&#x5F88;&#x5927;&#x7684;&#x6210;&#x672C;&#x3002;</li>
        <li>&#x5F53;<span class="mathjax-exps">$\log(a^{[3]}) = \log(0)$</span>&#xFF0C;&#x6210;&#x672C;&#x5C31;&#x4F1A;&#x8FBE;&#x5230;Inf.</li>
        </ul>
        </li>
        <li>&#x8F83;&#x5DEE;&#x7684;&#x521D;&#x59CB;&#x5316;&#x4F1A;&#x5BFC;&#x81F4; &#x68AF;&#x5EA6;&#x7206;&#x70B8;/&#x6D88;&#x5931;, &#x8FD9;&#x4E5F;&#x4F1A;&#x51CF;&#x6162;&#x4F18;&#x5316;&#x7B97;&#x6CD5;&#x7684;&#x901F;&#x5EA6;.</li>
        <li>&#x5982;&#x679C;&#x4F60;&#x82B1;&#x66F4;&#x957F;&#x65F6;&#x95F4;&#x53BB;&#x8BAD;&#x7EC3;&#x8FD9;&#x4E2A;&#x7F51;&#x7EDC;&#xFF0C;&#x4F60;&#x4F1A;&#x770B;&#x5230;&#x66F4;&#x597D;&#x7684;&#x7ED3;&#x679C;&#xFF0C;&#x4F46;&#x662F;&#x7528;&#x8FC7;&#x5927;&#x7684;&#x968F;&#x673A;&#x6570;&#x521D;&#x59CB;&#x5316;&#x4F1A;&#x51CF;&#x6162;&#x4F18;&#x5316;&#x901F;&#x5EA6;</li>
        </ul>
        <h5 class="mume-header" id="%E6%80%BB%E7%BB%93">&#x603B;&#x7ED3;:</h5>
        
        <ul>
        <li>&#x5C06;&#x6743;&#x91CD;&#x521D;&#x59CB;&#x5316;&#x4E3A;&#x975E;&#x5E38;&#x5927;&#x7684;&#x968F;&#x673A;&#x503C;&#x6548;&#x679C;&#x4E0D;&#x4F73;.</li>
        <li>&#x7528;&#x8F83;&#x5C0F;&#x7684;&#x968F;&#x673A;&#x503C;&#x521D;&#x59CB;&#x5316;&#x6548;&#x679C;&#x53EF;&#x80FD;&#x4F1A;&#x66F4;&#x597D;&#x3002;&#x4F46;&#x95EE;&#x9898;&#x662F;&#x968F;&#x673A;&#x503C;&#x5E94;&#x8BE5;&#x5C0F;&#x5230;&#x4EC0;&#x4E48;&#x7A0B;&#x5EA6;&#xFF1F;</li>
        </ul>
        <h3 class="mume-header" id="he%E5%88%9D%E5%A7%8B%E5%8C%96">He&#x521D;&#x59CB;&#x5316;</h3>
        
        <p>&#x6700;&#x540E;&#xFF0C;&#x6211;&#x4EEC;&#x6765;&#x5C1D;&#x8BD5; <strong>He&#x521D;&#x59CB;&#x5316;</strong> &#xFF01;&#x8FD9;&#x4E2A;&#x540D;&#x5B57;&#x6E90;&#x4E8E;&#x4F5C;&#x8005;He&#x7B49;&#x4EBA;&#x3002;&#x4E0E;Xavier&#x521D;&#x59CB;&#x5316;&#x7C7B;&#x4F3C;&#x3002;&#x6784;&#x9020;&#x516C;&#x5F0F;&#x5982;&#x4E0B;&#xFF1A;</p>
        <p></p><div class="mathjax-exps">$$random(layers_{dims}[l], layers_{dims}[l-1]) * \sqrt{\frac {2}{layers_{dims}[l-1]}}$$</div><p></p>
        <pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment"># GRADED FUNCTION: initialize_parameters_he</span>
        
        <span class="token keyword">def</span> <span class="token function">initialize_parameters_he</span><span class="token punctuation">(</span>layers_dims<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token triple-quoted-string string">&quot;&quot;&quot;
            Arguments:
            layer_dims -- python array (list) containing the size of each layer.
            
            Returns:
            parameters -- python dictionary containing your parameters &quot;W1&quot;, &quot;b1&quot;, ..., &quot;WL&quot;, &quot;bL&quot;:
                            W1 -- weight matrix of shape (layers_dims[1], layers_dims[0])
                            b1 -- bias vector of shape (layers_dims[1], 1)
                            ...
                            WL -- weight matrix of shape (layers_dims[L], layers_dims[L-1])
                            bL -- bias vector of shape (layers_dims[L], 1)
            &quot;&quot;&quot;</span>
            
            np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>
            parameters <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
            L <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>layers_dims<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span> <span class="token comment"># integer representing the number of layers</span>
             
            <span class="token keyword">for</span> l <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> L <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token comment">### START CODE HERE ### (&#x2248; 2 lines of code)</span>
                parameters<span class="token punctuation">[</span><span class="token string">&apos;W&apos;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>l<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>layers_dims<span class="token punctuation">[</span>l<span class="token punctuation">]</span><span class="token punctuation">,</span> layers_dims<span class="token punctuation">[</span>l<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span><span class="token number">2</span><span class="token operator">/</span>layers_dims<span class="token punctuation">[</span>l<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
                parameters<span class="token punctuation">[</span><span class="token string">&apos;b&apos;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>l<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>layers_dims<span class="token punctuation">[</span>l<span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token comment">### END CODE HERE ###</span>
                
            <span class="token keyword">return</span> parameters
        </pre><h4 class="mume-header" id="%E6%A3%80%E6%B5%8B%E6%95%88%E6%9E%9C-2">&#x68C0;&#x6D4B;&#x6548;&#x679C;</h4>
        
        <pre data-role="codeBlock" data-info="python" class="language-python">parameters <span class="token operator">=</span> model<span class="token punctuation">(</span>train_X<span class="token punctuation">,</span> train_Y<span class="token punctuation">,</span> initialization <span class="token operator">=</span> <span class="token string">&quot;he&quot;</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&quot;On the train set:&quot;</span><span class="token punctuation">)</span>
        predictions_train <span class="token operator">=</span> predict<span class="token punctuation">(</span>train_X<span class="token punctuation">,</span> train_Y<span class="token punctuation">,</span> parameters<span class="token punctuation">)</span>
        <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&quot;On the test set:&quot;</span><span class="token punctuation">)</span>
        predictions_test <span class="token operator">=</span> predict<span class="token punctuation">(</span>test_X<span class="token punctuation">,</span> test_Y<span class="token punctuation">,</span> parameters<span class="token punctuation">)</span>
        </pre><pre data-role="codeBlock" data-info class="language-"><code>Cost after iteration 0: 0.8830537463419761
        Cost after iteration 1000: 0.6879825919728063
        Cost after iteration 2000: 0.6751286264523371
        Cost after iteration 3000: 0.6526117768893807
        Cost after iteration 4000: 0.6082958970572937
        Cost after iteration 5000: 0.5304944491717495
        Cost after iteration 6000: 0.4138645817071793
        Cost after iteration 7000: 0.3117803464844441
        Cost after iteration 8000: 0.23696215330322556
        Cost after iteration 9000: 0.18597287209206828
        Cost after iteration 10000: 0.15015556280371808
        Cost after iteration 11000: 0.12325079292273548
        Cost after iteration 12000: 0.09917746546525937
        Cost after iteration 13000: 0.08457055954024274
        Cost after iteration 14000: 0.07357895962677366
        </code></pre><p><img src="img/QQ%E6%88%AA%E5%9B%BE20200816161414.jpg" alt></p>
        <h4 class="mume-header" id="%E8%AF%84%E4%BB%B7-2">&#x8BC4;&#x4EF7;</h4>
        
        <h5 class="mume-header" id="%E6%95%88%E6%9E%9C%E5%9B%BE%E6%A0%B7-2">&#x6548;&#x679C;&#x56FE;&#x6837;</h5>
        
        <pre data-role="codeBlock" data-info="python" class="language-python">plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">&quot;Model with He initialization&quot;</span><span class="token punctuation">)</span>
        axes <span class="token operator">=</span> plt<span class="token punctuation">.</span>gca<span class="token punctuation">(</span><span class="token punctuation">)</span>
        axes<span class="token punctuation">.</span>set_xlim<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.5</span><span class="token punctuation">,</span><span class="token number">1.5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        axes<span class="token punctuation">.</span>set_ylim<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.5</span><span class="token punctuation">,</span><span class="token number">1.5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        plot_decision_boundary<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> predict_dec<span class="token punctuation">(</span>parameters<span class="token punctuation">,</span> x<span class="token punctuation">.</span>T<span class="token punctuation">)</span><span class="token punctuation">,</span> train_X<span class="token punctuation">,</span> train_Y<span class="token punctuation">)</span>
        </pre><p><img src="img/QQ%E6%88%AA%E5%9B%BE20200816161543.jpg" alt></p>
        <table>
        <thead>
        <tr>
        <th>&#x6A21;&#x578B;&#xFF08;3&#x5C42;NN&#x6761;&#x4EF6;&#x4E0B;&#xFF09;</th>
        <th>&#x51C6;&#x786E;&#x7387;</th>
        <th>&#x95EE;&#x9898;/&#x8BC4;&#x4EF7;</th>
        </tr>
        </thead>
        <tbody>
        <tr>
        <td>&#x96F6;&#x521D;&#x59CB;&#x5316;</td>
        <td>50%</td>
        <td>&#x4E0D;&#x80FD;&#x7834;&#x574F;&#x5BF9;&#x79F0;&#x6027;</td>
        </tr>
        <tr>
        <td>&#x968F;&#x673A;&#x521D;&#x59CB;&#x5316;</td>
        <td>83%</td>
        <td>&#x6743;&#x91CD;&#x8FC7;&#x5927;</td>
        </tr>
        <tr>
        <td>He&#x521D;&#x59CB;&#x5316;</td>
        <td>99%</td>
        <td>&#x9700;&#x8981;&#x638C;&#x63E1;&#x65B9;&#x6CD5;</td>
        </tr>
        </tbody>
        </table>
        <h3 class="mume-header" id="%E6%80%BB%E7%BB%93-1">&#x603B;&#x7ED3;</h3>
        
        <p>&#x5728;&#x521D;&#x59CB;&#x5316;&#x9636;&#x6BB5;&#xFF0C;&#x6211;&#x4EEC;&#x4E86;&#x89E3;&#x4E86;&#xFF1A;</p>
        <ul>
        <li>&#x4E0D;&#x540C;&#x7684;&#x521D;&#x59CB;&#x5316;&#x5BFC;&#x81F4;&#x4E0D;&#x540C;&#x7684;&#x7ED3;&#x679C;</li>
        <li>&#x968F;&#x673A;&#x521D;&#x59CB;&#x5316;&#x7528;&#x4E8E;&#x7834;&#x574F;&#x5BF9;&#x79F0;&#x6027;&#xFF0C;&#x5E76;&#x786E;&#x4FDD;&#x4E0D;&#x540C;&#x7684;&#x9690;&#x85CF;&#x5355;&#x5143;&#x53EF;&#x4EE5;&#x5B66;&#x4E60;&#x4E0D;&#x540C;&#x7684;&#x4E1C;&#x897F;</li>
        <li>&#x4E0D;&#x8981;&#x521D;&#x59CB;&#x5316;&#x592A;&#x5927;&#x7684;&#x503C;</li>
        <li>&quot;He initialization&quot;&#x9002;&#x7528;&#x4E8E;ReLU&#x6FC0;&#x6D3B;&#x7684;&#x7F51;&#x7EDC;</li>
        </ul>
        <h2 class="mume-header" id="%E6%AD%A3%E5%88%99%E5%8C%96-1">&#x6B63;&#x5219;&#x5316;</h2>
        
        <p>&#x6B22;&#x8FCE;&#x6765;&#x5230;&#x672C;&#x5468;&#x7684;&#x7B2C;&#x4E8C;&#x4E2A;&#x4EFB;&#x52A1;&#x3002;&#x6DF1;&#x5EA6;&#x5B66;&#x4E60;&#x6A21;&#x578B;&#x5177;&#x6709;&#x5982;&#x6B64;&#x5927;&#x7684;&#x7075;&#x6D3B;&#x6027;&#x548C;&#x80FD;&#x529B;&#xFF0C;&#x4EE5;&#x81F3;&#x4E8E;&#x5F53;&#x8BAD;&#x7EC3;&#x6570;&#x636E;&#x96C6;&#x4E0D;&#x591F;&#x5927;&#x7684;&#x65F6;&#x5019;&#xFF0C;&#x80FD;&#x5BFC;&#x81F4;&#x4E25;&#x91CD;&#x7684;&#x95EE;&#x9898;&#xFF1A;&#x8FC7;&#x62DF;&#x5408;&#x3002;&#x5B83;&#x80FD;&#x786E;&#x4FDD;&#x5728;&#x8BAD;&#x7EC3;&#x96C6;&#x4E0A;&#x8868;&#x73B0;&#x826F;&#x597D;&#xFF0C;&#x4F46;&#x662F;&#x8BAD;&#x7EC3;&#x51FA;&#x7684;&#x7F51;&#x7EDC;&#x5E76;&#x4E0D;&#x80FD;&#x63A8;&#x5E7F;&#x5230;&#x5B83;&#x4ECE;&#x672A;&#x89C1;&#x8FC7;&#x7684;&#x65B0;&#x6837;&#x672C;&#x4E0A;&#xFF01;</p>
        <p>&#x60A8;&#x5C06;&#x5B66;&#x4E60;&#xFF1A;&#x5728;&#x6DF1;&#x5EA6;&#x5B66;&#x4E60;&#x6A21;&#x5F0F;&#x4E2D;&#x4F7F;&#x7528;&#x6B63;&#x5219;&#x5316;&#x3002;</p>
        <p>&#x6211;&#x4EEC;&#x5148;&#x5BFC;&#x5165;&#x4F60;&#x8981;&#x4F7F;&#x7528;&#x7684;&#x8F6F;&#x4EF6;&#x5305;&#x3002;</p>
        <h3 class="mume-header" id="%E5%AF%BC%E5%8C%85">&#x5BFC;&#x5305;</h3>
        
        <pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment"># import packages</span>
        <span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
        <span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
        <span class="token keyword">from</span> reg_utils <span class="token keyword">import</span> sigmoid<span class="token punctuation">,</span> relu<span class="token punctuation">,</span> plot_decision_boundary<span class="token punctuation">,</span> initialize_parameters<span class="token punctuation">,</span> load_2D_dataset<span class="token punctuation">,</span> predict_dec
        <span class="token keyword">from</span> reg_utils <span class="token keyword">import</span> compute_cost<span class="token punctuation">,</span> predict<span class="token punctuation">,</span> forward_propagation<span class="token punctuation">,</span> backward_propagation<span class="token punctuation">,</span> update_parameters
        <span class="token keyword">import</span> sklearn
        <span class="token keyword">import</span> sklearn<span class="token punctuation">.</span>datasets
        <span class="token keyword">import</span> scipy<span class="token punctuation">.</span>io
        <span class="token keyword">from</span> testCases <span class="token keyword">import</span> <span class="token operator">*</span>
        
        <span class="token keyword">import</span> warnings
        warnings<span class="token punctuation">.</span>filterwarnings<span class="token punctuation">(</span><span class="token string">&quot;ignore&quot;</span><span class="token punctuation">)</span>
        
        <span class="token operator">%</span>matplotlib inline
        plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">&apos;figure.figsize&apos;</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">7.0</span><span class="token punctuation">,</span> <span class="token number">4.0</span><span class="token punctuation">)</span> <span class="token comment"># set default size of plots</span>
        plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">&apos;image.interpolation&apos;</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">&apos;nearest&apos;</span>
        plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">&apos;image.cmap&apos;</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">&apos;gray&apos;</span>
        </pre><h3 class="mume-header" id="%E7%9B%AE%E6%A0%87-1">&#x76EE;&#x6807;</h3>
        
        <p>&#x60A8;&#x521A;&#x521A;&#x88AB;&#x6CD5;&#x56FD;&#x8DB3;&#x7403;&#x516C;&#x53F8;&#x8058;&#x4E3A;AI&#x4E13;&#x5BB6;&#x3002;&#x4ED6;&#x4EEC;&#x5E0C;&#x671B;&#x4F60;&#x63A8;&#x8350;&#x6CD5;&#x56FD;&#x5B88;&#x95E8;&#x5458;&#x5E94;&#x8BE5;&#x8E22;&#x7403;&#x7684;&#x4F4D;&#x7F6E;&#xFF0C;&#x8FD9;&#x6837;&#x6CD5;&#x56FD;&#x961F;&#x7684;&#x7403;&#x5458;&#x53EF;&#x4EE5;&#x66F4;&#x52A0;&#x5BB9;&#x6613;&#x4F7F;&#x7528;&#x5934;&#x7403;&#x3002;</p>
        <p>&#x4ED6;&#x4EEC;&#x4E3A;&#x60A8;&#x63D0;&#x4F9B;&#x6CD5;&#x56FD;&#x8FC7;&#x53BB;10&#x573A;&#x6BD4;&#x8D5B;&#x4E2D;&#x7684;&#x4EE5;&#x4E0B;&#x4E8C;&#x7EF4;&#x6570;&#x636E;&#x96C6;&#x3002;</p>
        <pre data-role="codeBlock" data-info="python" class="language-python">train_X<span class="token punctuation">,</span> train_Y<span class="token punctuation">,</span> test_X<span class="token punctuation">,</span> test_Y <span class="token operator">=</span> load_2D_dataset<span class="token punctuation">(</span><span class="token punctuation">)</span>
        </pre><img src="img/QQ&#x622A;&#x56FE;20200816163757.jpg" style="zoom:60%;">
        <p>&#x6BCF;&#x4E2A;&#x70B9;&#x5BF9;&#x5E94;&#x4E8E;&#x6CD5;&#x56FD;&#x5B88;&#x95E8;&#x5458;&#x5728;&#x8DB3;&#x7403;&#x573A;&#x5DE6;&#x4FA7;&#x51FB;&#x7403;&#x4E4B;&#x540E;&#xFF0C;&#x5176;&#x4ED6;&#x8FD0;&#x52A8;&#x5458;&#x7528;&#x5934;&#x5C06;&#x7403;&#x51FB;&#x4E2D;&#x7684;&#x8DB3;&#x7403;&#x573A;&#x4E0A;&#x7684;&#x4F4D;&#x7F6E;&#x3002;</p>
        <ul>
        <li>&#x5982;&#x679C;&#x8FD9;&#x4E2A;&#x70B9;&#x662F;&#x84DD;&#x8272;&#x7684;&#xFF0C;&#x8FD9;&#x610F;&#x5473;&#x7740;&#x8FD9;&#x4E2A;&#x6CD5;&#x56FD;&#x7403;&#x5458;&#x8BBE;&#x6CD5;&#x7528;&#x4ED6;/&#x5979;&#x7684;&#x5934;&#x51FB;&#x7403;</li>
        <li>&#x5982;&#x679C;&#x8FD9;&#x4E2A;&#x70B9;&#x662F;&#x7EA2;&#x8272;&#x7684;&#xFF0C;&#x8FD9;&#x610F;&#x5473;&#x7740;&#x53E6;&#x4E00;&#x4E2A;&#x961F;&#x7684;&#x7403;&#x5458;&#x7528;&#x5934;&#x649E;&#x7403;</li>
        </ul>
        <p><strong>&#x4F60;&#x7684;&#x76EE;&#x6807;</strong>&#xFF1A;&#x4F7F;&#x7528;&#x6DF1;&#x5EA6;&#x5B66;&#x4E60;&#x6A21;&#x5F0F;&#x6765;&#x627E;&#x5230;&#x5B88;&#x95E8;&#x5458;&#x8E22;&#x7403;&#x7684;&#x573A;&#x5730;&#x3002;</p>
        <p><strong>&#x5206;&#x6790;&#x6570;&#x636E;&#x96C6;</strong>: &#x8FD9;&#x4E2A;&#x6570;&#x636E;&#x96C6;&#x6709;&#x70B9;&#x5608;&#x6742;&#xFF0C;&#x4F46;&#x8C8C;&#x4F3C;&#x7528;&#x4E00;&#x6761;&#x5BF9;&#x89D2;&#x7EBF;&#x80FD;&#x533A;&#x5206;&#x5F00;&#x5DE6;&#x4E0A;&#x89D2;&#xFF08;&#x84DD;&#x8272;&#xFF09;&#x4E0E;&#x53F3;&#x4E0B;&#x89D2;&#xFF08;&#x7EA2;&#x8272;&#xFF09;&#x7684;&#x6570;&#x636E;&#xFF0C;&#x6548;&#x679C;&#x8FD8;&#x4E0D;&#x9519;&#x3002;</p>
        <p>&#x4F60;&#x5C06;&#x9996;&#x5148;&#x5C1D;&#x8BD5;&#x4E00;&#x4E2A;&#x975E;&#x6B63;&#x5219;&#x5316;&#x7684;&#x6A21;&#x578B;&#x3002;&#x7136;&#x540E;&#xFF0C;&#x60A8;&#x5C06;&#x5B66;&#x4E60;&#x5982;&#x4F55;&#x6B63;&#x89C4;&#x5316;&#xFF0C;&#x5E76;&#x51B3;&#x5B9A;&#x9009;&#x62E9;&#x54EA;&#x79CD;&#x6A21;&#x5F0F;&#x6765;&#x89E3;&#x51B3;&#x6CD5;&#x56FD;&#x8DB3;&#x7403;&#x516C;&#x53F8;&#x7684;&#x95EE;&#x9898;&#x3002;</p>
        <h3 class="mume-header" id="%E9%9D%9E%E6%AD%A3%E5%88%99%E5%8C%96%E6%A8%A1%E5%9E%8B">&#x975E;&#x6B63;&#x5219;&#x5316;&#x6A21;&#x578B;</h3>
        
        <p>&quot;<code>lambda</code>&quot; &#x662F;python&#x7684;&#x5173;&#x952E;&#x5B57;&#xFF0C;&#x6240;&#x4EE5;&#x8FD9;&#x91CC;<span class="mathjax-exps">$\lambda$</span>&#x5199;&#x4F5C;lambd.</p>
        <p>&#x60A8;&#x5C06;&#x9996;&#x5148;&#x5C1D;&#x8BD5;&#x6CA1;&#x6709;&#x6B63;&#x5219;&#x5316;&#x7684;&#x6A21;&#x578B;&#xFF0C;&#x7136;&#x540E;&#x63A5;&#x7740;&#x5C1D;&#x8BD5;:</p>
        <ul>
        <li><em>L2 &#x56DE;&#x5F52;</em><br>
        &quot;<code>compute_cost_with_regularization()</code>&quot; and &quot;<code>backward_propagation_with_regularization()</code>&quot;</li>
        <li><em>Dropout</em><br>
        &quot;<code>forward_propagation_with_dropout()</code>&quot; and &quot;<code>backward_propagation_with_dropout()</code>&quot;</li>
        </ul>
        <p>In each part&#xFF0C;&#x60A8;&#x8981;&#x4F7F;&#x7528;&#x6B63;&#x786E;&#x7684;&#x8F93;&#x5165;&#x53BB;&#x8FD0;&#x884C;&#x6A21;&#x578B;&#xFF0C;&#x4EE5;&#x4FBF;&#x8C03;&#x7528;&#x60A8;&#x5DF2;&#x7ECF;&#x5B9E;&#x73B0;&#x7684;&#x529F;&#x80FD;&#x3002;&#x73B0;&#x5728;&#x8BA9;&#x6211;&#x4EEC;&#x6765;&#x719F;&#x6089;&#x4E0B;&#x6A21;&#x578B;&#x3002;</p>
        <pre data-role="codeBlock" data-info="python" class="language-python"><span class="token keyword">def</span> <span class="token function">model</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">,</span> learning_rate <span class="token operator">=</span> <span class="token number">0.3</span><span class="token punctuation">,</span> num_iterations <span class="token operator">=</span> <span class="token number">30000</span><span class="token punctuation">,</span> print_cost <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span> lambd <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> keep_prob <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token triple-quoted-string string">&quot;&quot;&quot;
            Implements a three-layer neural network: LINEAR-&gt;RELU-&gt;LINEAR-&gt;RELU-&gt;LINEAR-&gt;SIGMOID.
            
            Arguments:
            X -- input data, of shape (input size, number of examples)
            Y -- true &quot;label&quot; vector (1 for blue dot / 0 for red dot), of shape (output size, number of examples)
            learning_rate -- learning rate of the optimization
            num_iterations -- number of iterations of the optimization loop
            print_cost -- If True, print the cost every 10000 iterations
            lambd -- regularization hyperparameter, scalar
            keep_prob - probability of keeping a neuron active during drop-out, scalar.
            
            Returns:
            parameters -- parameters learned by the model. They can then be used to predict.
            &quot;&quot;&quot;</span>
                
            grads <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
            costs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>                            <span class="token comment"># to keep track of the cost</span>
            m <span class="token operator">=</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>                        <span class="token comment"># number of examples</span>
            layers_dims <span class="token operator">=</span> <span class="token punctuation">[</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>
            
            <span class="token comment"># Initialize parameters dictionary.</span>
            parameters <span class="token operator">=</span> initialize_parameters<span class="token punctuation">(</span>layers_dims<span class="token punctuation">)</span>
        
            <span class="token comment"># Loop (gradient descent)</span>
        
            <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> num_iterations<span class="token punctuation">)</span><span class="token punctuation">:</span>
        
                <span class="token comment"># Forward propagation: LINEAR -&gt; RELU -&gt; LINEAR -&gt; RELU -&gt; LINEAR -&gt; SIGMOID.</span>
                <span class="token keyword">if</span> keep_prob <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
                    a3<span class="token punctuation">,</span> cache <span class="token operator">=</span> forward_propagation<span class="token punctuation">(</span>X<span class="token punctuation">,</span> parameters<span class="token punctuation">)</span>
                <span class="token keyword">elif</span> keep_prob <span class="token operator">&lt;</span> <span class="token number">1</span><span class="token punctuation">:</span>
                    a3<span class="token punctuation">,</span> cache <span class="token operator">=</span> forward_propagation_with_dropout<span class="token punctuation">(</span>X<span class="token punctuation">,</span> parameters<span class="token punctuation">,</span> keep_prob<span class="token punctuation">)</span>
                
                <span class="token comment"># Cost function</span>
                <span class="token keyword">if</span> lambd <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                    cost <span class="token operator">=</span> compute_cost<span class="token punctuation">(</span>a3<span class="token punctuation">,</span> Y<span class="token punctuation">)</span>
                <span class="token keyword">else</span><span class="token punctuation">:</span>
                    cost <span class="token operator">=</span> compute_cost_with_regularization<span class="token punctuation">(</span>a3<span class="token punctuation">,</span> Y<span class="token punctuation">,</span> parameters<span class="token punctuation">,</span> lambd<span class="token punctuation">)</span>
                    
                <span class="token comment"># Backward propagation.</span>
                <span class="token keyword">assert</span><span class="token punctuation">(</span>lambd<span class="token operator">==</span><span class="token number">0</span> <span class="token keyword">or</span> keep_prob<span class="token operator">==</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token comment"># it is possible to use both L2 regularization and dropout, </span>
                                                    <span class="token comment"># but this assignment will only explore one at a time</span>
                <span class="token keyword">if</span> lambd <span class="token operator">==</span> <span class="token number">0</span> <span class="token keyword">and</span> keep_prob <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
                    grads <span class="token operator">=</span> backward_propagation<span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">,</span> cache<span class="token punctuation">)</span>
                <span class="token keyword">elif</span> lambd <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">:</span>
                    grads <span class="token operator">=</span> backward_propagation_with_regularization<span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">,</span> cache<span class="token punctuation">,</span> lambd<span class="token punctuation">)</span>
                <span class="token keyword">elif</span> keep_prob <span class="token operator">&lt;</span> <span class="token number">1</span><span class="token punctuation">:</span>
                    grads <span class="token operator">=</span> backward_propagation_with_dropout<span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">,</span> cache<span class="token punctuation">,</span> keep_prob<span class="token punctuation">)</span>
                
                <span class="token comment"># Update parameters.</span>
                parameters <span class="token operator">=</span> update_parameters<span class="token punctuation">(</span>parameters<span class="token punctuation">,</span> grads<span class="token punctuation">,</span> learning_rate<span class="token punctuation">)</span>
                
                <span class="token comment"># Print the loss every 10000 iterations</span>
                <span class="token keyword">if</span> print_cost <span class="token keyword">and</span> i <span class="token operator">%</span> <span class="token number">10000</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;Cost after iteration {}: {}&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span> cost<span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token keyword">if</span> print_cost <span class="token keyword">and</span> i <span class="token operator">%</span> <span class="token number">1000</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                    costs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>cost<span class="token punctuation">)</span>
            
            <span class="token comment"># plot the cost</span>
            plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>costs<span class="token punctuation">)</span>
            plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">&apos;cost&apos;</span><span class="token punctuation">)</span>
            plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">&apos;iterations (x1,000)&apos;</span><span class="token punctuation">)</span>
            plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">&quot;Learning rate =&quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>learning_rate<span class="token punctuation">)</span><span class="token punctuation">)</span>
            plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
            
            <span class="token keyword">return</span> parameters
        </pre><h4 class="mume-header" id="%E6%A3%80%E6%B5%8B%E6%95%88%E6%9E%9C-3">&#x68C0;&#x6D4B;&#x6548;&#x679C;</h4>
        
        <pre data-role="codeBlock" data-info="python" class="language-python">parameters <span class="token operator">=</span> model<span class="token punctuation">(</span>train_X<span class="token punctuation">,</span> train_Y<span class="token punctuation">)</span>
        <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&quot;On the training set:&quot;</span><span class="token punctuation">)</span>
        predictions_train <span class="token operator">=</span> predict<span class="token punctuation">(</span>train_X<span class="token punctuation">,</span> train_Y<span class="token punctuation">,</span> parameters<span class="token punctuation">)</span>
        <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&quot;On the test set:&quot;</span><span class="token punctuation">)</span>
        predictions_test <span class="token operator">=</span> predict<span class="token punctuation">(</span>test_X<span class="token punctuation">,</span> test_Y<span class="token punctuation">,</span> parameters<span class="token punctuation">)</span>
        </pre><img src="img/QQ&#x622A;&#x56FE;20200816164431.jpg" style="zoom:80%;">
        <h4 class="mume-header" id="%E8%AF%84%E4%BB%B7-3">&#x8BC4;&#x4EF7;</h4>
        
        <h5 class="mume-header" id="%E6%95%88%E6%9E%9C%E5%9B%BE%E6%A0%B7-3">&#x6548;&#x679C;&#x56FE;&#x6837;</h5>
        
        <pre data-role="codeBlock" data-info="python" class="language-python">plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">&quot;Model without regularization&quot;</span><span class="token punctuation">)</span>
        axes <span class="token operator">=</span> plt<span class="token punctuation">.</span>gca<span class="token punctuation">(</span><span class="token punctuation">)</span>
        axes<span class="token punctuation">.</span>set_xlim<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.75</span><span class="token punctuation">,</span><span class="token number">0.40</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        axes<span class="token punctuation">.</span>set_ylim<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.75</span><span class="token punctuation">,</span><span class="token number">0.65</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        plot_decision_boundary<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> predict_dec<span class="token punctuation">(</span>parameters<span class="token punctuation">,</span> x<span class="token punctuation">.</span>T<span class="token punctuation">)</span><span class="token punctuation">,</span> train_X<span class="token punctuation">,</span> train_Y<span class="token punctuation">)</span>
        </pre><img src="img/QQ&#x622A;&#x56FE;20200816165738.jpg" style="zoom:60%;">
        <p>&#x975E;&#x6B63;&#x5219;&#x5316;&#x6A21;&#x578B;&#x663E;&#x7136;&#x662F;<strong>&#x8FC7;&#x5EA6;&#x62DF;&#x5408;</strong>&#x8BAD;&#x7EC3;&#x96C6;&#xFF0C;&#x5B83;&#x62DF;&#x5408;&#x4E86;&#x566A;&#x97F3;&#x6570;&#x636E;&#xFF01;&#x73B0;&#x5728;&#x8BA9;&#x6211;&#x4EEC;&#x770B;&#x770B;&#x53EF;&#x4EE5;&#x51CF;&#x5C11;&#x8FC7;&#x5EA6;&#x62DF;&#x5408;&#x7684;&#x4E24;&#x79CD;&#x6280;&#x672F;&#x3002;</p>
        <h3 class="mume-header" id="l2%E5%9B%9E%E5%BD%92">L2&#x56DE;&#x5F52;</h3>
        
        <p>&#x6807;&#x51C6;&#x7684;&#x907F;&#x514D;&#x8FC7;&#x62DF;&#x5408;&#x7684;&#x65B9;&#x6CD5;&#x53EB;&#x505A;<strong>L2&#x56DE;&#x5F52;</strong>&#x3002;&#x5B83;&#x80FD;&#x591F;&#x6070;&#x5F53;&#x7684;&#x4F18;&#x5316;&#x4F60;&#x7684;&#x6210;&#x672C;&#x51FD;&#x6570;&#xFF0C;&#x4ECE;&#x4EA4;&#x53C9;&#x71B5;&#x6210;&#x672C;&#x51FD;&#x6570;:<br>
        </p><div class="mathjax-exps">$$J = -\frac{1}{m} \sum\limits_{i = 1}^{m} \large{(}\small  y^{(i)}\log\left(a^{[L](i)}\right) + (1-y^{(i)})\log\left(1- a^{[L](i)}\right) \large{)}$$</div><br>
        &#x53D8;&#x4E3A;&#x4EA4;&#x53C9;&#x71B5;&#x6210;&#x672C;&#x51FD;&#x6570;+L2&#x56DE;&#x5F52;&#x6210;&#x672C;&#x51FD;&#x6570;&#xFF1A;<br>
        <div class="mathjax-exps">$$J_{regularized} = \small \underbrace{-\frac{1}{m} \sum\limits_{i = 1}^{m} \large{(}\small y^{(i)}\log\left(a^{[L](i)}\right) + (1-y^{(i)})\log\left(1- a^{[L](i)}\right) \large{)} }_\text{&#x4EA4;&#x53C9;&#x71B5;&#x635F;&#x5931;} + \underbrace{\frac{1}{m} \frac{\lambda}{2} \sum\limits_l\sum\limits_k\sum\limits_j W_{k,j}^{[l]2} }_\text{L2&#x56DE;&#x5F52;&#x635F;&#x5931;}$$</div><p></p>
        <p>&#x8BA9;&#x6211;&#x4EEC;&#x4FEE;&#x6539;&#x4E0B;&#x6210;&#x672C;&#x51FD;&#x6570;&#x5E76;&#x89C2;&#x5BDF;&#x7ED3;&#x679C;&#x3002;&#xFF08;&#x4EE5;&#x4E09;&#x5C42;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x4E3A;&#x4F8B;&#xFF09;</p>
        <h4 class="mume-header" id="%E8%AE%A1%E7%AE%97%E5%9B%9E%E5%BD%92%E6%88%90%E6%9C%AC%E5%87%BD%E6%95%B0">&#x8BA1;&#x7B97;&#x56DE;&#x5F52;&#x6210;&#x672C;&#x51FD;&#x6570;</h4>
        
        <pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment"># GRADED FUNCTION: compute_cost_with_regularization</span>
        
        <span class="token keyword">def</span> <span class="token function">compute_cost_with_regularization</span><span class="token punctuation">(</span>A3<span class="token punctuation">,</span> Y<span class="token punctuation">,</span> parameters<span class="token punctuation">,</span> lambd<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token triple-quoted-string string">&quot;&quot;&quot;
            Implement the cost function with L2 regularization. See formula (2) above.
            
            Arguments:
            A3 -- post-activation, output of forward propagation, of shape (output size, number of examples)
            Y -- &quot;true&quot; labels vector, of shape (output size, number of examples)
            parameters -- python dictionary containing parameters of the model
            
            Returns:
            cost - value of the regularized loss function (formula (2))
            &quot;&quot;&quot;</span>
            m <span class="token operator">=</span> Y<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
            W1 <span class="token operator">=</span> parameters<span class="token punctuation">[</span><span class="token string">&quot;W1&quot;</span><span class="token punctuation">]</span>
            W2 <span class="token operator">=</span> parameters<span class="token punctuation">[</span><span class="token string">&quot;W2&quot;</span><span class="token punctuation">]</span>
            W3 <span class="token operator">=</span> parameters<span class="token punctuation">[</span><span class="token string">&quot;W3&quot;</span><span class="token punctuation">]</span>
            
            cross_entropy_cost <span class="token operator">=</span> compute_cost<span class="token punctuation">(</span>A3<span class="token punctuation">,</span> Y<span class="token punctuation">)</span> <span class="token comment"># &#x8BA1;&#x7B97;&#x4EA4;&#x53C9;&#x71B5;&#x6210;&#x672C;</span>
            
            <span class="token comment">### START CODE HERE ### (approx. 1 line)</span>
            L2_regularization_cost <span class="token operator">=</span> <span class="token number">1</span><span class="token operator">/</span>m <span class="token operator">*</span> lambd<span class="token operator">/</span><span class="token number">2</span> <span class="token operator">*</span> <span class="token punctuation">(</span>np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>square<span class="token punctuation">(</span>W1<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">+</span>np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>square<span class="token punctuation">(</span>W2<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">+</span>np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>square<span class="token punctuation">(</span>W3<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token comment">### END CODER HERE ###</span>
            
            cost <span class="token operator">=</span> cross_entropy_cost <span class="token operator">+</span> L2_regularization_cost
            
            <span class="token keyword">return</span> cost
        </pre><p>&#x5F53;&#x7136;&#xFF0C;&#x56E0;&#x4E3A;&#x4F60;&#x6539;&#x53D8;&#x4E86;&#x6210;&#x672C;&#xFF0C;&#x4F60;&#x4E5F;&#x5FC5;&#x987B;&#x6539;&#x53D8;&#x540E;&#x5411;&#x4F20;&#x64AD;&#xFF01;&#x6240;&#x6709;&#x7684;&#x68AF;&#x5EA6;&#x90FD;&#x5FC5;&#x987B;&#x8BA1;&#x7B97;&#x8FD9;&#x4E2A;&#x65B0;&#x7684;&#x6210;&#x672C;&#x3002;</p>
        <h4 class="mume-header" id="%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD">&#x53CD;&#x5411;&#x4F20;&#x64AD;</h4>
        
        <pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment"># GRADED FUNCTION: backward_propagation_with_regularization</span>
        
        <span class="token keyword">def</span> <span class="token function">backward_propagation_with_regularization</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">,</span> cache<span class="token punctuation">,</span> lambd<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token triple-quoted-string string">&quot;&quot;&quot;
            Implements the backward propagation of our baseline model to which we added an L2 regularization.
            
            Arguments:
            X -- input dataset, of shape (input size, number of examples)
            Y -- &quot;true&quot; labels vector, of shape (output size, number of examples)
            cache -- cache output from forward_propagation()
            lambd -- regularization hyperparameter, scalar
            
            Returns:
            gradients -- A dictionary with the gradients with respect to each parameter, activation and pre-activation variables
            &quot;&quot;&quot;</span>
            
            m <span class="token operator">=</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
            <span class="token punctuation">(</span>Z1<span class="token punctuation">,</span> A1<span class="token punctuation">,</span> W1<span class="token punctuation">,</span> b1<span class="token punctuation">,</span> Z2<span class="token punctuation">,</span> A2<span class="token punctuation">,</span> W2<span class="token punctuation">,</span> b2<span class="token punctuation">,</span> Z3<span class="token punctuation">,</span> A3<span class="token punctuation">,</span> W3<span class="token punctuation">,</span> b3<span class="token punctuation">)</span> <span class="token operator">=</span> cache
            
            dZ3 <span class="token operator">=</span> A3 <span class="token operator">-</span> Y
            
            <span class="token comment">### START CODE HERE ### (approx. 1 line)</span>
            dW3 <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token operator">/</span>m <span class="token operator">*</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>dZ3<span class="token punctuation">,</span> A2<span class="token punctuation">.</span>T<span class="token punctuation">)</span> <span class="token operator">+</span>  lambd<span class="token operator">/</span>m <span class="token operator">*</span> W3
            <span class="token comment">### END CODE HERE ###</span>
            db3 <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token operator">/</span>m <span class="token operator">*</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dZ3<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> keepdims <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
            
            dA2 <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>W3<span class="token punctuation">.</span>T<span class="token punctuation">,</span> dZ3<span class="token punctuation">)</span>
            dZ2 <span class="token operator">=</span> np<span class="token punctuation">.</span>multiply<span class="token punctuation">(</span>dA2<span class="token punctuation">,</span> np<span class="token punctuation">.</span>int64<span class="token punctuation">(</span>A2 <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token comment">### START CODE HERE ### (approx. 1 line)</span>
            dW2 <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token operator">/</span>m <span class="token operator">*</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>dZ2<span class="token punctuation">,</span> A1<span class="token punctuation">.</span>T<span class="token punctuation">)</span> <span class="token operator">+</span> lambd<span class="token operator">/</span>m <span class="token operator">*</span> W2
            <span class="token comment">### END CODE HERE ###</span>
            db2 <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token operator">/</span>m <span class="token operator">*</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dZ2<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> keepdims <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
            
            dA1 <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>W2<span class="token punctuation">.</span>T<span class="token punctuation">,</span> dZ2<span class="token punctuation">)</span>
            dZ1 <span class="token operator">=</span> np<span class="token punctuation">.</span>multiply<span class="token punctuation">(</span>dA1<span class="token punctuation">,</span> np<span class="token punctuation">.</span>int64<span class="token punctuation">(</span>A1 <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token comment">### START CODE HERE ### (approx. 1 line)</span>
            dW1 <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token operator">/</span>m <span class="token operator">*</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>dZ1<span class="token punctuation">,</span> X<span class="token punctuation">.</span>T<span class="token punctuation">)</span> <span class="token operator">+</span> lambd<span class="token operator">/</span>m <span class="token operator">*</span> W1
            <span class="token comment">### END CODE HERE ###</span>
            db1 <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token operator">/</span>m <span class="token operator">*</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dZ1<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> keepdims <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
            
            gradients <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;dZ3&quot;</span><span class="token punctuation">:</span> dZ3<span class="token punctuation">,</span> <span class="token string">&quot;dW3&quot;</span><span class="token punctuation">:</span> dW3<span class="token punctuation">,</span> <span class="token string">&quot;db3&quot;</span><span class="token punctuation">:</span> db3<span class="token punctuation">,</span><span class="token string">&quot;dA2&quot;</span><span class="token punctuation">:</span> dA2<span class="token punctuation">,</span>
                         <span class="token string">&quot;dZ2&quot;</span><span class="token punctuation">:</span> dZ2<span class="token punctuation">,</span> <span class="token string">&quot;dW2&quot;</span><span class="token punctuation">:</span> dW2<span class="token punctuation">,</span> <span class="token string">&quot;db2&quot;</span><span class="token punctuation">:</span> db2<span class="token punctuation">,</span> <span class="token string">&quot;dA1&quot;</span><span class="token punctuation">:</span> dA1<span class="token punctuation">,</span> 
                         <span class="token string">&quot;dZ1&quot;</span><span class="token punctuation">:</span> dZ1<span class="token punctuation">,</span> <span class="token string">&quot;dW1&quot;</span><span class="token punctuation">:</span> dW1<span class="token punctuation">,</span> <span class="token string">&quot;db1&quot;</span><span class="token punctuation">:</span> db1<span class="token punctuation">}</span>
            
            <span class="token keyword">return</span> gradients
        </pre><h5 class="mume-header" id="%E6%A3%80%E6%B5%8B%E6%95%88%E6%9E%9C-4">&#x68C0;&#x6D4B;&#x6548;&#x679C;</h5>
        
        <pre data-role="codeBlock" data-info="python" class="language-python">parameters <span class="token operator">=</span> model<span class="token punctuation">(</span>train_X<span class="token punctuation">,</span> train_Y<span class="token punctuation">,</span> lambd <span class="token operator">=</span> <span class="token number">0.7</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&quot;On the train set:&quot;</span><span class="token punctuation">)</span>
        predictions_train <span class="token operator">=</span> predict<span class="token punctuation">(</span>train_X<span class="token punctuation">,</span> train_Y<span class="token punctuation">,</span> parameters<span class="token punctuation">)</span>
        <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&quot;On the test set:&quot;</span><span class="token punctuation">)</span>
        predictions_test <span class="token operator">=</span> predict<span class="token punctuation">(</span>test_X<span class="token punctuation">,</span> test_Y<span class="token punctuation">,</span> parameters<span class="token punctuation">)</span>
        </pre><img src="img/QQ&#x622A;&#x56FE;20200816171133.jpg" style="zoom:80%;">
        <p>&#x606D;&#x559C;&#xFF0C;&#x6D4B;&#x8BD5;&#x96C6;&#x7CBE;&#x5EA6;&#x63D0;&#x9AD8;&#x5230;&#x4E86;93&#xFF05;&#x3002;&#x4F60;&#x5DF2;&#x7ECF;&#x62EF;&#x6551;&#x4E86;&#x6CD5;&#x56FD;&#x8DB3;&#x7403;&#x961F;&#xFF01;</p>
        <h4 class="mume-header" id="%E8%AF%84%E4%BB%B7-4">&#x8BC4;&#x4EF7;</h4>
        
        <h5 class="mume-header" id="%E6%95%88%E6%9E%9C%E5%9B%BE%E6%A0%B7-4">&#x6548;&#x679C;&#x56FE;&#x6837;</h5>
        
        <pre data-role="codeBlock" data-info="python" class="language-python">plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">&quot;Model with L2-regularization&quot;</span><span class="token punctuation">)</span>
        axes <span class="token operator">=</span> plt<span class="token punctuation">.</span>gca<span class="token punctuation">(</span><span class="token punctuation">)</span>
        axes<span class="token punctuation">.</span>set_xlim<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.75</span><span class="token punctuation">,</span><span class="token number">0.40</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        axes<span class="token punctuation">.</span>set_ylim<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.75</span><span class="token punctuation">,</span><span class="token number">0.65</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        plot_decision_boundary<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> predict_dec<span class="token punctuation">(</span>parameters<span class="token punctuation">,</span> x<span class="token punctuation">.</span>T<span class="token punctuation">)</span><span class="token punctuation">,</span> train_X<span class="token punctuation">,</span> train_Y<span class="token punctuation">)</span>
        </pre><img src="img/QQ&#x622A;&#x56FE;20200816171219.jpg" style="zoom:80%;">
        <h5 class="mume-header" id="%E7%89%B9%E7%82%B9-1">&#x7279;&#x70B9;</h5>
        
        <ul>
        <li><span class="mathjax-exps">$\lambda$</span> &#x662F;&#x4E00;&#x4E2A;&#x4F60;&#x53EF;&#x4EE5;&#x7528;&#x5F00;&#x53D1;&#x96C6;&#x53BB;&#x8C03;&#x6574;&#x7684;&#x8D85;&#x53C2;&#x6570;.</li>
        <li>L2 &#x6B63;&#x5219;&#x5316;&#x4F7F;&#x5F97;&#x4F60;&#x7684;&#x51B3;&#x7B56;&#x8FB9;&#x754C;&#x66F4;&#x52A0;&#x5E73;&#x6ED1;. &#x5982;&#x679C; <span class="mathjax-exps">$\lambda$</span> &#x592A;&#x5927;, &#x4E5F;&#x6709;&#x53EF;&#x80FD;&#x201C;&#x8FC7;&#x5EA6;&#x5E73;&#x6ED1;&#x201D;&#xFF0C;&#x5BFC;&#x81F4;&#x9AD8;&#x504F;&#x5DEE;&#x6A21;&#x578B;&#x3002;</li>
        </ul>
        <h5 class="mume-header" id="l2%E5%88%B0%E5%BA%95%E5%9C%A8%E5%81%9A%E4%BB%80%E4%B9%88">L2&#x5230;&#x5E95;&#x5728;&#x505A;&#x4EC0;&#x4E48;</h5>
        
        <p>L2&#x6B63;&#x5219;&#x5316;&#x4F9D;&#x8D56;&#x4E8E;&#x8FD9;&#x6837;&#x7684;&#x5047;&#x8BBE;&#xFF0C;&#x5373;<strong>&#x6743;&#x91CD;&#x8D8A;&#x5927;&#x6A21;&#x578B;&#x8D8A;&#x590D;&#x6742;</strong>&#x3002;</p>
        <p>&#x56E0;&#x6B64;&#xFF0C;&#x901A;&#x8FC7;&#x60E9;&#x7F5A;&#x6210;&#x672C;&#x51FD;&#x6570;&#x4E2D;&#x6743;&#x91CD;&#x7684;&#x5E73;&#x65B9;&#x503C;&#xFF0C;&#x53EF;&#x4EE5;&#x5C06;&#x6240;&#x6709;&#x6743;&#x91CD;&#x90FD;&#x53D8;&#x6210;&#x66F4;&#x5C0F;&#x7684;&#x503C;&#x3002;&#x5982;&#x679C;&#x6743;&#x91CD;&#x8FC7;&#x5927;&#xFF0C;&#x8BA1;&#x7B97;&#x5F00;&#x9500;&#x4F1A;&#x5F88;&#x5927;&#xFF01;&#x800C;&#x4E14;&#xFF0C;&#x8FD9;&#x5C06;&#x4EA7;&#x751F;&#x4E00;&#x4E2A;&#x66F4;&#x5E73;&#x6ED1;&#x7684;&#x6A21;&#x578B;&#xFF0C;&#x5728;&#x8FD9;&#x4E2A;&#x6A21;&#x578B;&#x4E2D;&#xFF0C;&#x8F93;&#x51FA;&#x968F;&#x7740;&#x8F93;&#x5165;&#x7684;&#x53D8;&#x5316;&#x800C;&#x53D8;&#x5316;&#x5F97;&#x66F4;&#x6162;&#x3002;</p>
        <h4 class="mume-header" id="%E6%80%BB%E7%BB%93-2">&#x603B;&#x7ED3;</h4>
        
        <p>L2&#x56DE;&#x5F52;&#x7684;&#x542B;&#x4E49;:</p>
        <p><strong>&#x8BA1;&#x7B97;&#x6210;&#x672C;</strong> &#xFF1A;&#x6DFB;&#x52A0;&#x6B63;&#x5219;&#x9879;&#x5230;&#x6210;&#x672C;&#x51FD;&#x6570;</p>
        <p><strong>&#x53CD;&#x5411;&#x4F20;&#x64AD;</strong> &#xFF1A;&#x5173;&#x4E8E;&#x6743;&#x91CD;&#x77E9;&#x9635;&#x7684;&#x68AF;&#x5EA6;&#x4E2D;&#x6709;&#x989D;&#x5916;&#x7684;&#x9879;</p>
        <p><strong>&#x6700;&#x7EC8;&#x6743;&#x91CD;&#x8F83;&#x5C0F;</strong> &#xFF1A;&#x6743;&#x91CD;&#x63A8;&#x5230;&#x66F4;&#x5C0F;&#x7684;&#x503C;&#x3002;</p>
        <h3 class="mume-header" id="dropout%E5%9B%9E%E5%BD%92">Dropout&#x56DE;&#x5F52;</h3>
        
        <p><strong>dropout&#x56DE;&#x5F52;&#xFF08;&#x968F;&#x673A;&#x5931;&#x6D3B;&#xFF09;</strong> &#x662F;&#x6DF1;&#x5EA6;&#x5B66;&#x4E60;&#x6240;&#x7279;&#x6709;&#x7684;&#x88AB;&#x5E7F;&#x6CDB;&#x4F7F;&#x7528;&#x7684;&#x6B63;&#x5219;&#x5316;&#x6280;&#x672F;&#x3002;&#x5B83;&#x5728;&#x6BCF;&#x6B21;&#x8FED;&#x4EE3;&#x4E2D;<strong>&#x968F;&#x673A;&#x5173;&#x95ED;&#x4E00;&#x4E9B;&#x795E;&#x7ECF;&#x5143;</strong>&#x3002;</p>
        <p>&#x5F53;&#x4F60;&#x5173;&#x95ED;&#x4E00;&#x4E9B;&#x795E;&#x7ECF;&#x5143;&#x65F6;&#xFF0C;&#x4F60;&#x5B9E;&#x9645;&#x4E0A;&#x4FEE;&#x6539;&#x4E86;&#x4F60;&#x7684;&#x6A21;&#x578B;&#x3002;&#x76F8;&#x5F53;&#x4E8E;&#x5728;&#x6BCF;&#x6B21;&#x8FED;&#x4EE3;&#x4E2D;&#xFF0C;&#x4F60;&#x90FD;&#x8BAD;&#x7EC3;&#x4E86;&#x4E00;&#x4E2A;&#x4E0D;&#x540C;&#x7684;&#x6A21;&#x578B;&#xFF0C;&#x4F60;&#x53EA;&#x4F7F;&#x7528;&#x4F60;&#x7684;&#x795E;&#x7ECF;&#x5143;&#x7684;&#x4E00;&#x4E2A;&#x5B50;&#x96C6;&#x3002;&#x968F;&#x673A;&#x5931;&#x6D3B;&#x4F7F;&#x6BCF;&#x4E00;&#x4E2A;&#x795E;&#x7ECF;&#x5143;&#x4E0D;&#x518D;&#x4F9D;&#x8D56;&#x53E6;&#x4E00;&#x4E2A;&#x7279;&#x5B9A;&#x7684;&#x795E;&#x7ECF;&#x5143;&#xFF0C;&#x56E0;&#x4E3A;&#x5176;&#x4ED6;&#x7684;&#x795E;&#x7ECF;&#x5143;&#x968F;&#x65F6;&#x53EF;&#x80FD;&#x88AB;&#x5173;&#x95ED;&#x3002;&#x968F;&#x673A;&#x5931;&#x6D3B;&#x80FD;&#x9632;&#x6B62;&#x8FC7;&#x62DF;&#x5408;&#x3002;</p>
        <h4 class="mume-header" id="%E6%AD%A3%E5%90%91%E4%BC%A0%E6%92%ADdropout">&#x6B63;&#x5411;&#x4F20;&#x64AD;&#xFF08;+dropout&#xFF09;</h4>
        
        <p>&#x5982;&#x679C;&#x4F60;&#x60F3;&#x5173;&#x95ED;&#x7B2C;&#x4E00;&#x5C42;&#x548C;&#x7B2C;&#x4E8C;&#x5C42;&#x4E2D;&#x7684;&#x67D0;&#x4E9B;&#x795E;&#x7ECF;&#x5143;&#x3002;&#x4F60;&#x9700;&#x8981;&#x6267;&#x884C;&#x4E0B;&#x9762;&#x7684;&#x56DB;&#x4E2A;&#x6B65;&#x9AA4;:</p>
        <ol>
        <li>
        <p>&#x5728;&#x8BFE;&#x7A0B;&#x4E2D;&#xFF0C;&#x6211;&#x4EEC;&#x8BA8;&#x8BBA;&#x4E86;&#x4F7F;&#x7528;<code>np.random.rand()</code>&#x521B;&#x5EFA;&#x4E00;&#x4E2A;&#x4E0E;<span class="mathjax-exps">$a^{[1]}$</span>&#x5177;&#x6709;&#x76F8;&#x540C;shap&#x7684;&#x53D8;&#x91CF;<span class="mathjax-exps">$d^{[1]}$</span>&#x6765;&#x968F;&#x673A;&#x83B7;&#x53D6;0&#x5230;1&#x4E4B;&#x95F4;&#x7684;&#x6570;&#x5B57;&#x3002;&#x8FD9;&#x91CC;&#xFF0C;&#x60A8;&#x5C06;&#x4F7F;&#x7528;&#x4E00;&#x4E2A;&#x5411;&#x91CF;&#x5316;&#x7684;&#x5B9E;&#x73B0;&#xFF0C;&#x56E0;&#x6B64;&#x521B;&#x5EFA;&#x4E00;&#x4E2A;&#x968F;&#x673A;&#x77E9;&#x9635;<span class="mathjax-exps">$D^{[1]} = [d^{[1](1)} d^{[1](2)} ... d^{[1](m)}]$</span>&#x4E0E;<span class="mathjax-exps">$A^{[1]}$</span>&#x7EF4;&#x6570;&#x76F8;&#x540C;.</p>
        </li>
        <li>
        <p>&#x901A;&#x8FC7;&#x5BF9;<span class="mathjax-exps">$D^{[1]}$</span>&#x4E2D;&#x7684;&#x503C;&#x8FDB;&#x884C;&#x9002;&#x5F53;&#x7684;&#x9608;&#x503C;&#x8BBE;&#x5B9A;&#xFF0C;&#x5C06;<span class="mathjax-exps">$D^{[1]}$</span>&#x7684;&#x6BCF;&#x4E2A;&#x6761;&#x76EE;&#x6982;&#x7387;&#x8BBE;&#x4E3A;0 (<code>1-keep prob</code>)&#x6216;&#x6982;&#x7387;&#x8BBE;&#x4E3A;1 (<code>keep prob</code>)&#x3002;</p>
        <p><strong>&#x63D0;&#x793A;:</strong> &#x5982;&#x679C;&#x8981;&#x5C06;&#x77E9;&#x9635;X&#x7684;&#x6240;&#x6709;&#x9879;&#x8BBE;&#x4E3A;0(&#x5982;&#x679C;&#x9879;&#x5C0F;&#x4E8E;0.5)&#x6216;1(&#x5982;&#x679C;&#x9879;&#x5927;&#x4E8E;0.5)&#xFF0C;&#x53EF;&#x4EE5;&#x8FD9;&#x6837;&#x505A;:<code>X = (X &lt; 0.5)</code>&#x3002;&#x6CE8;&#x610F;&#xFF0C;0&#x548C;1&#x5206;&#x522B;&#x7B49;&#x540C;&#x4E8E;False&#x548C;True&#x3002;</p>
        </li>
        <li>
        <p>&#x8BBE;&#x7F6E; <span class="mathjax-exps">$A^{[1]}$</span>&#x4E3A; <span class="mathjax-exps">$A^{[1]} * D^{[1]}$</span>. (&#x4F60;&#x6B63;&#x5728;&#x5173;&#x6389;&#x4E00;&#x4E9B;&#x795E;&#x7ECF;&#x5143;). &#x4F60;&#x53EF;&#x4EE5;&#x8BA4;&#x4E3A; <span class="mathjax-exps">$D^{[1]}$</span> &#x662F;&#x4E00;&#x4E2A;&#x9762;&#x5177;&#xFF0C;&#x4E58;&#x4E0A;&#x5C31;&#x53EF;&#x4EE5;&#x5173;&#x6389;&#x4E00;&#x4E9B;&#x795E;&#x7ECF;&#x5143;.</p>
        </li>
        <li>
        <p>&#x6309;<code>keep_prob</code>&#x5206;&#x5272;<span class="mathjax-exps">$A^{[1]}$</span>&#x3002;&#x901A;&#x8FC7;&#x8FD9;&#x6837;&#x505A;&#xFF0C;&#x60A8;&#x53EF;&#x4EE5;&#x786E;&#x4FDD;&#x6210;&#x672C;&#x7684;&#x7ED3;&#x679C;&#x4ECD;&#x7136;&#x5177;&#x6709;&#x4E0E;&#x4E0D;&#x4F7F;&#x7528;dropout&#x76F8;&#x540C;&#x7684;&#x671F;&#x671B;&#x503C;&#x3002;</p>
        </li>
        </ol>
        <pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment"># GRADED FUNCTION: forward_propagation_with_dropout</span>
        
        <span class="token keyword">def</span> <span class="token function">forward_propagation_with_dropout</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> parameters<span class="token punctuation">,</span> keep_prob <span class="token operator">=</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token triple-quoted-string string">&quot;&quot;&quot;
            Implements the forward propagation: LINEAR -&gt; RELU + DROPOUT -&gt; LINEAR -&gt; RELU + DROPOUT -&gt; LINEAR -&gt; SIGMOID.
            
            Arguments:
            X -- input dataset, of shape (2, number of examples)
            parameters -- python dictionary containing your parameters &quot;W1&quot;, &quot;b1&quot;, &quot;W2&quot;, &quot;b2&quot;, &quot;W3&quot;, &quot;b3&quot;:
                            W1 -- weight matrix of shape (20, 2)
                            b1 -- bias vector of shape (20, 1)
                            W2 -- weight matrix of shape (3, 20)
                            b2 -- bias vector of shape (3, 1)
                            W3 -- weight matrix of shape (1, 3)
                            b3 -- bias vector of shape (1, 1)
            keep_prob - probability of keeping a neuron active during drop-out, scalar
            
            Returns:
            A3 -- last activation value, output of the forward propagation, of shape (1,1)
            cache -- tuple, information stored for computing the backward propagation
            &quot;&quot;&quot;</span>
            
            np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
            
            <span class="token comment"># retrieve parameters</span>
            W1 <span class="token operator">=</span> parameters<span class="token punctuation">[</span><span class="token string">&quot;W1&quot;</span><span class="token punctuation">]</span>
            b1 <span class="token operator">=</span> parameters<span class="token punctuation">[</span><span class="token string">&quot;b1&quot;</span><span class="token punctuation">]</span>
            W2 <span class="token operator">=</span> parameters<span class="token punctuation">[</span><span class="token string">&quot;W2&quot;</span><span class="token punctuation">]</span>
            b2 <span class="token operator">=</span> parameters<span class="token punctuation">[</span><span class="token string">&quot;b2&quot;</span><span class="token punctuation">]</span>
            W3 <span class="token operator">=</span> parameters<span class="token punctuation">[</span><span class="token string">&quot;W3&quot;</span><span class="token punctuation">]</span>
            b3 <span class="token operator">=</span> parameters<span class="token punctuation">[</span><span class="token string">&quot;b3&quot;</span><span class="token punctuation">]</span>
            
            <span class="token comment"># LINEAR -&gt; RELU -&gt; LINEAR -&gt; RELU -&gt; LINEAR -&gt; SIGMOID</span>
            Z1 <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>W1<span class="token punctuation">,</span> X<span class="token punctuation">)</span> <span class="token operator">+</span> b1
            A1 <span class="token operator">=</span> relu<span class="token punctuation">(</span>Z1<span class="token punctuation">)</span>
            <span class="token comment">### START CODE HERE ### (approx. 4 lines)         # &#x6B65;&#x9AA4; 1-4. </span>
            D1 <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span>A1<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> A1<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>     <span class="token comment"># &#x6B65;&#x9AA4; 1: &#x521D;&#x59CB;&#x5316;&#x77E9;&#x9635; D1 = np.random.rand(..., ...)</span>
            D1 <span class="token operator">=</span> D1 <span class="token operator">&lt;</span> keep_prob                               <span class="token comment"># &#x6B65;&#x9AA4; 2: &#x5C06; D1 &#x8F6C;&#x4E3A;0&#x6216;1 (&#x5C06;keep_prob&#x4F5C;&#x4E3A;&#x6982;&#x7387;)</span>
            A1 <span class="token operator">=</span> np<span class="token punctuation">.</span>multiply<span class="token punctuation">(</span>D1<span class="token punctuation">,</span> A1<span class="token punctuation">)</span>                          <span class="token comment"># &#x6B65;&#x9AA4; 3: &#x5173;&#x95ED;&#x4E00;&#x4E9B; A1&#x5185;&#x7684;&#x795E;&#x7ECF;&#x5143;</span>
            A1 <span class="token operator">=</span> A1 <span class="token operator">/</span> keep_prob                               <span class="token comment"># &#x6B65;&#x9AA4; 4: &#x9664;&#x4EE5;keep_prob&#xFF0C;&#x5206;&#x644A;&#x5173;&#x95ED;&#x795E;&#x7ECF;&#x5143;&#x5E26;&#x6765;&#x7684;&#x6570;&#x503C;&#x635F;&#x5931;</span>
            <span class="token comment">### END CODE HERE ###</span>
            Z2 <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>W2<span class="token punctuation">,</span> A1<span class="token punctuation">)</span> <span class="token operator">+</span> b2
            A2 <span class="token operator">=</span> relu<span class="token punctuation">(</span>Z2<span class="token punctuation">)</span>
            <span class="token comment">### START CODE HERE ### (approx. 4 lines)</span>
            D2 <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span>A2<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> A2<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>     
            D2 <span class="token operator">=</span> D2 <span class="token operator">&lt;</span> keep_prob                              
            A2 <span class="token operator">=</span> np<span class="token punctuation">.</span>multiply<span class="token punctuation">(</span>D2<span class="token punctuation">,</span> A2<span class="token punctuation">)</span>                          
            A2 <span class="token operator">=</span> A2 <span class="token operator">/</span> keep_prob                               
            <span class="token comment">### END CODE HERE ###</span>
            Z3 <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>W3<span class="token punctuation">,</span> A2<span class="token punctuation">)</span> <span class="token operator">+</span> b3
            A3 <span class="token operator">=</span> sigmoid<span class="token punctuation">(</span>Z3<span class="token punctuation">)</span>
            
            cache <span class="token operator">=</span> <span class="token punctuation">(</span>Z1<span class="token punctuation">,</span> D1<span class="token punctuation">,</span> A1<span class="token punctuation">,</span> W1<span class="token punctuation">,</span> b1<span class="token punctuation">,</span> Z2<span class="token punctuation">,</span> D2<span class="token punctuation">,</span> A2<span class="token punctuation">,</span> W2<span class="token punctuation">,</span> b2<span class="token punctuation">,</span> Z3<span class="token punctuation">,</span> A3<span class="token punctuation">,</span> W3<span class="token punctuation">,</span> b3<span class="token punctuation">)</span>
            
            <span class="token keyword">return</span> A3<span class="token punctuation">,</span> cache
        </pre><h4 class="mume-header" id="%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%ADdropout">&#x53CD;&#x5411;&#x4F20;&#x64AD;&#xFF08;+dropout&#xFF09;</h4>
        
        <p>&#x62E5;&#x6709;&#x968F;&#x673A;&#x5931;&#x6D3B;&#x7684;&#x53CD;&#x5411;&#x4F20;&#x64AD;&#x5176;&#x5B9E;&#x5F88;&#x7B80;&#x5355;. &#x4F60;&#x53EA;&#x9700;&#x6267;&#x884C;&#x4E0B;&#x9762;&#x4E24;&#x4E2A;&#x6B65;&#x9AA4;:</p>
        <ol>
        <li>&#x4F60;&#x4E4B;&#x524D;&#x5DF2;&#x7ECF;&#x5728;&#x524D;&#x5411;&#x4F20;&#x64AD;&#x8FC7;&#x7A0B;&#x4E2D;&#x5173;&#x95ED;&#x4E86;&#x4E00;&#x4E9B;&#x795E;&#x7ECF;&#x5143;&#xFF0C;&#x65B9;&#x6CD5;&#x662F;&#x5BF9;<code>A1</code>&#x5E94;&#x7528;&#x201C;&#x9762;&#x5177;&#x201D;&#x3010;&#x8499;&#x7248;&#x3011; <span class="mathjax-exps">$D^{[1]}$</span>&#x3002;&#x5728;&#x53CD;&#x5411;&#x4F20;&#x64AD;&#x4E2D;&#xFF0C;&#x4F60;&#x5FC5;&#x987B;&#x5173;&#x95ED;&#x4E00;&#x4E9B;&#x795E;&#x7ECF;&#x5143;&#xFF0C;&#x4E14;&#x6C42;<code>dA1</code>&#x5E94;&#x8BE5;&#x7528;&#x540C;&#x6837;&#x7684;&#x8499;&#x7248; <span class="mathjax-exps">$D^{[1]}$</span>.</li>
        <li>&#x901A;&#x8FC7;&#x6B63;&#x5411;&#x4F20;&#x64AD;&#xFF0C;&#x4F60;&#x5DF2;&#x7ECF;&#x6309;<code>keep_prob</code>&#x5206;&#x5272;&#x4E86;<code>A1</code>&#x3002;&#x5728;&#x53CD;&#x5411;&#x4F20;&#x64AD;&#x4E2D;&#xFF0C;&#x4F60;&#x4E5F;&#x5E94;&#x8BE5;&#x7528; <code>keep_prob</code>&#x5206;&#x5272;<code>dA1</code> &#x3002;</li>
        </ol>
        <pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment"># GRADED FUNCTION: backward_propagation_with_dropout</span>
        
        <span class="token keyword">def</span> <span class="token function">backward_propagation_with_dropout</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">,</span> cache<span class="token punctuation">,</span> keep_prob<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token triple-quoted-string string">&quot;&quot;&quot;
            Implements the backward propagation of our baseline model to which we added dropout.
            
            Arguments:
            X -- input dataset, of shape (2, number of examples)
            Y -- &quot;true&quot; labels vector, of shape (output size, number of examples)
            cache -- cache output from forward_propagation_with_dropout()
            keep_prob - probability of keeping a neuron active during drop-out, scalar
            
            Returns:
            gradients -- A dictionary with the gradients with respect to each parameter, activation and pre-activation variables
            &quot;&quot;&quot;</span>
            
            m <span class="token operator">=</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
            <span class="token punctuation">(</span>Z1<span class="token punctuation">,</span> D1<span class="token punctuation">,</span> A1<span class="token punctuation">,</span> W1<span class="token punctuation">,</span> b1<span class="token punctuation">,</span> Z2<span class="token punctuation">,</span> D2<span class="token punctuation">,</span> A2<span class="token punctuation">,</span> W2<span class="token punctuation">,</span> b2<span class="token punctuation">,</span> Z3<span class="token punctuation">,</span> A3<span class="token punctuation">,</span> W3<span class="token punctuation">,</span> b3<span class="token punctuation">)</span> <span class="token operator">=</span> cache
            
            dZ3 <span class="token operator">=</span> A3 <span class="token operator">-</span> Y
            dW3 <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token operator">/</span>m <span class="token operator">*</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>dZ3<span class="token punctuation">,</span> A2<span class="token punctuation">.</span>T<span class="token punctuation">)</span>
            db3 <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token operator">/</span>m <span class="token operator">*</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dZ3<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> keepdims <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
            dA2 <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>W3<span class="token punctuation">.</span>T<span class="token punctuation">,</span> dZ3<span class="token punctuation">)</span>
            <span class="token comment">### START CODE HERE ### (&#x2248; 2 lines of code)</span>
            dA2 <span class="token operator">=</span> np<span class="token punctuation">.</span>multiply<span class="token punctuation">(</span>dA2<span class="token punctuation">,</span> D2<span class="token punctuation">)</span>      <span class="token comment"># &#x6B65;&#x9AA4; 1: &#x5E94;&#x7528;&#x8499;&#x7248;D2&#x5173;&#x95ED;&#x548C;&#x6B63;&#x5411;&#x4F20;&#x64AD;&#x4E00;&#x6837;&#x7684;&#x795E;&#x7ECF;&#x5143;</span>
            dA2 <span class="token operator">=</span> dA2 <span class="token operator">/</span> keep_prob           <span class="token comment"># &#x6B65;&#x9AA4; 2: &#x9664;&#x4EE5;keep_prob&#xFF0C;&#x5206;&#x644A;&#x5173;&#x95ED;&#x795E;&#x7ECF;&#x5143;&#x5E26;&#x6765;&#x7684;&#x6570;&#x503C;&#x635F;&#x5931;</span>
            <span class="token comment">### END CODE HERE ###</span>
            dZ2 <span class="token operator">=</span> np<span class="token punctuation">.</span>multiply<span class="token punctuation">(</span>dA2<span class="token punctuation">,</span> np<span class="token punctuation">.</span>int64<span class="token punctuation">(</span>A2 <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            dW2 <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token operator">/</span>m <span class="token operator">*</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>dZ2<span class="token punctuation">,</span> A1<span class="token punctuation">.</span>T<span class="token punctuation">)</span>
            db2 <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token operator">/</span>m <span class="token operator">*</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dZ2<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> keepdims <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
            
            dA1 <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>W2<span class="token punctuation">.</span>T<span class="token punctuation">,</span> dZ2<span class="token punctuation">)</span>
            <span class="token comment">### START CODE HERE ### (&#x2248; 2 lines of code)</span>
            dA1 <span class="token operator">=</span> np<span class="token punctuation">.</span>multiply<span class="token punctuation">(</span>dA1<span class="token punctuation">,</span> D1<span class="token punctuation">)</span>     
            dA1 <span class="token operator">=</span> dA1 <span class="token operator">/</span> keep_prob          
            <span class="token comment">### END CODE HERE ###</span>
            dZ1 <span class="token operator">=</span> np<span class="token punctuation">.</span>multiply<span class="token punctuation">(</span>dA1<span class="token punctuation">,</span> np<span class="token punctuation">.</span>int64<span class="token punctuation">(</span>A1 <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            dW1 <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token operator">/</span>m <span class="token operator">*</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>dZ1<span class="token punctuation">,</span> X<span class="token punctuation">.</span>T<span class="token punctuation">)</span>
            db1 <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token operator">/</span>m <span class="token operator">*</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dZ1<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> keepdims <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
            
            gradients <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;dZ3&quot;</span><span class="token punctuation">:</span> dZ3<span class="token punctuation">,</span> <span class="token string">&quot;dW3&quot;</span><span class="token punctuation">:</span> dW3<span class="token punctuation">,</span> <span class="token string">&quot;db3&quot;</span><span class="token punctuation">:</span> db3<span class="token punctuation">,</span><span class="token string">&quot;dA2&quot;</span><span class="token punctuation">:</span> dA2<span class="token punctuation">,</span>
                         <span class="token string">&quot;dZ2&quot;</span><span class="token punctuation">:</span> dZ2<span class="token punctuation">,</span> <span class="token string">&quot;dW2&quot;</span><span class="token punctuation">:</span> dW2<span class="token punctuation">,</span> <span class="token string">&quot;db2&quot;</span><span class="token punctuation">:</span> db2<span class="token punctuation">,</span> <span class="token string">&quot;dA1&quot;</span><span class="token punctuation">:</span> dA1<span class="token punctuation">,</span> 
                         <span class="token string">&quot;dZ1&quot;</span><span class="token punctuation">:</span> dZ1<span class="token punctuation">,</span> <span class="token string">&quot;dW1&quot;</span><span class="token punctuation">:</span> dW1<span class="token punctuation">,</span> <span class="token string">&quot;db1&quot;</span><span class="token punctuation">:</span> db1<span class="token punctuation">}</span>
            
            <span class="token keyword">return</span> gradients
        </pre><h4 class="mume-header" id="%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%9E%8B">&#x8FD0;&#x884C;&#x6A21;&#x578B;</h4>
        
        <p>&#x73B0;&#x5728;&#x8BA9;&#x6211;&#x4EEC;&#x7528;dropout&#xFF08;keep_prob = 0.86&#xFF09;&#x6765;&#x8FD0;&#x884C;&#x6A21;&#x578B;&#x3002;&#x8FD9;&#x610F;&#x5473;&#x7740;&#x5728;&#x6BCF;&#x4E00;&#x6B21;&#x8FED;&#x4EE3;&#x4E2D;&#xFF0C;&#x90FD;&#x4EE5;24&#xFF05;&#x7684;&#x6982;&#x7387;&#x5173;&#x95ED;&#x7B2C;1&#x5C42;&#x548C;&#x7B2C;2&#x5C42;&#x7684;&#x6BCF;&#x4E2A;&#x795E;&#x7ECF;&#x5143;&#x3002;</p>
        <pre data-role="codeBlock" data-info="python" class="language-python">parameters <span class="token operator">=</span> model<span class="token punctuation">(</span>train_X<span class="token punctuation">,</span> train_Y<span class="token punctuation">,</span> keep_prob <span class="token operator">=</span> <span class="token number">0.86</span><span class="token punctuation">,</span> learning_rate <span class="token operator">=</span> <span class="token number">0.3</span><span class="token punctuation">)</span>
        
        <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&quot;On the train set:&quot;</span><span class="token punctuation">)</span>
        predictions_train <span class="token operator">=</span> predict<span class="token punctuation">(</span>train_X<span class="token punctuation">,</span> train_Y<span class="token punctuation">,</span> parameters<span class="token punctuation">)</span>
        <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&quot;On the test set:&quot;</span><span class="token punctuation">)</span>
        predictions_test <span class="token operator">=</span> predict<span class="token punctuation">(</span>test_X<span class="token punctuation">,</span> test_Y<span class="token punctuation">,</span> parameters<span class="token punctuation">)</span>
        </pre><img src="img/QQ&#x622A;&#x56FE;20200816171600.jpg" style="zoom:67%;">
        <p>Dropout &#x8868;&#x73B0;&#x7684;&#x5F88;&#x4F18;&#x5F02;&#xFF01;&#x6D4B;&#x8BD5;&#x96C6; accuracy &#x518D;&#x6B21;&#x63D0;&#x9AD8;&#xFF08;&#x8FBE;&#x5230;95&#xFF05;&#xFF09;&#xFF01;&#x4F60;&#x7684;&#x6A21;&#x578B;&#x5BF9;&#x8BAD;&#x7EC3;&#x96C6;&#x4E0D;&#x518D;&#x8FC7;&#x62DF;&#x5408;&#xFF0C;&#x5E76;&#x4E14;&#x5728;&#x6D4B;&#x8BD5;&#x96C6;&#x4E0A;&#x8868;&#x73B0;&#x4E5F;&#x5F88;&#x597D;&#x3002;&#x6CD5;&#x56FD;&#x8DB3;&#x7403;&#x961F;&#x5C06;&#x6C38;&#x8FDC;&#x611F;&#x6FC0;&#x4F60;&#xFF01;</p>
        <h4 class="mume-header" id="%E8%AF%84%E4%BB%B7-5">&#x8BC4;&#x4EF7;</h4>
        
        <h5 class="mume-header" id="%E6%95%88%E6%9E%9C%E5%9B%BE%E6%A0%B7-5">&#x6548;&#x679C;&#x56FE;&#x6837;</h5>
        
        <p>&#x8FD0;&#x884C;&#x4E0B;&#x9762;&#x7684;&#x4EE3;&#x7801;&#x6765;&#x7ED8;&#x5236;&#x51B3;&#x7B56;&#x8FB9;&#x754C;</p>
        <pre data-role="codeBlock" data-info="python" class="language-python">plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">&quot;Model with dropout&quot;</span><span class="token punctuation">)</span>
        axes <span class="token operator">=</span> plt<span class="token punctuation">.</span>gca<span class="token punctuation">(</span><span class="token punctuation">)</span>
        axes<span class="token punctuation">.</span>set_xlim<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.75</span><span class="token punctuation">,</span><span class="token number">0.40</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        axes<span class="token punctuation">.</span>set_ylim<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.75</span><span class="token punctuation">,</span><span class="token number">0.65</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        plot_decision_boundary<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> predict_dec<span class="token punctuation">(</span>parameters<span class="token punctuation">,</span> x<span class="token punctuation">.</span>T<span class="token punctuation">)</span><span class="token punctuation">,</span> train_X<span class="token punctuation">,</span> train_Y<span class="token punctuation">)</span>
        </pre><p><img src="img/QQ%E6%88%AA%E5%9B%BE20200816171649.jpg" alt></p>
        <h5 class="mume-header" id="%E5%85%B3%E4%BA%8Edropout%E4%BD%A0%E9%9C%80%E8%A6%81%E8%AE%B0%E4%BD%8F%E7%9A%84%E6%98%AF"><strong>&#x5173;&#x4E8E;dropout&#x4F60;&#x9700;&#x8981;&#x8BB0;&#x4F4F;&#x7684;&#x662F;:</strong>&#xFF01;&#xFF01;</h5>
        
        <ul>
        <li>Dropout &#x662F;&#x4E00;&#x79CD;&#x6B63;&#x5219;&#x5316;&#x6280;&#x672F;.</li>
        <li>&#x4F60;&#x53EA;&#x9700;&#x5728;&#x8BAD;&#x7EC3;&#x671F;&#x95F4;&#x4F7F;&#x7528;&#x5B83;&#xFF0C;&#x6D4B;&#x8BD5;&#x671F;&#x95F4;&#x4E0D;&#x8981;&#x4F7F;&#x7528;.</li>
        <li>&#x524D;&#x5411;&#x548C;&#x540E;&#x5411;&#x4F20;&#x64AD;&#x90FD;&#x4F1A;&#x4F7F;&#x7528;&#x5230;dropout.</li>
        <li>&#x5728;&#x8BAD;&#x7EC3;&#x671F;&#x95F4;&#xFF0C;&#x901A;&#x8FC7;<code>keep_prob</code>&#x5BF9;&#x6BCF;&#x4E2A;dropout&#x5C42;&#x8FDB;&#x884C;&#x5212;&#x5206;&#xFF0C;&#x4EE5;&#x4FDD;&#x6301;&#x6FC0;&#x6D3B;&#x7684;&#x671F;&#x671B;&#x503C;&#x76F8;&#x540C;&#x3002;&#x4F8B;&#x5982;&#xFF0C;&#x5982;&#x679C;keep prob&#x662F;0.5&#xFF0C;&#x90A3;&#x4E48;&#x6211;&#x4EEC;&#x5C06;&#x5E73;&#x5747;&#x5173;&#x95ED;&#x4E00;&#x534A;&#x7684;&#x8282;&#x70B9;&#xFF0C;&#x56E0;&#x6B64;&#x8F93;&#x51FA;&#x5C06;&#x6309;0.5&#x7684;&#x6BD4;&#x4F8B;&#x7F29;&#x653E;&#xFF0C;&#x56E0;&#x4E3A;&#x53EA;&#x6709;&#x5269;&#x4E0B;&#x7684;&#x4E00;&#x534A;&#x5BF9;&#x89E3;&#x51B3;&#x65B9;&#x6848;&#x6709;&#x8D21;&#x732E;&#x3002;&#x56E0;&#x6B64;&#xFF0C;&#x8F93;&#x51FA;&#x73B0;&#x5728;&#x5177;&#x6709;&#x76F8;&#x540C;&#x7684;&#x671F;&#x671B;&#x503C;&#x3002;&#x60A8;&#x53EF;&#x4EE5;&#x68C0;&#x67E5;&#xFF0C;&#x5373;&#x4F7F;&#x5F53;keep prob&#x662F;&#x5176;&#x4ED6;&#x503C;&#x800C;&#x4E0D;&#x662F;0.5&#x65F6;&#xFF0C;&#x8FD9;&#x4E5F;&#x53EF;&#x4EE5;&#x5DE5;&#x4F5C;&#x3002;</li>
        </ul>
        <h3 class="mume-header" id="%E4%B8%89%E4%B8%AA%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%AF%B9%E6%AF%94%E7%BB%93%E6%9E%9C">&#x4E09;&#x4E2A;&#x6A21;&#x578B;&#x7684;&#x5BF9;&#x6BD4;&#x7ED3;&#x679C;</h3>
        
        <table>
        <thead>
        <tr>
        <th>&#x6A21;&#x578B;&#xFF08;3&#x5C42;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#xFF09;</th>
        <th>&#x8BAD;&#x7EC3;&#x96C6;&#x51C6;&#x786E;&#x7387;</th>
        <th>&#x6D4B;&#x8BD5;&#x96C6;&#x51C6;&#x786E;&#x7387;</th>
        </tr>
        </thead>
        <tbody>
        <tr>
        <td>&#x65E0;&#x6B63;&#x5219;&#x5316;</td>
        <td>95%</td>
        <td>91.5%</td>
        </tr>
        <tr>
        <td>L2&#x6B63;&#x5219;&#x5316;</td>
        <td>94%</td>
        <td>93%</td>
        </tr>
        <tr>
        <td>dropout&#x6B63;&#x5219;&#x5316;</td>
        <td>93%</td>
        <td>95%</td>
        </tr>
        </tbody>
        </table>
        <p>&#x8BF7;&#x6CE8;&#x610F;&#xFF0C;&#x6B63;&#x5219;&#x5316;&#x4F1A;<strong>&#x6709;&#x635F;&#x4F60;&#x8BAD;&#x7EC3;&#x96C6;&#x7684;&#x8868;&#x73B0;</strong>&#xFF01;&#x56E0;&#x4E3A;&#x5B83;&#x4F1A;&#x9650;&#x5236;&#x7F51;&#x7EDC;&#x8FC7;&#x5EA6;&#x62DF;&#x5408;&#x8BAD;&#x7EC3;&#x96C6;&#x7684;&#x80FD;&#x529B;. &#x4F46;&#x662F;&#x5B83;&#x6700;&#x7EC8;&#x4F1A;&#x63D0;&#x9AD8;&#x6D4B;&#x8BD5;&#x96C6;&#x7684;&#x8868;&#x73B0;.</p>
        <h3 class="mume-header" id="%E6%80%BB%E7%BB%93-3">&#x603B;&#x7ED3;</h3>
        
        <ul>
        <li>&#x6B63;&#x5219;&#x5316;&#x80FD;&#x5E2E;&#x52A9;&#x4F60;&#x51CF;&#x5C11;&#x8FC7;&#x62DF;&#x5408;&#x3002;&#x4F1A;&#x63A8;&#x52A8;&#x4F60;&#x7684;&#x6743;&#x91CD;&#x5411;&#x66F4;&#x5C0F;&#x7684;&#x503C;&#x8F6C;&#x53D8;.</li>
        <li>&#x6B63;&#x5219;&#x5316;&#x4F1A;&#x63A8;&#x52A8;&#x4F60;&#x7684;&#x6743;&#x91CD;&#x5411;&#x66F4;&#x5C0F;&#x7684;&#x503C;&#x8F6C;&#x53D8;.</li>
        <li>L2 &#x56DE;&#x5F52; &#x548C; Dropout &#x662F;&#x4E24;&#x79CD;&#x975E;&#x5E38;&#x6709;&#x6548;&#x7684;&#x6B63;&#x5219;&#x5316;&#x6280;&#x672F;.</li>
        </ul>
        <h2 class="mume-header" id="%E6%A2%AF%E5%BA%A6%E6%A3%80%E9%AA%8C-1">&#x68AF;&#x5EA6;&#x68C0;&#x9A8C;</h2>
        
        <p>&#x5047;&#x8BBE;&#x60A8;&#x662F;&#x4E00;&#x4E2A;&#x5728;&#x5168;&#x7403;&#x8303;&#x56F4;&#x5185;&#x5F00;&#x5C55;&#x79FB;&#x52A8;&#x652F;&#x4ED8;&#x7684;&#x56E2;&#x961F;&#x7684;&#x4E00;&#x4EFD;&#x5B50;&#xFF0C;&#x5E76;&#x88AB;&#x8981;&#x6C42;&#x5EFA;&#x7ACB;&#x4E00;&#x4E2A;&#x6DF1;&#x5EA6;&#x5B66;&#x4E60;&#x6A21;&#x5F0F;&#x6765;&#x68C0;&#x6D4B;&#x6B3A;&#x8BC8;&#x884C;&#x4E3A; -- &#x6BCF;&#x5F53;&#x6709;&#x4EBA;&#x4ED8;&#x6B3E;&#x65F6;&#xFF0C;&#x60A8;&#x60F3;&#x8981;&#x67E5;&#x770B;&#x4ED8;&#x6B3E;&#x662F;&#x5426;&#x6709;&#x6B3A;&#x8BC8;&#x884C;&#x4E3A;&#xFF0C;&#x4F8B;&#x5982;&#x7528;&#x6237;&#x5E10;&#x6237;&#x662F;&#x5426;&#x88AB;&#x9ED1;&#x5BA2;&#x5360;&#x7528;&#x3002;</p>
        <p>&#x8FD9;&#x4E2A;&#x6A21;&#x578B;&#x7684;&#x53CD;&#x5411;&#x4F20;&#x64AD;&#x5F88;&#x590D;&#x6742;&#xFF0C;&#x53C8;&#x56E0;&#x4E3A;&#x8FD9;&#x4E2A;&#x5E94;&#x7528;&#x5B9E;&#x5728;&#x592A;&#x91CD;&#x8981;&#xFF0C;&#x6240;&#x4EE5;&#x4F60;&#x88AB;&#x8981;&#x6C42;&#x5411;&#x4F60;&#x516C;&#x53F8;&#x7684;CEO&#x8BC1;&#x660E;&#x4F60;&#x7684;&#x53CD;&#x5411;&#x4F20;&#x64AD;&#x5B9E;&#x9645;&#x4E0A;&#x662F;&#x6B63;&#x786E;&#x7684;&#xFF01;&#x4E3A;&#x4E86;&#x9A8C;&#x8BC1;&#x662F;&#x5426;&#x6B63;&#x786E;&#x6709;&#x6548;&#xFF0C;&#x4F60;&#x4F7F;&#x7528;&#x4E86;&#x68AF;&#x5EA6;&#x68C0;&#x9A8C;(Gradient Checking)&#x3002;</p>
        <h3 class="mume-header" id="%E5%AF%BC%E5%8C%85-1">&#x5BFC;&#x5305;</h3>
        
        <pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment"># Packages</span>
        <span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
        <span class="token keyword">from</span> testCases <span class="token keyword">import</span> <span class="token operator">*</span>
        <span class="token keyword">from</span> gc_utils <span class="token keyword">import</span> sigmoid<span class="token punctuation">,</span> relu<span class="token punctuation">,</span> dictionary_to_vector<span class="token punctuation">,</span> vector_to_dictionary<span class="token punctuation">,</span> gradients_to_vector
        </pre><h3 class="mume-header" id="%E5%8E%9F%E7%90%86">&#x539F;&#x7406;</h3>
        
        <p>&#x53CD;&#x5411;&#x4F20;&#x64AD;&#x9700;&#x8981;&#x8BA1;&#x7B97;&#x68AF;&#x5EA6; <span class="mathjax-exps">$\frac{\partial J}{\partial \theta}$</span>,  &#x5176;&#x4E2D;<span class="mathjax-exps">$\theta$</span> &#x8868;&#x793A;&#x6A21;&#x578B;&#x7684;&#x53C2;&#x6570;. <span class="mathjax-exps">$J$</span> &#x662F;&#x4F7F;&#x7528;&#x524D;&#x5411;&#x4F20;&#x64AD;&#x548C;&#x6210;&#x672C;&#x51FD;&#x6570;&#x8BA1;&#x7B97;&#x7684;&#x3002;</p>
        <p>&#x56E0;&#x4E3A;&#x524D;&#x5411;&#x4F20;&#x64AD;&#x5B9E;&#x73B0;&#x76F8;&#x5BF9;&#x7B80;&#x5355;, &#x6240;&#x4EE5;&#x4F60;&#x786E;&#x4FE1; <span class="mathjax-exps">$J$</span> &#x8BA1;&#x7B97;&#x6B63;&#x786E;. &#x56E0;&#x6B64;&#xFF0C;&#x4F60;&#x7528;&#x4EE3;&#x7801;&#x6765;&#x8BA1;&#x7B97; <span class="mathjax-exps">$J$</span> &#x6765;&#x68C0;&#x9A8C;&#x8BA1;&#x7B97; <span class="mathjax-exps">$\frac{\partial J}{\partial \theta}$</span>&#x7684;&#x4EE3;&#x7801;&#x3002;</p>
        <p>&#x73B0;&#x5728;&#x8BA9;&#x6211;&#x4EEC;&#x56DE;&#x5934;&#x6765;&#x770B;&#x4E00;&#x4E0B;&#x5BFC;&#x6570;&#xFF08;&#x6216;&#x8005;&#x68AF;&#x5EA6;&#xFF09;&#x7684;&#x5B9A;&#x4E49;&#xFF1A;<br>
        </p><div class="mathjax-exps">$$\frac{\partial J}{\partial \theta} = \lim_{\varepsilon \to 0} \frac{J(\theta + \varepsilon) - J(\theta - \varepsilon)}{2 \varepsilon} \tag{1}$$</div><p></p>
        <p>&#x6211;&#x4EEC;&#x77E5;&#x9053;&#x4EE5;&#x4E0B;&#x51E0;&#x70B9;&#xFF1A;</p>
        <ul>
        <li><span class="mathjax-exps">$\frac{\partial J}{\partial \theta}$</span> &#x662F;&#x4F60;&#x60F3;&#x53BB;&#x786E;&#x4FDD;&#x6B63;&#x786E;&#x8BA1;&#x7B97;&#x7684;&#x4E1C;&#x897F;.</li>
        <li>&#x4F60;&#x53EF;&#x4EE5;&#x8BA1;&#x7B97; <span class="mathjax-exps">$J(\theta + \varepsilon)$</span> &#x548C; <span class="mathjax-exps">$J(\theta - \varepsilon)$</span></li>
        </ul>
        <p>&#x8BA9;&#x6211;&#x4EEC;&#x7528;&#x516C;&#x5F0F;&#xFF08;1&#xFF09;&#x548C;&#x4E00;&#x4E2A;&#x8F83;&#x5C0F;&#x7684;&#x503C; <span class="mathjax-exps">$\varepsilon$</span> &#x8BA9;&#x4F60;&#x7684;CEO&#x76F8;&#x4FE1;&#x4F60;&#x8BA1;&#x7B97;<span class="mathjax-exps">$\frac{\partial J}{\partial \theta}$</span>&#x7684;&#x4EE3;&#x7801;&#x662F;&#x6B63;&#x786E;&#x7684;.</p>
        <h3 class="mume-header" id="%E4%B8%80%E7%BB%B4%E6%A2%AF%E5%BA%A6%E6%A3%80%E9%AA%8C">&#x4E00;&#x7EF4;&#x68AF;&#x5EA6;&#x68C0;&#x9A8C;</h3>
        
        <p>&#x8003;&#x8651;&#x4E00;&#x7EF4;&#x7EBF;&#x6027;&#x51FD;&#x6570; <span class="mathjax-exps">$J(\theta) = \theta x$</span>. &#x8BE5;&#x6A21;&#x578B;&#x53EA;&#x5305;&#x542B;&#x4E00;&#x4E2A;&#x5B9E;&#x503C;&#x53C2;&#x6570; <span class="mathjax-exps">$\theta$</span>, &#x5E76;&#x91C7;&#x53D6; <span class="mathjax-exps">$x$</span> &#x4F5C;&#x4E3A;&#x8F93;&#x5165;&#x3002;</p>
        <p>&#x4F60;&#x5C06;&#x5B9E;&#x73B0;&#x4EE3;&#x7801;&#x53BB;&#x8BA1;&#x7B97; <span class="mathjax-exps">$J(.)$</span> &#x548C;&#x5B83;&#x7684;&#x5BFC;&#x6570; <span class="mathjax-exps">$\frac{\partial J}{\partial \theta}$</span>. &#x7136;&#x540E;&#x4F60;&#x5C06;&#x4F7F;&#x7528;&#x201C;Gradient Checking&#x201D;&#x53BB;&#x786E;&#x4FDD;&#x4F60;&#x5173;&#x4E8E;<span class="mathjax-exps">$J$</span> &#x7684;&#x5BFC;&#x6570;&#x8BA1;&#x7B97;&#x662F;&#x6B63;&#x786E;&#x7684;.</p>
        <h4 class="mume-header" id="%E6%AD%A3%E5%90%91%E4%BC%A0%E6%92%AD">&#x6B63;&#x5411;&#x4F20;&#x64AD;</h4>
        
        <pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment"># GRADED FUNCTION: forward_propagation</span>
        
        <span class="token keyword">def</span> <span class="token function">forward_propagation</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> theta<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token triple-quoted-string string">&quot;&quot;&quot;
            Implement the linear forward propagation (compute J) presented in Figure 1 (J(theta) = theta * x)
            
            Arguments:
            x -- a real-valued input
            theta -- our parameter, a real number as well
            
            Returns:
            J -- the value of function J, computed using the formula J(theta) = theta * x
            &quot;&quot;&quot;</span>
            
            <span class="token comment">### START CODE HERE ### (approx. 1 line)</span>
            J <span class="token operator">=</span> theta <span class="token operator">*</span> x
            <span class="token comment">### END CODE HERE ###</span>
            
            <span class="token keyword">return</span> J
        </pre><h5 class="mume-header" id="%E6%B5%8B%E8%AF%95">&#x6D4B;&#x8BD5;</h5>
        
        <pre data-role="codeBlock" data-info="python" class="language-python">x<span class="token punctuation">,</span> theta <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span>
        J <span class="token operator">=</span> forward_propagation<span class="token punctuation">(</span>x<span class="token punctuation">,</span> theta<span class="token punctuation">)</span>
        <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&quot;J = &quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>J<span class="token punctuation">)</span><span class="token punctuation">)</span>
        </pre><pre data-role="codeBlock" data-info class="language-"><code>J = 8
        </code></pre><h4 class="mume-header" id="%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD-1">&#x53CD;&#x5411;&#x4F20;&#x64AD;</h4>
        
        <pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment"># GRADED FUNCTION: backward_propagation</span>
        
        <span class="token keyword">def</span> <span class="token function">backward_propagation</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> theta<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token triple-quoted-string string">&quot;&quot;&quot;
            Computes the derivative of J with respect to theta (see Figure 1).
            
            Arguments:
            x -- a real-valued input
            theta -- our parameter, a real number as well
            
            Returns:
            dtheta -- the gradient of the cost with respect to theta
            &quot;&quot;&quot;</span>
            
            <span class="token comment">### START CODE HERE ### (approx. 1 line)</span>
            dtheta <span class="token operator">=</span> x
            <span class="token comment">### END CODE HERE ###</span>
            
            <span class="token keyword">return</span> dtheta
        </pre><h5 class="mume-header" id="%E6%B5%8B%E8%AF%95-1">&#x6D4B;&#x8BD5;</h5>
        
        <pre data-role="codeBlock" data-info="python" class="language-python">x<span class="token punctuation">,</span> theta <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span>
        dtheta <span class="token operator">=</span> backward_propagation<span class="token punctuation">(</span>x<span class="token punctuation">,</span> theta<span class="token punctuation">)</span>
        <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&quot;dtheta = &quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>dtheta<span class="token punctuation">)</span><span class="token punctuation">)</span>
        </pre><pre data-role="codeBlock" data-info class="language-"><code>dtheta = 2
        </code></pre><h4 class="mume-header" id="%E6%A2%AF%E5%BA%A6%E6%A3%80%E9%AA%8C-2">&#x68AF;&#x5EA6;&#x68C0;&#x9A8C;</h4>
        
        <ul>
        <li>&#x9996;&#x5148;&#xFF0C;&#x4F7F;&#x7528;&#x516C;&#x5F0F; (1) &#x548C;&#x4E00;&#x4E2A;&#x5F88;&#x5C0F;&#x7684;&#x91CF; <span class="mathjax-exps">$\varepsilon$</span>. &#x6B65;&#x9AA4;&#x5982;&#x4E0B;:
        <ol>
        <li><span class="mathjax-exps">$\theta^{+} = \theta + \varepsilon$</span></li>
        <li><span class="mathjax-exps">$\theta^{-} = \theta - \varepsilon$</span></li>
        <li><span class="mathjax-exps">$J^{+} = J(\theta^{+})$</span></li>
        <li><span class="mathjax-exps">$J^{-} = J(\theta^{-})$</span></li>
        <li><span class="mathjax-exps">$gradapprox = \frac{J^{+} - J^{-}}{2  \varepsilon}$</span></li>
        </ol>
        </li>
        <li>&#x7136;&#x540E;&#x4F7F;&#x7528;&#x53CD;&#x5411;&#x4F20;&#x64AD;&#x8BA1;&#x7B97;&#x68AF;&#x5EA6;&#xFF0C;&#x5E76;&#x5C06;&#x7ED3;&#x679C;&#x5B58;&#x50A8;&#x5728;&#x4E00;&#x4E2A;&#x53D8;&#x91CF;&#x201C;grad&#x201D;&#x4E2D;</li>
        <li>&#x6700;&#x540E;&#xFF0C;&#x4F7F;&#x7528;&#x4E0B;&#x9762;&#x7684;&#x516C;&#x5F0F;&#x8BA1;&#x7B97;&#x201C;gradapprox&#x201D;&#x548C;&#x201C;grad&#x201D;&#x4E4B;&#x95F4;&#x7684;&#x76F8;&#x5BF9;&#x5DEE;&#x5F02;<br>
        <div class="mathjax-exps">$$difference = \frac {\mid\mid grad - gradapprox \mid\mid_2}{\mid\mid grad \mid\mid_2 + \mid\mid gradapprox \mid\mid_2}$$</div><br>
        &#x6309;&#x7167;&#x4EE5;&#x4E0B;&#x4E09;&#x6B65;&#x8BA1;&#x7B97;:
        <ul>
        <li>&#x4F7F;&#x7528; <code>np.linalg.norm(...)</code>&#x8BA1;&#x7B97;&#x5206;&#x5B50;</li>
        <li>&#x7528; <code>np.linalg.norm(...)</code>&#x4E24;&#x6B21;&#x6765;&#x8BA1;&#x7B97;&#x5206;&#x6BCD;</li>
        <li>&#x76F8;&#x9664;</li>
        </ul>
        </li>
        <li>&#x5982;&#x679C;&#x5DEE;&#x503C;&#x5C0F;&#x4E8E; <span class="mathjax-exps">$10^{-7}$</span>&#xFF0C;&#x4F60;&#x5C31;&#x53EF;&#x4EE5;&#x786E;&#x4FE1;&#x4F60;&#x7684;&#x6A21;&#x578B;&#x6B63;&#x786E;&#x4E86;&#xFF0C;&#x5982;&#x679C;&#x4E0D;&#x884C;&#xFF0C;&#x53EF;&#x80FD;&#x662F;&#x54EA;&#x91CC;&#x51FA;&#x9519;&#x4E86;&#x3002;</li>
        </ul>
        <pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment"># GRADED FUNCTION: gradient_check</span>
        
        <span class="token keyword">def</span> <span class="token function">gradient_check</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> theta<span class="token punctuation">,</span> epsilon <span class="token operator">=</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token triple-quoted-string string">&quot;&quot;&quot;
            Implement the backward propagation presented in Figure 1.
            
            Arguments:
            x -- a real-valued input
            theta -- our parameter, a real number as well
            epsilon -- tiny shift to the input to compute approximated gradient with formula(1)
            
            Returns:
            difference -- difference (2) between the approximated gradient and the backward propagation gradient
            &quot;&quot;&quot;</span>
            
            <span class="token comment"># Compute gradapprox using left side of formula (1). epsilon is small enough, you don&apos;t need to worry about the limit.</span>
            <span class="token comment">### START CODE HERE ### (approx. 5 lines)</span>
            thetaplus <span class="token operator">=</span> theta <span class="token operator">+</span> epsilon                           <span class="token comment"># Step 1</span>
            thetaminus <span class="token operator">=</span> theta <span class="token operator">-</span> epsilon                          <span class="token comment"># Step 2</span>
            J_plus <span class="token operator">=</span> thetaplus <span class="token operator">*</span> x                                <span class="token comment"># Step 3</span>
            J_minus <span class="token operator">=</span> thetaminus <span class="token operator">*</span> x                              <span class="token comment"># Step 4</span>
            gradapprox <span class="token operator">=</span> <span class="token punctuation">(</span>J_plus <span class="token operator">-</span> J_minus<span class="token punctuation">)</span><span class="token operator">/</span><span class="token punctuation">(</span><span class="token number">2</span> <span class="token operator">*</span> epsilon<span class="token punctuation">)</span>         <span class="token comment"># Step 5</span>
            <span class="token comment">### END CODE HERE ###</span>
            
            <span class="token comment"># &#x68C0;&#x67E5;&#x68AF;&#x5EA6;&#x662F;&#x5426;&#x4E0E;backward_propagation()&#x8F93;&#x51FA;&#x63A5;&#x8FD1;</span>
            <span class="token comment">### START CODE HERE ### (approx. 1 line)</span>
            grad <span class="token operator">=</span> backward_propagation<span class="token punctuation">(</span>x<span class="token punctuation">,</span> theta<span class="token punctuation">)</span>
            <span class="token comment">### END CODE HERE ###</span>
            
            <span class="token comment">### START CODE HERE ### (approx. 1 line)</span>
            numerator <span class="token operator">=</span> np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>grad <span class="token operator">-</span> gradapprox<span class="token punctuation">)</span>                     <span class="token comment"># Step 1&apos;</span>
            denominator <span class="token operator">=</span> np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>grad<span class="token punctuation">)</span> <span class="token operator">+</span> np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>gradapprox<span class="token punctuation">)</span>   <span class="token comment"># Step 2&apos;</span>
            difference <span class="token operator">=</span> numerator <span class="token operator">/</span> denominator                              <span class="token comment"># Step 3&apos;</span>
            <span class="token comment">### END CODE HERE ###</span>
            
            <span class="token keyword">if</span> difference <span class="token operator">&lt;</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">7</span><span class="token punctuation">:</span>
                <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&quot;The gradient is correct!&quot;</span><span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&quot;The gradient is wrong!&quot;</span><span class="token punctuation">)</span>
            
            <span class="token keyword">return</span> difference
        </pre><h5 class="mume-header" id="%E6%B5%8B%E8%AF%95-2">&#x6D4B;&#x8BD5;</h5>
        
        <pre data-role="codeBlock" data-info="python" class="language-python">x<span class="token punctuation">,</span> theta <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span>
        difference <span class="token operator">=</span> gradient_check<span class="token punctuation">(</span>x<span class="token punctuation">,</span> theta<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;difference = &quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>difference<span class="token punctuation">)</span><span class="token punctuation">)</span>
        </pre><pre data-role="codeBlock" data-info class="language-"><code>The gradient is correct!
        difference = 2.919335883291695e-10
        </code></pre><h3 class="mume-header" id="n%E7%BB%B4%E6%A2%AF%E5%BA%A6%E6%A3%80%E9%AA%8C">N&#x7EF4;&#x68AF;&#x5EA6;&#x68C0;&#x9A8C;</h3>
        
        <h4 class="mume-header" id="%E6%AD%A3%E5%90%91%E4%BC%A0%E6%92%AD-1">&#x6B63;&#x5411;&#x4F20;&#x64AD;</h4>
        
        <pre data-role="codeBlock" data-info="python" class="language-python"><span class="token keyword">def</span> <span class="token function">forward_propagation_n</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">,</span> parameters<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token triple-quoted-string string">&quot;&quot;&quot;
            Implements the forward propagation (and computes the cost) presented in Figure 3.
            
            Arguments:
            X -- training set for m examples
            Y -- labels for m examples 
            parameters -- python dictionary containing your parameters &quot;W1&quot;, &quot;b1&quot;, &quot;W2&quot;, &quot;b2&quot;, &quot;W3&quot;, &quot;b3&quot;:
                            W1 -- weight matrix of shape (5, 4)
                            b1 -- bias vector of shape (5, 1)
                            W2 -- weight matrix of shape (3, 5)
                            b2 -- bias vector of shape (3, 1)
                            W3 -- weight matrix of shape (1, 3)
                            b3 -- bias vector of shape (1, 1)
            
            Returns:
            cost -- the cost function (logistic cost for one example)
            &quot;&quot;&quot;</span>
            
            <span class="token comment"># retrieve parameters</span>
            m <span class="token operator">=</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
            W1 <span class="token operator">=</span> parameters<span class="token punctuation">[</span><span class="token string">&quot;W1&quot;</span><span class="token punctuation">]</span>
            b1 <span class="token operator">=</span> parameters<span class="token punctuation">[</span><span class="token string">&quot;b1&quot;</span><span class="token punctuation">]</span>
            W2 <span class="token operator">=</span> parameters<span class="token punctuation">[</span><span class="token string">&quot;W2&quot;</span><span class="token punctuation">]</span>
            b2 <span class="token operator">=</span> parameters<span class="token punctuation">[</span><span class="token string">&quot;b2&quot;</span><span class="token punctuation">]</span>
            W3 <span class="token operator">=</span> parameters<span class="token punctuation">[</span><span class="token string">&quot;W3&quot;</span><span class="token punctuation">]</span>
            b3 <span class="token operator">=</span> parameters<span class="token punctuation">[</span><span class="token string">&quot;b3&quot;</span><span class="token punctuation">]</span>
        
            <span class="token comment"># LINEAR -&gt; RELU -&gt; LINEAR -&gt; RELU -&gt; LINEAR -&gt; SIGMOID</span>
            Z1 <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>W1<span class="token punctuation">,</span> X<span class="token punctuation">)</span> <span class="token operator">+</span> b1
            A1 <span class="token operator">=</span> relu<span class="token punctuation">(</span>Z1<span class="token punctuation">)</span>
            Z2 <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>W2<span class="token punctuation">,</span> A1<span class="token punctuation">)</span> <span class="token operator">+</span> b2
            A2 <span class="token operator">=</span> relu<span class="token punctuation">(</span>Z2<span class="token punctuation">)</span>
            Z3 <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>W3<span class="token punctuation">,</span> A2<span class="token punctuation">)</span> <span class="token operator">+</span> b3
            A3 <span class="token operator">=</span> sigmoid<span class="token punctuation">(</span>Z3<span class="token punctuation">)</span>
        
            <span class="token comment"># Cost</span>
            logprobs <span class="token operator">=</span> np<span class="token punctuation">.</span>multiply<span class="token punctuation">(</span><span class="token operator">-</span>np<span class="token punctuation">.</span>log<span class="token punctuation">(</span>A3<span class="token punctuation">)</span><span class="token punctuation">,</span>Y<span class="token punctuation">)</span> <span class="token operator">+</span> np<span class="token punctuation">.</span>multiply<span class="token punctuation">(</span><span class="token operator">-</span>np<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> A3<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span> <span class="token operator">-</span> Y<span class="token punctuation">)</span>
            cost <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token operator">/</span>m <span class="token operator">*</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>logprobs<span class="token punctuation">)</span>
            
            cache <span class="token operator">=</span> <span class="token punctuation">(</span>Z1<span class="token punctuation">,</span> A1<span class="token punctuation">,</span> W1<span class="token punctuation">,</span> b1<span class="token punctuation">,</span> Z2<span class="token punctuation">,</span> A2<span class="token punctuation">,</span> W2<span class="token punctuation">,</span> b2<span class="token punctuation">,</span> Z3<span class="token punctuation">,</span> A3<span class="token punctuation">,</span> W3<span class="token punctuation">,</span> b3<span class="token punctuation">)</span>
            
            <span class="token keyword">return</span> cost<span class="token punctuation">,</span> cache
        </pre><h4 class="mume-header" id="%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD-2">&#x53CD;&#x5411;&#x4F20;&#x64AD;</h4>
        
        <pre data-role="codeBlock" data-info="python" class="language-python"><span class="token keyword">def</span> <span class="token function">backward_propagation_n</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">,</span> cache<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token triple-quoted-string string">&quot;&quot;&quot;
            Implement the backward propagation presented in figure 2.
            
            Arguments:
            X -- input datapoint, of shape (input size, 1)
            Y -- true &quot;label&quot;
            cache -- cache output from forward_propagation_n()
            
            Returns:
            gradients -- A dictionary with the gradients of the cost with respect to each parameter, activation and pre-activation variables.
            &quot;&quot;&quot;</span>
            
            m <span class="token operator">=</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
            <span class="token punctuation">(</span>Z1<span class="token punctuation">,</span> A1<span class="token punctuation">,</span> W1<span class="token punctuation">,</span> b1<span class="token punctuation">,</span> Z2<span class="token punctuation">,</span> A2<span class="token punctuation">,</span> W2<span class="token punctuation">,</span> b2<span class="token punctuation">,</span> Z3<span class="token punctuation">,</span> A3<span class="token punctuation">,</span> W3<span class="token punctuation">,</span> b3<span class="token punctuation">)</span> <span class="token operator">=</span> cache
            
            dZ3 <span class="token operator">=</span> A3 <span class="token operator">-</span> Y
            dW3 <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token operator">/</span>m <span class="token operator">*</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>dZ3<span class="token punctuation">,</span> A2<span class="token punctuation">.</span>T<span class="token punctuation">)</span>
            db3 <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token operator">/</span>m <span class="token operator">*</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dZ3<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> keepdims <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
            
            dA2 <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>W3<span class="token punctuation">.</span>T<span class="token punctuation">,</span> dZ3<span class="token punctuation">)</span>
            dZ2 <span class="token operator">=</span> np<span class="token punctuation">.</span>multiply<span class="token punctuation">(</span>dA2<span class="token punctuation">,</span> np<span class="token punctuation">.</span>int64<span class="token punctuation">(</span>A2 <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            dW2 <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token operator">/</span>m <span class="token operator">*</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>dZ2<span class="token punctuation">,</span> A1<span class="token punctuation">.</span>T<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">2</span>
            db2 <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token operator">/</span>m <span class="token operator">*</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dZ2<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> keepdims <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
            
            dA1 <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>W2<span class="token punctuation">.</span>T<span class="token punctuation">,</span> dZ2<span class="token punctuation">)</span>
            dZ1 <span class="token operator">=</span> np<span class="token punctuation">.</span>multiply<span class="token punctuation">(</span>dA1<span class="token punctuation">,</span> np<span class="token punctuation">.</span>int64<span class="token punctuation">(</span>A1 <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            dW1 <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token operator">/</span>m <span class="token operator">*</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>dZ1<span class="token punctuation">,</span> X<span class="token punctuation">.</span>T<span class="token punctuation">)</span>
            db1 <span class="token operator">=</span> <span class="token number">4</span><span class="token punctuation">.</span><span class="token operator">/</span>m <span class="token operator">*</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dZ1<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> keepdims <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
            
            gradients <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;dZ3&quot;</span><span class="token punctuation">:</span> dZ3<span class="token punctuation">,</span> <span class="token string">&quot;dW3&quot;</span><span class="token punctuation">:</span> dW3<span class="token punctuation">,</span> <span class="token string">&quot;db3&quot;</span><span class="token punctuation">:</span> db3<span class="token punctuation">,</span>
                         <span class="token string">&quot;dA2&quot;</span><span class="token punctuation">:</span> dA2<span class="token punctuation">,</span> <span class="token string">&quot;dZ2&quot;</span><span class="token punctuation">:</span> dZ2<span class="token punctuation">,</span> <span class="token string">&quot;dW2&quot;</span><span class="token punctuation">:</span> dW2<span class="token punctuation">,</span> <span class="token string">&quot;db2&quot;</span><span class="token punctuation">:</span> db2<span class="token punctuation">,</span>
                         <span class="token string">&quot;dA1&quot;</span><span class="token punctuation">:</span> dA1<span class="token punctuation">,</span> <span class="token string">&quot;dZ1&quot;</span><span class="token punctuation">:</span> dZ1<span class="token punctuation">,</span> <span class="token string">&quot;dW1&quot;</span><span class="token punctuation">:</span> dW1<span class="token punctuation">,</span> <span class="token string">&quot;db1&quot;</span><span class="token punctuation">:</span> db1<span class="token punctuation">}</span>
            
            <span class="token keyword">return</span> gradients
        </pre><p>&#x60A8;&#x5728;&#x6B3A;&#x8BC8;&#x68C0;&#x6D4B;&#x6D4B;&#x8BD5;&#x96C6;&#x4E0A;&#x83B7;&#x5F97;&#x4E86;&#x4E00;&#x4E9B;&#x7ED3;&#x679C;&#xFF0C;&#x4F46;&#x662F;&#x60A8;&#x4E0D;&#x80FD;100%&#x786E;&#x5B9A;&#x60A8;&#x7684;&#x6A21;&#x578B;&#x3002;&#x6CA1;&#x6709;&#x4EBA;&#x662F;&#x5B8C;&#x7F8E;&#x7684;!&#x8BA9;&#x6211;&#x4EEC;&#x5B9E;&#x73B0;&#x68AF;&#x5EA6;&#x68C0;&#x67E5;&#x6765;&#x9A8C;&#x8BC1;&#x4F60;&#x7684;&#x68AF;&#x5EA6;&#x662F;&#x5426;&#x6B63;&#x786E;&#x3002;</p>
        <h3 class="mume-header" id="%E5%8E%9F%E7%90%86-1">&#x539F;&#x7406;</h3>
        
        <p>&#x4F60;&#x60F3;&#x901A;&#x8FC7;&#x6BD4;&#x8F83;&#x68AF;&#x5EA6;&#x548C;&#x5BFC;&#x6570;&#x95F4;&#x7684;&#x5173;&#x7CFB;&#xFF0C;&#x6765;&#x786E;&#x8BA4;&#x81EA;&#x5DF1;&#x7684;&#x6A21;&#x578B;&#x662F;&#x5426;&#x6B63;&#x786E;&#xFF0C;&#x5373;</p>
        <p></p><div class="mathjax-exps">$$\frac{\partial J}{\partial \theta} = \lim_{\varepsilon \to 0} \frac{J(\theta + \varepsilon) - J(\theta - \varepsilon)}{2 \varepsilon}$$</div><p></p>
        <p>&#x3010;&#x8FD9;&#x91CC;&#x7528;&#x4E86;&#x5927;&#x91CF;&#x7684;&#x8BCD;&#x5178;&#x65B9;&#x4FBF;&#x53D6;&#x503C;&#x3011;</p>
        <h4 class="mume-header" id="%E4%BC%AA%E4%BB%A3%E7%A0%81">&#x4F2A;&#x4EE3;&#x7801;</h4>
        
        <p>For each i in num_parameters:</p>
        <ul>
        <li>&#x8BA1;&#x7B97; <code>J_plus[i]</code>:
        <ol>
        <li><span class="mathjax-exps">$\theta^{+}$</span> = <code>np.copy(parameters_values)</code></li>
        <li><span class="mathjax-exps">$\theta^{+}_i$</span> = <span class="mathjax-exps">$\theta^{+}_i + \varepsilon$</span></li>
        <li><span class="mathjax-exps">$J^{+}_i$</span> = <code>forward_propagation_n(x, y, vector_to_dictionary(</code><span class="mathjax-exps">$\theta^{+}$</span><code>))</code>.</li>
        </ol>
        </li>
        <li>&#x8BA1;&#x7B97; <code>J_minus[i]</code>&#x540C;&#x7406;&#xFF0C;&#x5BF9; <span class="mathjax-exps">$\theta^{-}$</span>&#x8FDB;&#x884C;&#x540C;&#x6837;&#x64CD;&#x4F5C;</li>
        <li>&#x8BA1;&#x7B97; <span class="mathjax-exps">$gradapprox[i] = \frac{J^{+}_i - J^{-}_i}{2 \varepsilon}$</span></li>
        </ul>
        <p>&#x56E0;&#x6B64;&#xFF0C;&#x4F60;&#x5F97;&#x5230;&#x4E00;&#x4E2A;&#x5411;&#x91CF;gradapprox&#xFF0C;&#x5176;&#x4E2D;gradapprox[i]&#x662F;&#x5173;&#x4E8E;&#x201C;&#x53C2;&#x6570;&#x503C;[i]&#x201D;&#x7684;&#x68AF;&#x5EA6;&#x7684;&#x8FD1;&#x4F3C;&#x503C;&#x3002;&#x4F60;&#x73B0;&#x5728;&#x53EF;&#x4EE5;&#x6BD4;&#x8F83;&#x8FD9;&#x4E2A;gradapprox&#x77E2;&#x91CF;&#x548C;&#x6765;&#x81EA;&#x53CD;&#x5411;&#x4F20;&#x64AD;&#x7684;&#x68AF;&#x5EA6;&#x77E2;&#x91CF;&#x3002;&#x5C31;&#x50CF;&#x4E00;&#x7EF4;&#x60C5;&#x51B5;(&#x6B65;&#x9AA4;1&#x2019;&#xFF0C;2&#x2019;&#xFF0C;3&#x2019;)&#xFF0C;&#x8BA1;&#x7B97;:<br>
        </p><div class="mathjax-exps">$$difference = \frac {\| grad - gradapprox \|_2}{\| grad \|_2 + \| gradapprox \|_2 }$$</div><p></p>
        <h4 class="mume-header" id="%E4%BB%A3%E7%A0%81">&#x4EE3;&#x7801;</h4>
        
        <pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment"># GRADED FUNCTION: gradient_check_n</span>
        
        <span class="token keyword">def</span> <span class="token function">gradient_check_n</span><span class="token punctuation">(</span>parameters<span class="token punctuation">,</span> gradients<span class="token punctuation">,</span> X<span class="token punctuation">,</span> Y<span class="token punctuation">,</span> epsilon <span class="token operator">=</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token triple-quoted-string string">&quot;&quot;&quot;
            Checks if backward_propagation_n computes correctly the gradient of the cost output by forward_propagation_n
            
            Arguments:
            parameters -- python dictionary containing your parameters &quot;W1&quot;, &quot;b1&quot;, &quot;W2&quot;, &quot;b2&quot;, &quot;W3&quot;, &quot;b3&quot;:
            grad -- output of backward_propagation_n, contains gradients of the cost with respect to the parameters. 
            x -- input datapoint, of shape (input size, 1)
            y -- true &quot;label&quot;
            epsilon -- tiny shift to the input to compute approximated gradient with formula(1)
            
            Returns:
            difference -- difference (2) between the approximated gradient and the backward propagation gradient
            &quot;&quot;&quot;</span>
            
            <span class="token comment"># Set-up variables</span>
            parameters_values<span class="token punctuation">,</span> _ <span class="token operator">=</span> dictionary_to_vector<span class="token punctuation">(</span>parameters<span class="token punctuation">)</span>
            grad <span class="token operator">=</span> gradients_to_vector<span class="token punctuation">(</span>gradients<span class="token punctuation">)</span>
            num_parameters <span class="token operator">=</span> parameters_values<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            J_plus <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>num_parameters<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            J_minus <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>num_parameters<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            gradapprox <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>num_parameters<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            
            <span class="token comment"># Compute gradapprox</span>
            <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_parameters<span class="token punctuation">)</span><span class="token punctuation">:</span>
                
                <span class="token comment"># Compute J_plus[i]. Inputs: &quot;parameters_values, epsilon&quot;. Output = &quot;J_plus[i]&quot;.</span>
                <span class="token comment"># &quot;_&quot; is used because the function you have to outputs two parameters but we only care about the first one</span>
                <span class="token comment">### START CODE HERE ### (approx. 3 lines)</span>
                thetaplus <span class="token operator">=</span> np<span class="token punctuation">.</span>copy<span class="token punctuation">(</span>parameters_values<span class="token punctuation">)</span>                                         <span class="token comment"># Step 1</span>
                thetaplus<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> thetaplus<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> epsilon                                    <span class="token comment"># Step 2</span>
                J_plus<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> _ <span class="token operator">=</span> forward_propagation_n<span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">,</span> vector_to_dictionary<span class="token punctuation">(</span>thetaplus<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment"># Step 3</span>
                <span class="token comment">### END CODE HERE ###</span>
                
                <span class="token comment"># Compute J_minus[i]. Inputs: &quot;parameters_values, epsilon&quot;. Output = &quot;J_minus[i]&quot;.</span>
                <span class="token comment">### START CODE HERE ### (approx. 3 lines)</span>
                thetaminus <span class="token operator">=</span> np<span class="token punctuation">.</span>copy<span class="token punctuation">(</span>parameters_values<span class="token punctuation">)</span>                                     <span class="token comment"># Step 1</span>
                thetaminus<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> thetaminus<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">-</span> epsilon                               <span class="token comment"># Step 2        </span>
                J_minus<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> _ <span class="token operator">=</span> forward_propagation_n<span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">,</span> vector_to_dictionary<span class="token punctuation">(</span>thetaminus<span class="token punctuation">)</span><span class="token punctuation">)</span>                                  <span class="token comment"># Step 3</span>
                <span class="token comment">### END CODE HERE ###</span>
                
                <span class="token comment"># Compute gradapprox[i]</span>
                <span class="token comment">### START CODE HERE ### (approx. 1 line)</span>
                gradapprox<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span>J_plus<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">-</span> J_minus<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">2</span> <span class="token operator">*</span> epsilon<span class="token punctuation">)</span>
                <span class="token comment">### END CODE HERE ###</span>
            
            <span class="token comment"># Compare gradapprox to backward propagation gradients by computing difference.</span>
            <span class="token comment">### START CODE HERE ### (approx. 1 line)</span>
            numerator <span class="token operator">=</span> np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>gradapprox <span class="token operator">-</span> grad<span class="token punctuation">)</span>                                <span class="token comment"># Step 1&apos;</span>
            denominator <span class="token operator">=</span> np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>grad<span class="token punctuation">)</span> <span class="token operator">+</span> np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>gradapprox<span class="token punctuation">)</span>              <span class="token comment"># Step 2&apos;</span>
            difference <span class="token operator">=</span> numerator <span class="token operator">/</span> denominator                                         <span class="token comment"># Step 3&apos;</span>
            <span class="token comment">### END CODE HERE ###</span>
        
            <span class="token keyword">if</span> difference <span class="token operator">&gt;</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">7</span><span class="token punctuation">:</span>
                <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&quot;\033[93m&quot;</span> <span class="token operator">+</span> <span class="token string">&quot;There is a mistake in the backward propagation! difference = &quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>difference<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">&quot;\033[0m&quot;</span><span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&quot;\033[92m&quot;</span> <span class="token operator">+</span> <span class="token string">&quot;Your backward propagation works perfectly fine! difference = &quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>difference<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">&quot;\033[0m&quot;</span><span class="token punctuation">)</span>
            
            <span class="token keyword">return</span> difference
        </pre><pre data-role="codeBlock" data-info="python" class="language-python">X<span class="token punctuation">,</span> Y<span class="token punctuation">,</span> parameters <span class="token operator">=</span> gradient_check_n_test_case<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
        cost<span class="token punctuation">,</span> cache <span class="token operator">=</span> forward_propagation_n<span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">,</span> parameters<span class="token punctuation">)</span>
        gradients <span class="token operator">=</span> backward_propagation_n<span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">,</span> cache<span class="token punctuation">)</span>
        difference <span class="token operator">=</span> gradient_check_n<span class="token punctuation">(</span>parameters<span class="token punctuation">,</span> gradients<span class="token punctuation">,</span> X<span class="token punctuation">,</span> Y<span class="token punctuation">)</span>
        </pre><h5 class="mume-header" id="%E7%BB%93%E6%9E%9C-1">&#x7ED3;&#x679C;</h5>
        
        <pre data-role="codeBlock" data-info class="language-"><code>There is a mistake in the backward propagation! difference = 0.285093156776
        </code></pre><p>&#x770B;&#x8D77;&#x6765;&#x6211;&#x4EEC;&#x7ED9;&#x4F60;&#x7684;<code>backward_propagation_n</code>&#x91CC;&#x6709;&#x9519;&#x8BEF;&#xFF01;&#x8FD9;&#x8BF4;&#x660E;&#x4F60;&#x5DF2;&#x7ECF;&#x5F88;&#x597D;&#x7684;&#x5B9E;&#x8DF5;&#x4E86;&#x68AF;&#x5EA6;&#x68C0;&#x9A8C;&#x3002;</p>
        <p>It seems that there were errors in the <code>backward_propagation_n</code> code we gave you! Good that you&apos;ve implemented the gradient check. Go back to <code>backward_propagation</code> and try to find/correct the errors <em>(Hint: check dW2 and db1)</em>. Rerun the gradient check when you think you&apos;ve fixed it. Remember you&apos;ll need to re-execute the cell defining <code>backward_propagation_n()</code> if you modify the code.</p>
        <h4 class="mume-header" id="%E6%B3%A8%E6%84%8F-2">&#x6CE8;&#x610F;</h4>
        
        <ul>
        <li>&#x68AF;&#x5EA6;&#x68C0;&#x9A8C;&#x662F;&#x5F88;&#x6162;&#x7684;! &#x8FD1;&#x4F3C;&#x8BA1;&#x7B97;&#x68AF;&#x5EA6;<span class="mathjax-exps">$\frac{\partial J}{\partial \theta} \approx  \frac{J(\theta + \varepsilon) - J(\theta - \varepsilon)}{2 \varepsilon}$</span> &#x7B97;&#x529B;&#x82B1;&#x8D39;&#x5F88;&#x5927;&#x3002;&#x6240;&#x4EE5;&#x6211;&#x4EEC;&#x4E0D;&#x53EF;&#x80FD;&#x6BCF;&#x6B21;&#x8BAD;&#x7EC3;&#x8FED;&#x4EE3;&#x90FD;&#x8DD1;&#xFF0C;&#x53EA;&#x80FD;&#x68C0;&#x6D4B;&#x8981;&#x70B9;&#x3002;</li>
        <li>dropout&#x56DE;&#x5F52;&#x4E0B;&#xFF0C;&#x4E0D;&#x80FD;&#x8FDB;&#x884C;&#x68AF;&#x5EA6;&#x68C0;&#x9A8C;&#x3002;&#x4FDD;&#x8BC1;&#x6B63;&#x786E;&#x540E;&#x518D;&#x52A0;&#x5165;dropout&#x3002;</li>
        </ul>
        <h4 class="mume-header" id="%E6%80%BB%E7%BB%93-4">&#x603B;&#x7ED3;</h4>
        
        <ul>
        <li>&#x68AF;&#x5EA6;&#x68C0;&#x67E5;&#x9A8C;&#x8BC1;&#x4E86;&#x6765;&#x81EA;&#x53CD;&#x5411;&#x4F20;&#x64AD;&#x7684;&#x68AF;&#x5EA6;&#x548C;&#x68AF;&#x5EA6;&#x7684;&#x6570;&#x503C;&#x8FD1;&#x4F3C;(&#x7528;&#x6B63;&#x5411;&#x4F20;&#x64AD;&#x8BA1;&#x7B97;)&#x4E4B;&#x95F4;&#x7684;&#x7D27;&#x5BC6;&#x6027;&#x3002;</li>
        <li>&#x68AF;&#x5EA6;&#x68C0;&#x67E5;&#x5F88;&#x6162;&#xFF0C;&#x6240;&#x4EE5;&#x6211;&#x4EEC;&#x4E0D;&#x4F1A;&#x5728;&#x6BCF;&#x6B21;&#x8FED;&#x4EE3;&#x8BAD;&#x7EC3;&#x65F6;&#x90FD;&#x8FD0;&#x884C;&#x5B83;&#x3002;&#x60A8;&#x901A;&#x5E38;&#x53EA;&#x4F1A;&#x8FD0;&#x884C;&#x5B83;&#x4EE5;&#x786E;&#x4FDD;&#x60A8;&#x7684;&#x4EE3;&#x7801;&#x662F;&#x6B63;&#x786E;&#x7684;&#xFF0C;&#x7136;&#x540E;&#x5173;&#x95ED;&#x5B83;&#x5E76;&#x5728;&#x5B9E;&#x9645;&#x5B66;&#x4E60;&#x8FC7;&#x7A0B;&#x4E2D;&#x4F7F;&#x7528;backprop&#x3002;</li>
        </ul>
        <h2 class="mume-header" id="%E6%80%BB%E7%BB%93-5">&#x603B;&#x7ED3;</h2>
        
        <h3 class="mume-header" id="%E8%AF%BE%E7%A8%8B">&#x8BFE;&#x7A0B;</h3>
        
        <p>&#x8FD9;&#x8282;&#x8BFE;&#x6211;&#x4EEC;&#x4E3B;&#x8981;&#x4ECB;&#x7ECD;&#x4E86;&#x5982;&#x4F55;&#x5EFA;&#x7ACB;&#x4E00;&#x4E2A;&#x5B9E;&#x7528;&#x7684;&#x6DF1;&#x5EA6;&#x5B66;&#x4E60;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x3002;&#x5305;&#x62EC;Train/Dev/Test sets&#x7684;&#x6BD4;&#x4F8B;&#x9009;&#x62E9;&#xFF0C;Bias&#x548C;Variance&#x7684;&#x6982;&#x5FF5;&#x548C;&#x533A;&#x522B;&#xFF1A;Bias&#x5BF9;&#x5E94;&#x6B20;&#x62DF;&#x5408;&#xFF0C;Variance&#x5BF9;&#x5E94;&#x8FC7;&#x62DF;&#x5408;&#x3002;</p>
        <p>&#x63A5;&#x7740;&#xFF0C;&#x6211;&#x4EEC;&#x4ECB;&#x7ECD;&#x4E86;&#x9632;&#x6B62;&#x8FC7;&#x62DF;&#x5408;&#x7684;&#x4E24;&#x79CD;&#x65B9;&#x6CD5;&#xFF1A;L2&#x56DE;&#x5F52;&#x548C;Dropout&#x3002;</p>
        <p>&#x7136;&#x540E;&#xFF0C;&#x4ECB;&#x7ECD;&#x4E86;&#x5982;&#x4F55;&#x8FDB;&#x884C;&#x89C4;&#x8303;&#x5316;&#x8F93;&#x5165;&#xFF0C;&#x4EE5;&#x52A0;&#x5FEB;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x901F;&#x5EA6;&#x548C;&#x7CBE;&#x5EA6;&#x3002;</p>
        <p>&#x7136;&#x540E;&#xFF0C;&#x6211;&#x4EEC;&#x4ECB;&#x7ECD;&#x4E86;&#x68AF;&#x5EA6;&#x6D88;&#x5931;&#x548C;&#x68AF;&#x5EA6;&#x7206;&#x70B8;&#x7684;&#x6982;&#x5FF5;&#x548C;&#x5371;&#x5BB3;&#xFF0C;&#x5E76;&#x63D0;&#x51FA;&#x4E86;&#x5982;&#x4F55;&#x4F7F;&#x7528;&#x68AF;&#x5EA6;&#x521D;&#x59CB;&#x5316;&#x6765;&#x964D;&#x4F4E;&#x8FD9;&#x79CD;&#x98CE;&#x9669;&#x3002;</p>
        <p>&#x6700;&#x540E;&#xFF0C;&#x6211;&#x4EEC;&#x4ECB;&#x7ECD;&#x4E86;&#x68AF;&#x5EA6;&#x68C0;&#x67E5;&#xFF0C;&#x6765;&#x9A8C;&#x8BC1;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x7B97;&#x6CD5;&#x662F;&#x5426;&#x6B63;&#x786E;&#x3002;</p>
        
              </div>
          </main>
        </div>
      </div>

    </body></html>