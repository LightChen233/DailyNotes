<!DOCTYPE html>
<html>
  <head>
      <title>Emojify</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      
        <script type="text/x-mathjax-config">
          MathJax.Hub.Config({"extensions":["tex2jax.js"],"jax":["input/TeX","output/HTML-CSS"],"messageStyle":"none","tex2jax":{"processEnvironments":false,"processEscapes":true,"inlineMath":[["$","$"],["\\(","\\)"]],"displayMath":[["$$","$$"],["\\[","\\]"]]},"TeX":{"extensions":["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]},"HTML-CSS":{"availableFonts":["TeX"]}});
        </script>
        <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"></script>
        <link rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.3.1/css/bootstrap.min.css">
        <script src="https://cdn.staticfile.org/jquery/3.2.1/jquery.min.js"></script>
        <script src="https://cdn.staticfile.org/twitter-bootstrap/4.3.1/js/bootstrap.min.js"></script>
      <style>
      /**
 * prism.js Github theme based on GitHub's theme.
 * @author Sam Clarke
 */
code[class*="language-"],
pre[class*="language-"] {
  color: #333;
  background: none;
  font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.4;

  -moz-tab-size: 8;
  -o-tab-size: 8;
  tab-size: 8;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

/* Code blocks */
pre[class*="language-"] {
  padding: .8em;
  overflow: auto;
  /* border: 1px solid #ddd; */
  border-radius: 3px;
  /* background: #fff; */
  background: #f5f5f5;
}

/* Inline code */
:not(pre) > code[class*="language-"] {
  padding: .1em;
  border-radius: .3em;
  white-space: normal;
  background: #f5f5f5;
}

.token.comment,
.token.blockquote {
  color: #969896;
}

.token.cdata {
  color: #183691;
}

.token.doctype,
.token.punctuation,
.token.variable,
.token.macro.property {
  color: #333;
}

.token.operator,
.token.important,
.token.keyword,
.token.rule,
.token.builtin {
  color: #a71d5d;
}

.token.string,
.token.url,
.token.regex,
.token.attr-value {
  color: #183691;
}

.token.property,
.token.number,
.token.boolean,
.token.entity,
.token.atrule,
.token.constant,
.token.symbol,
.token.command,
.token.code {
  color: #0086b3;
}

.token.tag,
.token.selector,
.token.prolog {
  color: #63a35c;
}

.token.function,
.token.namespace,
.token.pseudo-element,
.token.class,
.token.class-name,
.token.pseudo-class,
.token.id,
.token.url-reference .token.variable,
.token.attr-name {
  color: #795da3;
}

.token.entity {
  cursor: help;
}

.token.title,
.token.title .token.punctuation {
  font-weight: bold;
  color: #1d3e81;
}

.token.list {
  color: #ed6a43;
}

.token.inserted {
  background-color: #eaffea;
  color: #55a532;
}

.token.deleted {
  background-color: #ffecec;
  color: #bd2c00;
}

.token.bold {
  font-weight: bold;
}

.token.italic {
  font-style: italic;
}


/* JSON */
.language-json .token.property {
  color: #183691;
}

.language-markup .token.tag .token.punctuation {
  color: #333;
}

/* CSS */
code.language-css,
.language-css .token.function {
  color: #0086b3;
}

/* YAML */
.language-yaml .token.atrule {
  color: #63a35c;
}

code.language-yaml {
  color: #183691;
}

/* Ruby */
.language-ruby .token.function {
  color: #333;
}

/* Markdown */
.language-markdown .token.url {
  color: #795da3;
}

/* Makefile */
.language-makefile .token.symbol {
  color: #795da3;
}

.language-makefile .token.variable {
  color: #183691;
}

.language-makefile .token.builtin {
  color: #0086b3;
}

/* Bash */
.language-bash .token.keyword {
  color: #0086b3;
}

/* highlight */
pre[data-line] {
  position: relative;
  padding: 1em 0 1em 3em;
}
pre[data-line] .line-highlight-wrapper {
  position: absolute;
  top: 0;
  left: 0;
  background-color: transparent;
  display: block;
  width: 100%;
}

pre[data-line] .line-highlight {
  position: absolute;
  left: 0;
  right: 0;
  padding: inherit 0;
  margin-top: 1em;
  background: hsla(24, 20%, 50%,.08);
  background: linear-gradient(to right, hsla(24, 20%, 50%,.1) 70%, hsla(24, 20%, 50%,0));
  pointer-events: none;
  line-height: inherit;
  white-space: pre;
}

pre[data-line] .line-highlight:before, 
pre[data-line] .line-highlight[data-end]:after {
  content: attr(data-start);
  position: absolute;
  top: .4em;
  left: .6em;
  min-width: 1em;
  padding: 0 .5em;
  background-color: hsla(24, 20%, 50%,.4);
  color: hsl(24, 20%, 95%);
  font: bold 65%/1.5 sans-serif;
  text-align: center;
  vertical-align: .3em;
  border-radius: 999px;
  text-shadow: none;
  box-shadow: 0 1px white;
}

pre[data-line] .line-highlight[data-end]:after {
  content: attr(data-end);
  top: auto;
  bottom: .4em;
}html body{font-family:"Helvetica Neue",Helvetica,"Segoe UI",Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ul,html body>ol{margin-bottom:16px}html body ul,html body ol{padding-left:2em}html body ul.no-list,html body ol.no-list{padding:0;list-style-type:none}html body ul ul,html body ul ol,html body ol ol,html body ol ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;background-color:#f0f0f0;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:bold;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:bold}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em !important;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::before,html body code::after{letter-spacing:-0.2em;content:"\00a0"}html body pre>code{padding:0;margin:0;font-size:.85em !important;word-break:normal;white-space:pre;background:transparent;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;font-size:.85em !important;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:before,html body pre tt:before,html body pre code:after,html body pre tt:after{content:normal}html body p,html body blockquote,html body ul,html body ol,html body dl,html body pre{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body pre,html body code{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview .pagebreak,.markdown-preview .newpage{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center !important}.markdown-preview:not([for="preview"]) .code-chunk .btn-group{display:none}.markdown-preview:not([for="preview"]) .code-chunk .status{display:none}.markdown-preview:not([for="preview"]) .code-chunk .output-div{margin-bottom:16px}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for="html-export"]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0}@media screen and (min-width:914px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px + 2em)}}@media screen and (max-width:914px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{font-size:14px !important;padding:1em}}@media print{html body[for="html-export"]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for="html-export"]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,0.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc ul{padding:0 1.6em;margin-top:.8em}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc li{margin-bottom:.8em}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc ul{list-style-type:none}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% -  300px);padding:2em calc(50% - 457px -  150px);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for="html-export"]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for="html-export"]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */

      </style>
    </head>
    <body for="html-export">
      <nav class="navbar navbar-expand-sm bg-dark navbar-dark fixed-top">
        <!-- Brand -->
        <img src="../logo.jpg">
      
        <!-- Links -->
        <ul class="navbar-nav">
          <li class="nav-item dropdown">
            <a class="nav-link" href="../index.html">主页</a>
          </li>
          <li class="nav-item dropdown">
            <a class="nav-link" href="../PyTorch.html">Pytorch</a>
          </li>
          <li class="nav-item dropdown">
            <a class="nav-link" href="../DeepLearning/DeepNetwork.html">人工智能</a>
          </li>
        </ul>
      </nav>
      <br>
      <br>
      <br>
      <div class="container-fluid">
        <div class="row">
          <nav class="col-md-2 d-none d-md-block bg-light sidebar fixed-bottom">
          <div class="sidebar-sticky">
            <ul class="nav flex-column">
              <li class="nav-item">
                <a class="nav-link active" href="#">
                  深层神经网络前馈
                </a>
              </li>
              <li class="nav-item">
                <a class="nav-link" href="#">
                  搭建神经网络块
                </a>
              </li>
              <li class="nav-item">
                <a class="nav-link" href="#">
                  参数/超参数
                </a>
              </li>
            </ul>
            <br><br><br><br><br><br><br><br><br><br>
            <br><br><br><br><br><br><br><br><br><br>
          </div>
          </nav>
          <main role="main" class="col-md-9 ml-sm-auto col-lg-10 pt-3 px-4">
            <div class="mume markdown-preview  ">
              <h1 class="mume-header" id="%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">&#x6DF1;&#x5C42;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;</h1>
        
        <img src="img/QQ&#x622A;&#x56FE;20200810201510.jpg" style="zoom:50%;">
        <h3 class="mume-header" id="%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%89%8D%E9%A6%88">&#x6DF1;&#x5C42;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x524D;&#x9988;</h3>
        
        <p><span class="mathjax-exps">$X:z[i]=W[i]*A[i-1]+b[i]$</span></p>
        <p><span class="mathjax-exps">$A[i]=g[i](z[i])$</span></p>
        <p>&#x6700;&#x7EC8;&#x7ED3;&#x679C;&#xFF1A;<span class="mathjax-exps">$\hat Y=g(z[n])=A[n]$</span></p>
        <h3 class="mume-header" id="debug%E6%8A%80%E5%B7%A7">Debug&#x6280;&#x5DE7;</h3>
        
        <p>&#x5224;&#x65AD;&#x5411;&#x91CF;&#x7EF4;&#x6570;&#x3002;</p>
        <p>&#x5DF2;&#x77E5;&#x3010;X&#x53EF;&#x4EE5;&#x662F;&#x8F93;&#x5165;&#xFF0C;&#x4E5F;&#x53EF;&#x4EE5;&#x662F;&#x4E0A;&#x4E00;&#x5C42;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x7684;&#x8F93;&#x51FA;&#xFF0C;&#x672C;&#x5C42;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x7684;&#x8F93;&#x5165;&#x3002;&#x3011;</p>
        <p><span class="mathjax-exps">$X:(n^{[i-1]},1)$</span>&#xFF0C;<span class="mathjax-exps">$Z:(n^{[i]},1)$</span></p>
        <p>&#x7531;&#x4E8E;<span class="mathjax-exps">$z^{[i]}=W^{[i]}X+b^{[i]}$</span></p>
        <p><span class="mathjax-exps">$W^{[i]}:(n^{[i]},n^{[i-1]})$</span></p>
        <p><span class="mathjax-exps">$dW^{[i]}:(n^{[i]},n^{[i-1]})$</span></p>
        <p><span class="mathjax-exps">$b^{[i]}:(n^{[i]},1)$</span></p>
        <p><span class="mathjax-exps">$db^{[i]}:(n^{[i]},1)$</span></p>
        <h3 class="mume-header" id="%E4%BC%98%E7%82%B9%E5%92%8C%E7%94%A8%E5%A4%84">&#x4F18;&#x70B9;&#x548C;&#x7528;&#x5904;</h3>
        
        <p>&#x9996;&#x5148;&#xFF0C;&#x6DF1;&#x5EA6;&#x5B66;&#x4E60;&#x7F51;&#x7EDC;&#x5728;&#x5E72;&#x4EC0;&#x4E48;&#xFF1F;</p>
        <p>&#x5982;&#x679C;&#x4F60;&#x5728;&#x5EFA;&#x4E00;&#x4E2A;&#x4EBA;&#x8138;&#x8BC6;&#x522B;&#x6216;&#x662F;&#x4EBA;&#x8138;&#x68C0;&#x6D4B;&#x7CFB;&#x7EDF;&#xFF0C;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x505A;&#x7684;&#x5C31;&#x662F;&#xFF0C;&#x5F53;&#x4F60;&#x8F93;&#x5165;&#x4E00;&#x5F20;&#x56FE;&#x7247;&#xFF0C;&#x4F60;&#x53EF;&#x4EE5;&#x628A;&#x7B2C;&#x4E00;&#x5C42;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x5F53;&#x6210;&#x4E00;&#x4E2A;&#x7279;&#x5F81;&#x63A2;&#x6D4B;&#x5668;&#xFF0C;&#x6216;&#x8005;&#x8FB9;&#x7F18;&#x63A2;&#x6D4B;&#x5668;&#x3002;&#x3010;&#x8FB9;&#x7F18;&#x63A2;&#x6D4B;&#x5668;&#x5176;&#x5B9E;&#x76F8;&#x5BF9;&#x6765;&#x8BF4;&#x90FD;&#x662F;&#x9488;&#x5BF9;&#x7167;&#x7247;&#x4E2D;&#x975E;&#x5E38;&#x5C0F;&#x7684;&#x9762;&#x79EF;&#x3002;&#x3011;</p>
        <p>&#x4F8B;&#x5B50;&#x4E2D;&#x6709;20&#x4E2A;&#x9690;&#x85CF;&#x5355;&#x5143;&#x3002;&#x628A;&#x8FD9;&#x4E9B;&#x63A2;&#x6D4B;&#x5230;&#x7684;&#x8FB9;&#x7F18;&#x7EC4;&#x5408;&#x5230;&#x4E00;&#x8D77;&#x5C31;&#x53EF;&#x4EE5;&#x5F00;&#x59CB;&#x68C0;&#x6D4B;&#x4EBA;&#x8138;&#x7684;&#x4E0D;&#x540C;&#x90E8;&#x5206;&#x3002;&#x6BD4;&#x5982;&#x8BF4;&#x6709;&#x4E00;&#x4E2A;&#x795E;&#x7ECF;&#x5143;&#x4E13;&#x95E8;&#x627E;&#x773C;&#x775B;&#x7684;&#x90E8;&#x5206;&#xFF0C;&#x53E6;&#x5916;&#x8FD8;&#x6709;&#x522B;&#x7684;&#x5728;&#x627E;&#x9F3B;&#x5B50;&#x7684;&#x90E8;&#x5206;&#x3002;&#x6700;&#x540E;&#x628A;&#x6240;&#x6709;&#x5668;&#x5B98;&#x62FC;&#x5728;&#x4E00;&#x8D77;&#xFF0C;&#x6BD4;&#x5982;&#x9F3B;&#x5B50;&#x773C;&#x775B;&#x4E0B;&#x5DF4;&#xFF0C;&#x5C31;&#x53EF;&#x4EE5;&#x8BC6;&#x522B;&#x6216;&#x662F;&#x63A2;&#x6D4B;&#x4E0D;&#x540C;&#x7684;&#x4EBA;&#x8138;&#x4E86;&#x3002;</p>
        <p><img src="img/QQ%E6%88%AA%E5%9B%BE20200808160112.jpg" alt></p>
        <p>&#x8FD9;&#x79CD;&#x4ECE;&#x7B80;&#x5355;&#x5230;&#x590D;&#x6742;&#x7684;&#x91D1;&#x5B57;&#x5854;&#x72B6;&#x8868;&#x793A;&#x65B9;&#x6CD5;&#x6216;&#x7279;&#x5F81;&#x65B9;&#x6CD5;&#x4E5F;&#x53EF;&#x4EE5;&#x5E94;&#x7528;&#x5728;&#x56FE;&#x50CF;&#x6216;&#x8005;&#x4EBA;&#x8138;&#x8BC6;&#x522B;&#x4EE5;&#x5916;&#x7684;&#x5176;&#x4ED6;&#x6570;&#x636E;&#x4E0A;&#x3002;</p>
        <p>&#x6BD4;&#x5982;&#x8BF4;&#x4F60;&#x60F3;&#x8981;&#x7684;&#x642D;&#x5EFA;&#x4E00;&#x4E2A;&#x8BED;&#x97F3;&#x8BC6;&#x522B;&#x7CFB;&#x7EDF;&#x7684;&#x65F6;&#x5019;&#xFF0C;&#x9700;&#x8981;&#x89E3;&#x51B3;&#x7684;&#x5C31;&#x662F;&#x5982;&#x4F55;&#x53EF;&#x89C6;&#x5316;&#x8BED;&#x97F3;&#xFF0C;&#x6BD4;&#x5982;&#x4F60;&#x8F93;&#x5165;&#x4E00;&#x4E2A;&#x97F3;&#x9891;&#x7247;&#x6BB5;&#xFF0C;&#x90A3;&#x4E48;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x7684;&#x7B2C;&#x4E00;&#x5C42;&#x5C31;&#x4F1A;&#x53BB;&#x5148;&#x5F00;&#x59CB;&#x8BD5;&#x7740;&#x63A2;&#x6D4B;<strong>&#x8F83;&#x4F4E;&#x5C42;&#x6B21;</strong>&#x7684;&#x97F3;&#x9891;&#x6CE2;&#x5F62;&#x7684;&#x4E00;&#x4E9B;&#x7279;&#x5F81;&#xFF0C;&#x6BD4;&#x5982;&#x97F3;&#x8C03;&#x9AD8;&#x4F4E;&#x554A;&#xFF0C;&#x767D;&#x566A;&#x97F3;&#x554A;&#xFF0C;&#x5636;&#x5636;&#x5636;&#x7684;&#x58F0;&#x97F3;&#x7B49;&#x7B49;&#x3002;&#x53EF;&#x4EE5;&#x9009;&#x62E9;&#x8FD9;&#x4E9B;&#x76F8;&#x5BF9;&#x7A0B;&#x5EA6;&#x6BD4;&#x8F83;&#x4F4E;&#x7684;&#x6CE2;&#x6027;&#x7279;&#x5F81;&#xFF0C;&#x7136;&#x540E;&#x628A;&#x8FD9;&#x4E9B;&#x6CE2;&#x5F62;&#x7EC4;&#x5408;&#x5728;&#x4E00;&#x8D77;&#xFF0C;&#x5C31;&#x80FD;&#x53BB;&#x63A2;&#x6D4B;&#x58F0;&#x97F3;&#x7684;&#x57FA;&#x672C;&#x5355;&#x5143;&#xFF0C;&#x5373;&#x97F3;&#x4F4D;&#x3002;&#x5728;&#x7EC4;&#x5408;&#x8D77;&#x6765;&#xFF0C;&#x4F60;&#x5C31;&#x80FD;&#x8BC6;&#x522B;&#x97F3;&#x9891;&#x5F53;&#x4E2D;&#x7684;&#x5355;&#x8BCD;&#xFF0C;&#x518D;&#x5230;&#x8BCD;&#x7EC4;&#xFF0C;&#x518D;&#x5230;&#x53E5;&#x5B50;&#x3002;<strong>&#x628A;&#x7B80;&#x5355;&#x7684;&#x7279;&#x5F81;&#x4E00;&#x6B65;&#x6B65;&#x7EC4;&#x5408;&#x6210;&#x66F4;&#x52A0;&#x590D;&#x6742;&#x7684;&#x4E1C;&#x897F;&#x3002;</strong></p>
        <h3 class="mume-header" id="%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%BA%E4%BD%95%E6%9C%89%E6%95%88">&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x4E3A;&#x4F55;&#x6709;&#x6548;</h3>
        
        <p>&#x6765;&#x6E90;&#x4E8E;&#x7535;&#x8DEF;&#x7406;&#x8BBA;&#xFF0C;&#x53EF;&#x4EE5;&#x7528;&#x76F8;&#x5BF9;&#x8F83;&#x5C0F;&#x4F46;&#x5F88;&#x6DF1;&#x7684;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x6765;&#x8BA1;&#x7B97;&#x3002;&#x5C0F;&#x5728;&#x8FD9;&#x91CC;&#x662F;&#x6307;&#x9690;&#x85CF;&#x5355;&#x5143;&#x7684;&#x6570;&#x91CF;&#x76F8;&#x5BF9;&#x8F83;&#x5C0F;&#x3002;</p>
        <img src="img/QQ&#x622A;&#x56FE;20200813115048.jpg" style="zoom:50%;">
        <h3 class="mume-header" id="%E6%90%AD%E5%BB%BA%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9D%97">&#x642D;&#x5EFA;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x5757;</h3>
        
        <h4 class="mume-header" id="%E7%A5%9E%E7%BB%8F%E5%85%83">&#x795E;&#x7ECF;&#x5143;&#xFF1A;</h4>
        
        <img src="img/QQ&#x622A;&#x56FE;20200813120128.jpg" style="zoom:50%;">
        <h4 class="mume-header" id="%E5%89%8D%E9%A6%88">&#x524D;&#x9988;:</h4>
        
        <p><span class="mathjax-exps">$Z^{[i]}=W^{[i]}A^{[i-1]}+b^{[i]}$</span></p>
        <p><span class="mathjax-exps">$A^{[i]}=g^{[i]}(Z^{[i]})$</span></p>
        <h4 class="mume-header" id="%E5%8F%8D%E9%A6%88">&#x53CD;&#x9988;&#xFF1A;</h4>
        
        <p><span class="mathjax-exps">$dZ^{[i]}=A^{[i-1]}*g^{[i]\prime}(Z^{[i]})$</span></p>
        <p><span class="mathjax-exps">$dW^{[i]}=\frac {dZ^{[i]}A^{[i-1]T}}{m}$</span></p>
        <p><span class="mathjax-exps">$db^{[i]}=\frac{np.sum(dZ^{[i]},axis=1,keepdims=True)}{m}$</span></p>
        <p><span class="mathjax-exps">$A^{[i-1]}=W^{[i]T}dZ^{[i]}$</span></p>
        <h4 class="mume-header" id="%E6%80%BB%E7%BB%93%E6%9E%84">&#x603B;&#x7ED3;&#x6784;</h4>
        
        <img src="img/QQ&#x622A;&#x56FE;20200813143417.jpg" style="zoom:50%;">
        <h3 class="mume-header" id="%E5%8F%82%E6%95%B0%E8%B6%85%E5%8F%82%E6%95%B0">&#x53C2;&#x6570;/&#x8D85;&#x53C2;&#x6570;</h3>
        
        <p>&#x4E3A;&#x4E86;&#x4F7F;&#x6DF1;&#x5EA6;&#x5B66;&#x4E60;&#x83B7;&#x5F97;&#x66F4;&#x597D;&#x7684;&#x6548;&#x679C;&#xFF0C;&#x6211;&#x4EEC;&#x8FD8;&#x9700;&#x8981;&#x89C4;&#x5212;&#x597D;&#x53C2;&#x6570;&#x3002;</p>
        <p>&#x9664;&#x4E86;W&#x548C;B&#x88AB;&#x79F0;&#x4E3A;&#x53C2;&#x6570;&#xFF0C;&#x8FD8;&#x6709;&#x5176;&#x4ED6;&#x53D8;&#x91CF;&#x6765;&#x63A7;&#x5236;&#x5168;&#x5C40;&#x6216;&#x5C40;&#x90E8;&#x79F0;&#x4E4B;&#x4E3A;&#x8D85;&#x53C2;&#x6570;&#xFF0C;&#x9700;&#x8981;&#x8F93;&#x5165;&#x5230;&#x5B66;&#x4E60;&#x7B97;&#x6CD5;&#x4E2D;&#x3002;&#x6BD4;&#x5982;&#xFF0C;&#x5B66;&#x4E60;&#x7387;<span class="mathjax-exps">$\alpha$</span>&#x6765;&#x51B3;&#x5B9A;&#x6211;&#x4EEC;&#x7684;&#x53C2;&#x6570;&#x5982;&#x4F55;&#x8FDB;&#x5316;&#xFF0C;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x6CD5;&#x5FAA;&#x73AF;&#x7684;&#x6570;&#x91CF;&#xFF0C;&#x9690;&#x5C42;&#x6570;L,&#x9690;&#x85CF;&#x5355;&#x5143;&#x6570;&#xFF0C;&#x9009;&#x62E9;&#x6FC0;&#x6D3B;&#x51FD;&#x6570;&#x7B49;&#x7B49;&#x3002;</p>
        <p>&#x9690;&#x5C42;&#x6570;L,&#x9690;&#x85CF;&#x5355;&#x5143;&#x6570;&#xFF0C;&#x9009;&#x62E9;&#x6FC0;&#x6D3B;&#x51FD;&#x6570;&#x7B49;&#x7B49;&#x3002;</p>
        <p>&#x4EE5;&#x4E0A;&#x8FD9;&#x4E9B;&#x56E0;&#x7D20;&#x90FD;&#x5728;&#x67D0;&#x79CD;&#x7A0B;&#x5EA6;&#x4E0A;&#x51B3;&#x5B9A;&#x4E86;W&#x548C;B&#x7684;&#x503C;&#xFF0C;&#x79F0;&#x4E3A;&#x8D85;&#x53C2;&#x6570;&#x3002;&#x8FD8;&#x6709;momentum&#xFF0C;mini batch&#x7684;&#x5927;&#x5C0F;&#xFF0C;&#x51E0;&#x79CD;&#x4E0D;&#x540C;&#x7684;&#x6B63;&#x5219;&#x5316;&#x53C2;&#x6570;&#x7B49;&#x7B49;&#x3002;</p>
        <p>&#x8FD9;&#x662F;&#x4E00;&#x4E2A;&#x7ECF;&#x9A8C;&#x5316;&#x7684;&#x8FC7;&#x7A0B;&#xFF0C;&#x53EF;&#x4EE5;&#x4E0D;&#x65AD;&#x5C1D;&#x8BD5;&#xFF0C;&#x770B;&#x770B;&#x6210;&#x672C;&#x51FD;&#x6570;&#x7684;&#x6548;&#x679C;&#x3002;</p>
        <img src="img/QQ&#x622A;&#x56FE;20200808151021.jpg" style="zoom:50%;">
        <h4 class="mume-header" id="%E6%B5%81%E7%A8%8B">&#x6D41;&#x7A0B;&#xFF1A;</h4>
        
        <p><img src="img/QQ%E6%88%AA%E5%9B%BE20200808151719.jpg" alt></p>
        <h1 class="mume-header" id="%E6%9E%84%E5%BB%BA%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B">&#x6784;&#x5EFA;&#x6DF1;&#x5C42;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x6A21;&#x578B;</h1>
        
        <h2 class="mume-header" id="%E7%9B%AE%E6%A0%87">&#x76EE;&#x6807;</h2>
        
        <p>&#x6A21;&#x578B;&#x7684;&#x7ED3;&#x6784;&#x662F;: <em>LINEAR -&gt; RELU -&gt; LINEAR -&gt; SIGMOID</em>.</p>
        <ul>
        <li>&#x4F7F;&#x7528;&#x50CF;ReLU&#x8FD9;&#x6837;&#x7684;&#x975E;&#x7EBF;&#x6027;&#x5355;&#x5143;&#x6765;&#x6539;&#x8FDB;&#x4F60;&#x7684;&#x6A21;&#x578B;</li>
        <li>&#x5EFA;&#x7ACB;&#x4E00;&#x4E2A;&#x66F4;&#x6DF1;&#x5C42;&#x7684;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#xFF08;&#x5177;&#x6709;&#x591A;&#x4E8E;&#x4E00;&#x4E2A;&#x7684;&#x9690;&#x85CF;&#x5C42;&#xFF09;</li>
        <li>&#x5B9E;&#x73B0;&#x4E00;&#x4E2A;&#x6613;&#x4E8E;&#x4F7F;&#x7528;&#x7684;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x7C7B;</li>
        </ul>
        <h2 class="mume-header" id="%E7%AC%A6%E5%8F%B7%E7%BA%A6%E5%AE%9A">&#x7B26;&#x53F7;&#x7EA6;&#x5B9A;</h2>
        
        <ul>
        <li>
        <p>&#x4E0A;&#x6807; <span class="mathjax-exps">$[l]$</span> &#x8868;&#x793A;&#x7B2C; <span class="mathjax-exps">$l$</span> &#x5C42;&#x3002;</p>
        </li>
        <li>
        <p>&#x4E0A;&#x6807; <span class="mathjax-exps">$(i)$</span> &#x8868;&#x793A;&#x7B2C; <span class="mathjax-exps">$i$</span> &#x4E2A;&#x6837;&#x672C;&#x3002;</p>
        </li>
        <li>
        <p>&#x4E0B;&#x6807; <span class="mathjax-exps">$i$</span> &#x8868;&#x793A;&#x5411;&#x91CF;&#x7684;&#x7B2C; <span class="mathjax-exps">$i$</span> &#x4E2A;&#x8BB0;&#x5F55;&#x3002;</p>
        <p>&#x4F8B;&#x5982;: <span class="mathjax-exps">$a^{[l]}_i$</span> &#x8868;&#x793A;&#x7B2C;<span class="mathjax-exps">$l$</span> &#x5C42;&#x6FC0;&#x6D3B;&#x51FD;&#x6570;&#x7684;&#x7B2C;<span class="mathjax-exps">$i$</span>&#x9879;</p>
        </li>
        </ul>
        <h2 class="mume-header" id="%E5%AF%BC%E5%8C%85">&#x5BFC;&#x5305;</h2>
        
        <pre data-role="codeBlock" data-info="python" class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
        <span class="token keyword">import</span> h5py
        <span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
        <span class="token keyword">from</span> testCases_v2 <span class="token keyword">import</span> <span class="token operator">*</span>
        <span class="token keyword">from</span> dnn_utils_v2 <span class="token keyword">import</span> sigmoid<span class="token punctuation">,</span> sigmoid_backward<span class="token punctuation">,</span> relu<span class="token punctuation">,</span> relu_backward
        
        <span class="token operator">%</span>matplotlib inline
        plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">&apos;figure.figsize&apos;</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">5.0</span><span class="token punctuation">,</span> <span class="token number">4.0</span><span class="token punctuation">)</span> <span class="token comment"># set default size of plots</span>
        plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">&apos;image.interpolation&apos;</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">&apos;nearest&apos;</span>
        plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">&apos;image.cmap&apos;</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">&apos;gray&apos;</span>
        
        <span class="token operator">%</span>load_ext autoreload
        <span class="token operator">%</span>autoreload <span class="token number">2</span>
        
        np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
        </pre><p>&#x9274;&#x4E8E;&#x6709;&#x4E9B;&#x4EBA;&#x627E;&#x4E0D;&#x5230;&#x5305;&#xFF0C;&#x6211;&#x5728;&#x8FD9;&#x91CC;&#x5C31;&#x5148;&#x8D34;&#x51FA;&#x6765;&#x4EE3;&#x7801;&#x3002;</p>
        <h3 class="mume-header" id="testcases_v2py">testCases_v2.py</h3>
        
        <pre data-role="codeBlock" data-info="python" class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
        
        <span class="token keyword">def</span> <span class="token function">layer_sizes_test_case</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
            X_assess <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
            Y_assess <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
            <span class="token keyword">return</span> X_assess<span class="token punctuation">,</span> Y_assess
        
        <span class="token keyword">def</span> <span class="token function">initialize_parameters_test_case</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            n_x<span class="token punctuation">,</span> n_h<span class="token punctuation">,</span> n_y <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">1</span>
            <span class="token keyword">return</span> n_x<span class="token punctuation">,</span> n_h<span class="token punctuation">,</span> n_y
        
        <span class="token keyword">def</span> <span class="token function">forward_propagation_test_case</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
            X_assess <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
        
            parameters <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&apos;W1&apos;</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.00416758</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.00056267</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.02136196</span><span class="token punctuation">,</span>  <span class="token number">0.01640271</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.01793436</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.00841747</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token punctuation">[</span> <span class="token number">0.00502881</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.01245288</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
             <span class="token string">&apos;W2&apos;</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.01057952</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.00909008</span><span class="token punctuation">,</span>  <span class="token number">0.00551454</span><span class="token punctuation">,</span>  <span class="token number">0.02292208</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
             <span class="token string">&apos;b1&apos;</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
             <span class="token string">&apos;b2&apos;</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
        
            <span class="token keyword">return</span> X_assess<span class="token punctuation">,</span> parameters
        
        <span class="token keyword">def</span> <span class="token function">compute_cost_test_case</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
            Y_assess <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
            parameters <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&apos;W1&apos;</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.00416758</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.00056267</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.02136196</span><span class="token punctuation">,</span>  <span class="token number">0.01640271</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.01793436</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.00841747</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token punctuation">[</span> <span class="token number">0.00502881</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.01245288</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
             <span class="token string">&apos;W2&apos;</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.01057952</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.00909008</span><span class="token punctuation">,</span>  <span class="token number">0.00551454</span><span class="token punctuation">,</span>  <span class="token number">0.02292208</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
             <span class="token string">&apos;b1&apos;</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
             <span class="token string">&apos;b2&apos;</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
        
            a2 <span class="token operator">=</span> <span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.5002307</span> <span class="token punctuation">,</span>  <span class="token number">0.49985831</span><span class="token punctuation">,</span>  <span class="token number">0.50023963</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            
            <span class="token keyword">return</span> a2<span class="token punctuation">,</span> Y_assess<span class="token punctuation">,</span> parameters
        
        <span class="token keyword">def</span> <span class="token function">backward_propagation_test_case</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
            X_assess <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
            Y_assess <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
            parameters <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&apos;W1&apos;</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.00416758</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.00056267</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.02136196</span><span class="token punctuation">,</span>  <span class="token number">0.01640271</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.01793436</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.00841747</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token punctuation">[</span> <span class="token number">0.00502881</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.01245288</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
             <span class="token string">&apos;W2&apos;</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.01057952</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.00909008</span><span class="token punctuation">,</span>  <span class="token number">0.00551454</span><span class="token punctuation">,</span>  <span class="token number">0.02292208</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
             <span class="token string">&apos;b1&apos;</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
             <span class="token string">&apos;b2&apos;</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
        
            cache <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&apos;A1&apos;</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.00616578</span><span class="token punctuation">,</span>  <span class="token number">0.0020626</span> <span class="token punctuation">,</span>  <span class="token number">0.00349619</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                 <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.05225116</span><span class="token punctuation">,</span>  <span class="token number">0.02725659</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.02646251</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                 <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.02009721</span><span class="token punctuation">,</span>  <span class="token number">0.0036869</span> <span class="token punctuation">,</span>  <span class="token number">0.02883756</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                 <span class="token punctuation">[</span> <span class="token number">0.02152675</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.01385234</span><span class="token punctuation">,</span>  <span class="token number">0.02599885</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
          <span class="token string">&apos;A2&apos;</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.5002307</span> <span class="token punctuation">,</span>  <span class="token number">0.49985831</span><span class="token punctuation">,</span>  <span class="token number">0.50023963</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
          <span class="token string">&apos;Z1&apos;</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.00616586</span><span class="token punctuation">,</span>  <span class="token number">0.0020626</span> <span class="token punctuation">,</span>  <span class="token number">0.0034962</span> <span class="token punctuation">]</span><span class="token punctuation">,</span>
                 <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.05229879</span><span class="token punctuation">,</span>  <span class="token number">0.02726335</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.02646869</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                 <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.02009991</span><span class="token punctuation">,</span>  <span class="token number">0.00368692</span><span class="token punctuation">,</span>  <span class="token number">0.02884556</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                 <span class="token punctuation">[</span> <span class="token number">0.02153007</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.01385322</span><span class="token punctuation">,</span>  <span class="token number">0.02600471</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
          <span class="token string">&apos;Z2&apos;</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.00092281</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.00056678</span><span class="token punctuation">,</span>  <span class="token number">0.00095853</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
            <span class="token keyword">return</span> parameters<span class="token punctuation">,</span> cache<span class="token punctuation">,</span> X_assess<span class="token punctuation">,</span> Y_assess
        
        <span class="token keyword">def</span> <span class="token function">update_parameters_test_case</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            parameters <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&apos;W1&apos;</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.00615039</span><span class="token punctuation">,</span>  <span class="token number">0.0169021</span> <span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.02311792</span><span class="token punctuation">,</span>  <span class="token number">0.03137121</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.0169217</span> <span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.01752545</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token punctuation">[</span> <span class="token number">0.00935436</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.05018221</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
         <span class="token string">&apos;W2&apos;</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.0104319</span> <span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.04019007</span><span class="token punctuation">,</span>  <span class="token number">0.01607211</span><span class="token punctuation">,</span>  <span class="token number">0.04440255</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
         <span class="token string">&apos;b1&apos;</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token operator">-</span><span class="token number">8.97523455e-07</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token punctuation">[</span>  <span class="token number">8.15562092e-06</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token punctuation">[</span>  <span class="token number">6.04810633e-07</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token punctuation">[</span> <span class="token operator">-</span><span class="token number">2.54560700e-06</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
         <span class="token string">&apos;b2&apos;</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span>  <span class="token number">9.14954378e-05</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
        
            grads <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&apos;dW1&apos;</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.00023322</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.00205423</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token punctuation">[</span> <span class="token number">0.00082222</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.00700776</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.00031831</span><span class="token punctuation">,</span>  <span class="token number">0.0028636</span> <span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.00092857</span><span class="token punctuation">,</span>  <span class="token number">0.00809933</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
         <span class="token string">&apos;dW2&apos;</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token operator">-</span><span class="token number">1.75740039e-05</span><span class="token punctuation">,</span>   <span class="token number">3.70231337e-03</span><span class="token punctuation">,</span>  <span class="token operator">-</span><span class="token number">1.25683095e-03</span><span class="token punctuation">,</span>
                  <span class="token operator">-</span><span class="token number">2.55715317e-03</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
         <span class="token string">&apos;db1&apos;</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span>  <span class="token number">1.05570087e-07</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token punctuation">[</span> <span class="token operator">-</span><span class="token number">3.81814487e-06</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token punctuation">[</span> <span class="token operator">-</span><span class="token number">1.90155145e-07</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token punctuation">[</span>  <span class="token number">5.46467802e-07</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
         <span class="token string">&apos;db2&apos;</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token operator">-</span><span class="token number">1.08923140e-05</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
            <span class="token keyword">return</span> parameters<span class="token punctuation">,</span> grads
        
        <span class="token keyword">def</span> <span class="token function">nn_model_test_case</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
            X_assess <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
            Y_assess <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
            <span class="token keyword">return</span> X_assess<span class="token punctuation">,</span> Y_assess
        
        <span class="token keyword">def</span> <span class="token function">predict_test_case</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
            X_assess <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
            parameters <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&apos;W1&apos;</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.00615039</span><span class="token punctuation">,</span>  <span class="token number">0.0169021</span> <span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.02311792</span><span class="token punctuation">,</span>  <span class="token number">0.03137121</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.0169217</span> <span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.01752545</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token punctuation">[</span> <span class="token number">0.00935436</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.05018221</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
             <span class="token string">&apos;W2&apos;</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.0104319</span> <span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.04019007</span><span class="token punctuation">,</span>  <span class="token number">0.01607211</span><span class="token punctuation">,</span>  <span class="token number">0.04440255</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
             <span class="token string">&apos;b1&apos;</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token operator">-</span><span class="token number">8.97523455e-07</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token punctuation">[</span>  <span class="token number">8.15562092e-06</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token punctuation">[</span>  <span class="token number">6.04810633e-07</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token punctuation">[</span> <span class="token operator">-</span><span class="token number">2.54560700e-06</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
             <span class="token string">&apos;b2&apos;</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span>  <span class="token number">9.14954378e-05</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
            <span class="token keyword">return</span> parameters<span class="token punctuation">,</span> X_assess
        
        </pre><h3 class="mume-header" id="dnn_utils_v2py">dnn_utils_v2.py</h3>
        
        <pre data-role="codeBlock" data-info="python" class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
        
        <span class="token keyword">def</span> <span class="token function">sigmoid</span><span class="token punctuation">(</span>Z<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token triple-quoted-string string">&quot;&quot;&quot;
            Implements the sigmoid activation in numpy
            
            Arguments:
            Z -- numpy array of any shape
            
            Returns:
            A -- output of sigmoid(z), same shape as Z
            cache -- returns Z as well, useful during backpropagation
            &quot;&quot;&quot;</span>
            
            A <span class="token operator">=</span> <span class="token number">1</span><span class="token operator">/</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">+</span>np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span>Z<span class="token punctuation">)</span><span class="token punctuation">)</span>
            cache <span class="token operator">=</span> Z
            
            <span class="token keyword">return</span> A<span class="token punctuation">,</span> cache
        
        <span class="token keyword">def</span> <span class="token function">relu</span><span class="token punctuation">(</span>Z<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token triple-quoted-string string">&quot;&quot;&quot;
            Implement the RELU function.
        
            Arguments:
            Z -- Output of the linear layer, of any shape
        
            Returns:
            A -- Post-activation parameter, of the same shape as Z
            cache -- a python dictionary containing &quot;A&quot; ; stored for computing the backward pass efficiently
            &quot;&quot;&quot;</span>
            
            A <span class="token operator">=</span> np<span class="token punctuation">.</span>maximum<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span>Z<span class="token punctuation">)</span>
            
            <span class="token keyword">assert</span><span class="token punctuation">(</span>A<span class="token punctuation">.</span>shape <span class="token operator">==</span> Z<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
            
            cache <span class="token operator">=</span> Z 
            <span class="token keyword">return</span> A<span class="token punctuation">,</span> cache
        
        
        <span class="token keyword">def</span> <span class="token function">relu_backward</span><span class="token punctuation">(</span>dA<span class="token punctuation">,</span> cache<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token triple-quoted-string string">&quot;&quot;&quot;
            Implement the backward propagation for a single RELU unit.
        
            Arguments:
            dA -- post-activation gradient, of any shape
            cache -- &apos;Z&apos; where we store for computing backward propagation efficiently
        
            Returns:
            dZ -- Gradient of the cost with respect to Z
            &quot;&quot;&quot;</span>
            
            Z <span class="token operator">=</span> cache
            dZ <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>dA<span class="token punctuation">,</span> copy<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span> <span class="token comment"># just converting dz to a correct object.</span>
            
            <span class="token comment"># When z &lt;= 0, you should set dz to 0 as well. </span>
            dZ<span class="token punctuation">[</span>Z <span class="token operator">&lt;=</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>
            
            <span class="token keyword">assert</span> <span class="token punctuation">(</span>dZ<span class="token punctuation">.</span>shape <span class="token operator">==</span> Z<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
            
            <span class="token keyword">return</span> dZ
        
        <span class="token keyword">def</span> <span class="token function">sigmoid_backward</span><span class="token punctuation">(</span>dA<span class="token punctuation">,</span> cache<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token triple-quoted-string string">&quot;&quot;&quot;
            Implement the backward propagation for a single SIGMOID unit.
        
            Arguments:
            dA -- post-activation gradient, of any shape
            cache -- &apos;Z&apos; where we store for computing backward propagation efficiently
        
            Returns:
            dZ -- Gradient of the cost with respect to Z
            &quot;&quot;&quot;</span>
            
            Z <span class="token operator">=</span> cache
            
            s <span class="token operator">=</span> <span class="token number">1</span><span class="token operator">/</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">+</span>np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span>Z<span class="token punctuation">)</span><span class="token punctuation">)</span>
            dZ <span class="token operator">=</span> dA <span class="token operator">*</span> s <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span>s<span class="token punctuation">)</span>
            
            <span class="token keyword">assert</span> <span class="token punctuation">(</span>dZ<span class="token punctuation">.</span>shape <span class="token operator">==</span> Z<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
            
            <span class="token keyword">return</span> dZ
        
        
        </pre><h2 class="mume-header" id="%E5%88%9D%E5%A7%8B%E5%8C%96%E5%8F%82%E6%95%B0">&#x521D;&#x59CB;&#x5316;&#x53C2;&#x6570;</h2>
        
        <p>&#x4F7F;&#x7528;<code>np.random.randn(shape)*0.01</code> &#x968F;&#x673A;&#x521D;&#x59CB;&#x5316;&#x6743;&#x91CD;&#x77E9;&#x9635;w&#xFF0C;&#x5E76;&#x4F7F;&#x5B83;&#x7B26;&#x5408;shape&#x7684;&#x8981;&#x6C42;</p>
        <p>&#x4F7F;&#x7528; <code>np.zeros(shape)</code>&#xFF0C;&#x5BF9;&#x504F;&#x7F6E;b&#x5168;&#x90E8;&#x521D;&#x59CB;&#x5316;&#x4E3A;0&#x3002;</p>
        <h3 class="mume-header" id="2%E5%B1%82%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96">2&#x5C42;&#x7684;&#x521D;&#x59CB;&#x5316;</h3>
        
        <pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment"># GRADED FUNCTION: initialize_parameters</span>
        
        <span class="token keyword">def</span> <span class="token function">initialize_parameters</span><span class="token punctuation">(</span>n_x<span class="token punctuation">,</span> n_h<span class="token punctuation">,</span> n_y<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token triple-quoted-string string">&quot;&quot;&quot;
            Argument:
            n_x -- size of the input layer
            n_h -- size of the hidden layer
            n_y -- size of the output layer
            
            Returns:
            parameters -- python dictionary containing your parameters:
                            W1 -- weight matrix of shape (n_h, n_x)
                            b1 -- bias vector of shape (n_h, 1)
                            W2 -- weight matrix of shape (n_y, n_h)
                            b2 -- bias vector of shape (n_y, 1)
            &quot;&quot;&quot;</span>
            
            np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
            
            <span class="token comment">### START CODE HERE ### (&#x2248; 4 lines of code)</span>
            W1 <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>n_h<span class="token punctuation">,</span> n_x<span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">0.01</span>
            b1 <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>n_h<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            W2 <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>n_y<span class="token punctuation">,</span> n_h<span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">0.01</span>
            b2 <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>n_y<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token comment">### END CODE HERE ###</span>
            
            <span class="token keyword">assert</span><span class="token punctuation">(</span>W1<span class="token punctuation">.</span>shape <span class="token operator">==</span> <span class="token punctuation">(</span>n_h<span class="token punctuation">,</span> n_x<span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token keyword">assert</span><span class="token punctuation">(</span>b1<span class="token punctuation">.</span>shape <span class="token operator">==</span> <span class="token punctuation">(</span>n_h<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token keyword">assert</span><span class="token punctuation">(</span>W2<span class="token punctuation">.</span>shape <span class="token operator">==</span> <span class="token punctuation">(</span>n_y<span class="token punctuation">,</span> n_h<span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token keyword">assert</span><span class="token punctuation">(</span>b2<span class="token punctuation">.</span>shape <span class="token operator">==</span> <span class="token punctuation">(</span>n_y<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            
            parameters <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;W1&quot;</span><span class="token punctuation">:</span> W1<span class="token punctuation">,</span>
                          <span class="token string">&quot;b1&quot;</span><span class="token punctuation">:</span> b1<span class="token punctuation">,</span>
                          <span class="token string">&quot;W2&quot;</span><span class="token punctuation">:</span> W2<span class="token punctuation">,</span>
                          <span class="token string">&quot;b2&quot;</span><span class="token punctuation">:</span> b2<span class="token punctuation">}</span>
            
            <span class="token keyword">return</span> parameters    
        </pre><h3 class="mume-header" id="l%E5%B1%82%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96">L&#x5C42;&#x7684;&#x521D;&#x59CB;&#x5316;</h3>
        
        <pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment"># GRADED FUNCTION: initialize_parameters_deep</span>
        
        <span class="token keyword">def</span> <span class="token function">initialize_parameters_deep</span><span class="token punctuation">(</span>layer_dims<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token triple-quoted-string string">&quot;&quot;&quot;
            Arguments:
            layer_dims -- python array (list) containing the dimensions of each layer in our network
            
            Returns:
            parameters -- python dictionary containing your parameters &quot;W1&quot;, &quot;b1&quot;, ..., &quot;WL&quot;, &quot;bL&quot;:
                            Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])
                            bl -- bias vector of shape (layer_dims[l], 1)
            &quot;&quot;&quot;</span>
            
            np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>
            parameters <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
            L <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>layer_dims<span class="token punctuation">)</span>            <span class="token comment"># &#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x7684;&#x5C42;&#x6570;</span>
        
            <span class="token keyword">for</span> l <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> L<span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token comment">### START CODE HERE ### (&#x2248; 2 lines of code)</span>
                parameters<span class="token punctuation">[</span><span class="token string">&apos;W&apos;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>l<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>layer_dims<span class="token punctuation">[</span>l<span class="token punctuation">]</span><span class="token punctuation">,</span> layer_dims<span class="token punctuation">[</span>l<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">0.01</span>
                parameters<span class="token punctuation">[</span><span class="token string">&apos;b&apos;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>l<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span> <span class="token punctuation">(</span>layer_dims<span class="token punctuation">[</span>l<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token punctuation">)</span>
                <span class="token comment">### END CODE HERE ###</span>
                
                <span class="token keyword">assert</span><span class="token punctuation">(</span>parameters<span class="token punctuation">[</span><span class="token string">&apos;W&apos;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>l<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape <span class="token operator">==</span> <span class="token punctuation">(</span>layer_dims<span class="token punctuation">[</span>l<span class="token punctuation">]</span><span class="token punctuation">,</span> layer_dims<span class="token punctuation">[</span>l<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token keyword">assert</span><span class="token punctuation">(</span>parameters<span class="token punctuation">[</span><span class="token string">&apos;b&apos;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>l<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape <span class="token operator">==</span> <span class="token punctuation">(</span>layer_dims<span class="token punctuation">[</span>l<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        
                
            <span class="token keyword">return</span> parameters
        </pre><h2 class="mume-header" id="%E7%BA%BF%E6%80%A7%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E5%89%8D%E9%A6%88">&#x7EBF;&#x6027;&#x6FC0;&#x6D3B;&#x51FD;&#x6570;(&#x524D;&#x9988;)</h2>
        
        <p>&#x8FD9;&#x91CC;&#x6211;&#x4EEC;&#x628A;ReLU&#x548C;sigmoid&#x7EC4;&#x5408;&#x6210;&#x4E00;&#x4E2A;&#x51FD;&#x6570;&#x3002;cache&#x7F13;&#x5B58;&#x5B57;&#x5178;&#xFF0C;&#x6765;&#x66F4;&#x52A0;&#x65B9;&#x4FBF;&#x7684;&#x83B7;&#x5F97;&#x524D;&#x9988;&#x6570;&#x636E;&#xFF0C;&#x6709;&#x5229;&#x4E8E;&#x4E0B;&#x4E00;&#x6B65;&#x7684;&#x53CD;&#x9988;&#x3002;</p>
        <h3 class="mume-header" id="%E5%8F%8C%E5%B1%82">&#x53CC;&#x5C42;</h3>
        
        <pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment"># GRADED FUNCTION: linear_activation_forward</span>
        
        <span class="token keyword">def</span> <span class="token function">linear_activation_forward</span><span class="token punctuation">(</span>A_prev<span class="token punctuation">,</span> W<span class="token punctuation">,</span> b<span class="token punctuation">,</span> activation<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token triple-quoted-string string">&quot;&quot;&quot;
            Implement the forward propagation for the LINEAR-&gt;ACTIVATION layer
        
            Arguments:
            A_prev -- activations from previous layer (or input data): (size of previous layer, number of examples)
            W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)
            b -- bias vector, numpy array of shape (size of the current layer, 1)
            activation -- the activation to be used in this layer, stored as a text string: &quot;sigmoid&quot; or &quot;relu&quot;
        
            Returns:
            A -- the output of the activation function, also called the post-activation value 
            cache -- a python dictionary containing &quot;linear_cache&quot; and &quot;activation_cache&quot;;
                     stored for computing the backward pass efficiently
            &quot;&quot;&quot;</span>
            
            <span class="token keyword">if</span> activation <span class="token operator">==</span> <span class="token string">&quot;sigmoid&quot;</span><span class="token punctuation">:</span>
                <span class="token comment"># &#x8F93;&#x5165;: &quot;A_prev, W, b&quot;. &#x8F93;&#x51FA;: &quot;A, activation_cache&quot;.</span>
                <span class="token comment">### START CODE HERE ### (&#x2248; 2 lines of code)</span>
                Z<span class="token punctuation">,</span> linear_cache <span class="token operator">=</span> linear_forward<span class="token punctuation">(</span>A_prev<span class="token punctuation">,</span> W<span class="token punctuation">,</span> b<span class="token punctuation">)</span>
                A<span class="token punctuation">,</span> activation_cache <span class="token operator">=</span> sigmoid<span class="token punctuation">(</span>Z<span class="token punctuation">)</span>
                <span class="token comment">### END CODE HERE ###</span>
            
            <span class="token keyword">elif</span> activation <span class="token operator">==</span> <span class="token string">&quot;relu&quot;</span><span class="token punctuation">:</span>
                <span class="token comment"># &#x8F93;&#x5165;: &quot;A_prev, W, b&quot;. &#x8F93;&#x51FA;: &quot;A, activation_cache&quot;.</span>
                <span class="token comment">### START CODE HERE ### (&#x2248; 2 lines of code)</span>
                Z<span class="token punctuation">,</span> linear_cache <span class="token operator">=</span> linear_forward<span class="token punctuation">(</span>A_prev<span class="token punctuation">,</span> W<span class="token punctuation">,</span> b<span class="token punctuation">)</span>
                A<span class="token punctuation">,</span> activation_cache <span class="token operator">=</span> relu<span class="token punctuation">(</span>Z<span class="token punctuation">)</span>
                <span class="token comment">### END CODE HERE ###</span>
            
            <span class="token keyword">assert</span> <span class="token punctuation">(</span>A<span class="token punctuation">.</span>shape <span class="token operator">==</span> <span class="token punctuation">(</span>W<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> A_prev<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            cache <span class="token operator">=</span> <span class="token punctuation">(</span>linear_cache<span class="token punctuation">,</span> activation_cache<span class="token punctuation">)</span>
        
            <span class="token keyword">return</span> A<span class="token punctuation">,</span> cache
        </pre><h3 class="mume-header" id="l%E5%B1%82">L&#x5C42;</h3>
        
        <pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment"># GRADED FUNCTION: L_model_forward</span>
        
        <span class="token keyword">def</span> <span class="token function">L_model_forward</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> parameters<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token triple-quoted-string string">&quot;&quot;&quot;
            Implement forward propagation for the [LINEAR-&gt;RELU]*(L-1)-&gt;LINEAR-&gt;SIGMOID computation
            
            Arguments:
            X -- data, numpy array of shape (input size, number of examples)
            parameters -- output of initialize_parameters_deep()
            
            Returns:
            AL -- last post-activation value
            caches -- list of caches containing:
                        every cache of linear_relu_forward() (there are L-1 of them, indexed from 0 to L-2)
                        the cache of linear_sigmoid_forward() (there is one, indexed L-1)
            &quot;&quot;&quot;</span>
        
            caches <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
            A <span class="token operator">=</span> X
            L <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>parameters<span class="token punctuation">)</span> <span class="token operator">//</span> <span class="token number">2</span>                  <span class="token comment"># number of layers in the neural network</span>
            
            <span class="token comment"># &#x8FD0;&#x884C;ReLU&#x51FD;&#x6570;L-1&#x6B21;. &#x5E76;&#x4E14;&#x5C06; &quot;cache&quot; &#x6DFB;&#x52A0;&#x5230;&quot;caches&quot;&#x4E2D;.</span>
            <span class="token keyword">for</span> l <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> L<span class="token punctuation">)</span><span class="token punctuation">:</span>
                A_prev <span class="token operator">=</span> A 
                <span class="token comment">### START CODE HERE ### (&#x2248; 2 lines of code)</span>
                A<span class="token punctuation">,</span> cache <span class="token operator">=</span> linear_activation_forward<span class="token punctuation">(</span>A_prev<span class="token punctuation">,</span> parameters<span class="token punctuation">[</span><span class="token string">&apos;W&apos;</span><span class="token operator">+</span><span class="token builtin">str</span><span class="token punctuation">(</span>l<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> parameters<span class="token punctuation">[</span><span class="token string">&apos;b&apos;</span><span class="token operator">+</span><span class="token builtin">str</span><span class="token punctuation">(</span>l<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> activation <span class="token operator">=</span> <span class="token string">&quot;relu&quot;</span><span class="token punctuation">)</span>
                caches<span class="token punctuation">.</span>append<span class="token punctuation">(</span>cache<span class="token punctuation">)</span>
        
                <span class="token comment">### END CODE HERE ###</span>
            
            <span class="token comment"># &#x8FD0;&#x884C;SIGMOID&#x51FD;&#x6570;. &#x5E76;&#x4E14;&#x5C06; &quot;cache&quot; &#x6DFB;&#x52A0;&#x5230;&quot;caches&quot;&#x4E2D;.</span>
            <span class="token comment">### START CODE HERE ### (&#x2248; 2 lines of code)</span>
            AL<span class="token punctuation">,</span> cache <span class="token operator">=</span> linear_activation_forward<span class="token punctuation">(</span>A<span class="token punctuation">,</span> parameters<span class="token punctuation">[</span><span class="token string">&apos;W&apos;</span><span class="token operator">+</span><span class="token builtin">str</span><span class="token punctuation">(</span>L<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> parameters<span class="token punctuation">[</span><span class="token string">&apos;b&apos;</span><span class="token operator">+</span><span class="token builtin">str</span><span class="token punctuation">(</span>L<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> activation <span class="token operator">=</span> <span class="token string">&quot;sigmoid&quot;</span><span class="token punctuation">)</span>
            caches<span class="token punctuation">.</span>append<span class="token punctuation">(</span>cache<span class="token punctuation">)</span>
        
            <span class="token comment">### END CODE HERE ###</span>
            
            <span class="token keyword">assert</span><span class="token punctuation">(</span>AL<span class="token punctuation">.</span>shape <span class="token operator">==</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                    
            <span class="token keyword">return</span> AL<span class="token punctuation">,</span> caches
        </pre><h2 class="mume-header" id="%E6%88%90%E6%9C%AC%E5%87%BD%E6%95%B0">&#x6210;&#x672C;&#x51FD;&#x6570;</h2>
        
        <pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment"># GRADED FUNCTION: compute_cost</span>
        
        <span class="token keyword">def</span> <span class="token function">compute_cost</span><span class="token punctuation">(</span>AL<span class="token punctuation">,</span> Y<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token triple-quoted-string string">&quot;&quot;&quot;
            Implement the cost function defined by equation (7).
        
            Arguments:
            AL -- probability vector corresponding to your label predictions, shape (1, number of examples)
            Y -- true &quot;label&quot; vector (for example: containing 0 if non-cat, 1 if cat), shape (1, number of examples)
        
            Returns:
            cost -- cross-entropy cost
            &quot;&quot;&quot;</span>
            
            m <span class="token operator">=</span> Y<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
        
            <span class="token comment"># &#x8BA1;&#x7B97; aL&#xFF08;&#x5373;&#x4E0A;&#x6587;&#x7684;a_L&#x6216;&#x8005;&#x662F;y_hat&#xFF09; &#x548C; y&#x7684;&#x6210;&#x672C;.</span>
            <span class="token comment">### START CODE HERE ### (&#x2248; 1 lines of code)</span>
            cost <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token operator">/</span>m <span class="token operator">*</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span> Y<span class="token operator">*</span>np<span class="token punctuation">.</span>log<span class="token punctuation">(</span>AL<span class="token punctuation">)</span><span class="token operator">+</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span>Y<span class="token punctuation">)</span><span class="token operator">*</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span>AL<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token comment">### END CODE HERE ###</span>
            
            cost <span class="token operator">=</span> np<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>cost<span class="token punctuation">)</span>      <span class="token comment"># &#x786E;&#x4FDD;cost&#x7684;shape&#x7B26;&#x5408;&#x8981;&#x6C42;(e.g. this turns [[17]] into 17).</span>
            <span class="token keyword">assert</span><span class="token punctuation">(</span>cost<span class="token punctuation">.</span>shape <span class="token operator">==</span> <span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            
            <span class="token keyword">return</span> cost
        </pre><h2 class="mume-header" id="%E7%BA%BF%E6%80%A7%E5%8F%8D%E9%A6%88">&#x7EBF;&#x6027;&#x53CD;&#x9988;</h2>
        
        <h3 class="mume-header" id="%E7%BA%BF%E6%80%A7%E5%8F%8D%E9%A6%88-1">&#x7EBF;&#x6027;&#x53CD;&#x9988;</h3>
        
        <pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment"># GRADED FUNCTION: linear_backward</span>
        
        <span class="token keyword">def</span> <span class="token function">linear_backward</span><span class="token punctuation">(</span>dZ<span class="token punctuation">,</span> cache<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token triple-quoted-string string">&quot;&quot;&quot;
            Implement the linear portion of backward propagation for a single layer (layer l)
        
            Arguments:
            dZ -- Gradient of the cost with respect to the linear output (of current layer l)
            cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer
        
            Returns:
            dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev
            dW -- Gradient of the cost with respect to W (current layer l), same shape as W
            db -- Gradient of the cost with respect to b (current layer l), same shape as b
            &quot;&quot;&quot;</span>
            A_prev<span class="token punctuation">,</span> W<span class="token punctuation">,</span> b <span class="token operator">=</span> cache
            m <span class="token operator">=</span> A_prev<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
            
            <span class="token comment">### START CODE HERE ### (&#x2248; 3 lines of code)</span>
            dW <span class="token operator">=</span> <span class="token number">1</span><span class="token operator">/</span>m <span class="token operator">*</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>dZ<span class="token punctuation">,</span> A_prev<span class="token punctuation">.</span>T<span class="token punctuation">)</span>
            db <span class="token operator">=</span> <span class="token number">1</span><span class="token operator">/</span>m <span class="token operator">*</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dZ<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
            dA_prev <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>W<span class="token punctuation">.</span>T<span class="token punctuation">,</span> dZ<span class="token punctuation">)</span>
            <span class="token comment">### END CODE HERE ###</span>
            
            <span class="token keyword">assert</span> <span class="token punctuation">(</span>dA_prev<span class="token punctuation">.</span>shape <span class="token operator">==</span> A_prev<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
            <span class="token keyword">assert</span> <span class="token punctuation">(</span>dW<span class="token punctuation">.</span>shape <span class="token operator">==</span> W<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
            <span class="token keyword">assert</span> <span class="token punctuation">(</span>db<span class="token punctuation">.</span>shape <span class="token operator">==</span> b<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
            
            <span class="token keyword">return</span> dA_prev<span class="token punctuation">,</span> dW<span class="token punctuation">,</span> db
        </pre><h3 class="mume-header" id="%E7%BA%BF%E6%80%A7%E6%BF%80%E6%B4%BB%E5%8F%8D%E9%A6%88">&#x7EBF;&#x6027;&#x6FC0;&#x6D3B;&#x53CD;&#x9988;</h3>
        
        <p>&#x7531;&#x4E0A;&#x6587;&#xFF0C;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x5F88;&#x5BB9;&#x6613;&#x7684;&#x5F97;&#x51FA;sigmoid&#x51FD;&#x6570;&#x548C;ReLU&#x51FD;&#x6570;&#x4E0E;&#x5B83;&#x5BFC;&#x6570;&#x95F4;&#x7684;&#x5173;&#x7CFB;&#x3002;</p>
        <p>&#x8BBE;<span class="mathjax-exps">$\sigma(z)=a&#xFF0C;d\sigma(z)=a(1-a)$</span>&#x3002;</p>
        <p></p><div class="mathjax-exps">$$dReLU=\begin{cases} 0,\quad x\leq 0\\ 1, \quad x&gt;0 \end{cases}$$</div><p></p>
        <p>&#x6240;&#x4EE5;&#x5BF9;&#x4E8E;&#x539F;&#x672C;&#x7684;&#x6B63;&#x5411;&#x4F20;&#x64AD;&#x7684;&#x6FC0;&#x6D3B;&#x51FD;&#x6570;&#xFF0C;&#x53CD;&#x5411;&#x4F20;&#x64AD;&#x65F6;&#xFF0C;&#x6211;&#x4EEC;&#x5C31;&#x53EF;&#x4EE5;&#x76F4;&#x63A5;&#x4EE3;&#x5165;&#x516C;&#x5F0F;&#x5373;&#x53EF;&#x3002;</p>
        <pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment"># GRADED FUNCTION: linear_activation_backward</span>
        
        <span class="token keyword">def</span> <span class="token function">linear_activation_backward</span><span class="token punctuation">(</span>dA<span class="token punctuation">,</span> cache<span class="token punctuation">,</span> activation<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token triple-quoted-string string">&quot;&quot;&quot;
            Implement the backward propagation for the LINEAR-&gt;ACTIVATION layer.
            
            Arguments:
            dA -- post-activation gradient for current layer l 
            cache -- tuple of values (linear_cache, activation_cache) we store for computing backward propagation efficiently
            activation -- the activation to be used in this layer, stored as a text string: &quot;sigmoid&quot; or &quot;relu&quot;
            
            Returns:
            dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev
            dW -- Gradient of the cost with respect to W (current layer l), same shape as W
            db -- Gradient of the cost with respect to b (current layer l), same shape as b
            &quot;&quot;&quot;</span>
            linear_cache<span class="token punctuation">,</span> activation_cache <span class="token operator">=</span> cache
            
            <span class="token keyword">if</span> activation <span class="token operator">==</span> <span class="token string">&quot;relu&quot;</span><span class="token punctuation">:</span>
                <span class="token comment">### START CODE HERE ### (&#x2248; 2 lines of code)</span>
                dZ <span class="token operator">=</span> relu_backward<span class="token punctuation">(</span>dA<span class="token punctuation">,</span> activation_cache<span class="token punctuation">)</span>
                dA_prev<span class="token punctuation">,</span> dW<span class="token punctuation">,</span> db <span class="token operator">=</span> linear_backward<span class="token punctuation">(</span>dZ<span class="token punctuation">,</span> linear_cache<span class="token punctuation">)</span>
                <span class="token comment">### END CODE HERE ###</span>
                
            <span class="token keyword">elif</span> activation <span class="token operator">==</span> <span class="token string">&quot;sigmoid&quot;</span><span class="token punctuation">:</span>
                <span class="token comment">### START CODE HERE ### (&#x2248; 2 lines of code)</span>
                dZ <span class="token operator">=</span> sigmoid_backward<span class="token punctuation">(</span>dA<span class="token punctuation">,</span> activation_cache<span class="token punctuation">)</span>
                dA_prev<span class="token punctuation">,</span> dW<span class="token punctuation">,</span> db <span class="token operator">=</span> linear_backward<span class="token punctuation">(</span>dZ<span class="token punctuation">,</span> linear_cache<span class="token punctuation">)</span>
                <span class="token comment">### END CODE HERE ###</span>
            
            <span class="token keyword">return</span> dA_prev<span class="token punctuation">,</span> dW<span class="token punctuation">,</span> db
        </pre><h2 class="mume-header" id="l%E5%B1%82%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%8D%E9%A6%88">L&#x5C42;&#x6A21;&#x578B;&#x7684;&#x53CD;&#x9988;</h2>
        
        <p>&#x6B64;&#x65F6;&#x6211;&#x4EEC;&#x8981;&#x53D6;&#x51FA;&#x4E4B;&#x524D;&#x7684;&#x7684;cache&#x8FDB;&#x884C;&#x8BA1;&#x7B97;&#x53CD;&#x9988;&#x4E86;&#x3002;</p>
        <pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment"># GRADED FUNCTION: L_model_backward</span>
        
        <span class="token keyword">def</span> <span class="token function">L_model_backward</span><span class="token punctuation">(</span>AL<span class="token punctuation">,</span> Y<span class="token punctuation">,</span> caches<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token triple-quoted-string string">&quot;&quot;&quot;
            Implement the backward propagation for the [LINEAR-&gt;RELU] * (L-1) -&gt; LINEAR -&gt; SIGMOID group
            
            Arguments:
            AL -- probability vector, output of the forward propagation (L_model_forward())
            Y -- true &quot;label&quot; vector (containing 0 if non-cat, 1 if cat)
            caches -- list of caches containing:
                        every cache of linear_activation_forward() with &quot;relu&quot; (it&apos;s caches[l], for l in range(L-1) i.e l = 0...L-2)
                        the cache of linear_activation_forward() with &quot;sigmoid&quot; (it&apos;s caches[L-1])
            
            Returns:
            grads -- A dictionary with the gradients
                     grads[&quot;dA&quot; + str(l)] = ...
                     grads[&quot;dW&quot; + str(l)] = ...
                     grads[&quot;db&quot; + str(l)] = ...
            &quot;&quot;&quot;</span>
            grads <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
            L <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>caches<span class="token punctuation">)</span> <span class="token comment"># the number of layers</span>
            m <span class="token operator">=</span> AL<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
            Y <span class="token operator">=</span> Y<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>AL<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment"># &#x5C06;Y&#x7684;shape&#x4FDD;&#x6301;&#x4E0E;AL&#x4E00;&#x81F4;</span>
        
            <span class="token comment"># &#x521D;&#x59CB;&#x5316;&#x53CD;&#x9988;</span>
            <span class="token comment">### START CODE HERE ### (1 line of code)</span>
            dAL <span class="token operator">=</span> <span class="token operator">-</span> <span class="token punctuation">(</span>np<span class="token punctuation">.</span>divide<span class="token punctuation">(</span>Y<span class="token punctuation">,</span> AL<span class="token punctuation">)</span> <span class="token operator">-</span> np<span class="token punctuation">.</span>divide<span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> Y<span class="token punctuation">,</span> <span class="token number">1</span> <span class="token operator">-</span> AL<span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token comment">### END CODE HERE ###</span>
            
            <span class="token comment"># &#x7B2C;L&#x5C42;(SIGMOID -&gt; LINEAR)&#x68AF;&#x5EA6;. &#x8F93;&#x5165;: &quot;AL, Y, caches&quot;. &#x8F93;&#x51FA;: &quot;grads[&quot;dAL&quot;], grads[&quot;dWL&quot;], grads[&quot;dbL&quot;]</span>
            <span class="token comment">### START CODE HERE ### (approx. 2 lines)</span>
            current_cache <span class="token operator">=</span> caches<span class="token punctuation">[</span>L<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
            grads<span class="token punctuation">[</span><span class="token string">&quot;dA&quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>L<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> grads<span class="token punctuation">[</span><span class="token string">&quot;dW&quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>L<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> grads<span class="token punctuation">[</span><span class="token string">&quot;db&quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>L<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> linear_activation_backward<span class="token punctuation">(</span>dAL<span class="token punctuation">,</span> current_cache<span class="token punctuation">,</span> <span class="token string">&apos;sigmoid&apos;</span><span class="token punctuation">)</span>
            <span class="token comment">### END CODE HERE ###</span>
            
            <span class="token keyword">for</span> l <span class="token keyword">in</span> <span class="token builtin">reversed</span><span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span>L <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token comment"># &#x7B2C;l&#x5C42;: (RELU -&gt; LINEAR) &#x68AF;&#x5EA6;.</span>
                <span class="token comment"># &#x8F93;&#x5165;: &quot;grads[&quot;dA&quot; + str(l + 2)], caches&quot;. &#x8F93;&#x51FA;: &quot;grads[&quot;dA&quot; + str(l + 1)] , grads[&quot;dW&quot; + str(l + 1)] , grads[&quot;db&quot; + str(l + 1)] </span>
                <span class="token comment">### START CODE HERE ### (approx. 5 lines)</span>
                current_cache <span class="token operator">=</span> caches<span class="token punctuation">[</span>l<span class="token punctuation">]</span>
                dA_prev_temp<span class="token punctuation">,</span> dW_temp<span class="token punctuation">,</span> db_temp <span class="token operator">=</span> linear_activation_backward<span class="token punctuation">(</span>grads<span class="token punctuation">[</span><span class="token string">&quot;dA&quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>l<span class="token operator">+</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> current_cache<span class="token punctuation">,</span> <span class="token string">&apos;relu&apos;</span><span class="token punctuation">)</span>
                grads<span class="token punctuation">[</span><span class="token string">&quot;dA&quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>l <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> dA_prev_temp
                grads<span class="token punctuation">[</span><span class="token string">&quot;dW&quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>l <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> dW_temp
                grads<span class="token punctuation">[</span><span class="token string">&quot;db&quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>l <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> db_temp
                <span class="token comment">### END CODE HERE ###</span>
        
            <span class="token keyword">return</span> grads
        </pre><h2 class="mume-header" id="%E6%9B%B4%E6%96%B0%E5%8F%82%E6%95%B0">&#x66F4;&#x65B0;&#x53C2;&#x6570;</h2>
        
        <pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment"># GRADED FUNCTION: update_parameters</span>
        
        <span class="token keyword">def</span> <span class="token function">update_parameters</span><span class="token punctuation">(</span>parameters<span class="token punctuation">,</span> grads<span class="token punctuation">,</span> learning_rate<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token triple-quoted-string string">&quot;&quot;&quot;
            Update parameters using gradient descent
            
            Arguments:
            parameters -- python dictionary containing your parameters 
            grads -- python dictionary containing your gradients, output of L_model_backward
            
            Returns:
            parameters -- python dictionary containing your updated parameters 
                          parameters[&quot;W&quot; + str(l)] = ... 
                          parameters[&quot;b&quot; + str(l)] = ...
            &quot;&quot;&quot;</span>
            
            L <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>parameters<span class="token punctuation">)</span> <span class="token operator">//</span> <span class="token number">2</span> <span class="token comment"># &#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x5C42;&#x6570;</span>
        
            <span class="token comment"># &#x5FAA;&#x73AF;&#x66F4;&#x65B0;W[l]&#x548C;b[l]</span>
            <span class="token comment">### START CODE HERE ### (&#x2248; 3 lines of code)</span>
            <span class="token keyword">for</span> l <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>L<span class="token punctuation">)</span><span class="token punctuation">:</span>
                parameters<span class="token punctuation">[</span><span class="token string">&quot;W&quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>l<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> parameters<span class="token punctuation">[</span><span class="token string">&quot;W&quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>l<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">-</span> learning_rate <span class="token operator">*</span> grads<span class="token punctuation">[</span><span class="token string">&quot;dW&quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>l<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
                parameters<span class="token punctuation">[</span><span class="token string">&quot;b&quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>l<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> parameters<span class="token punctuation">[</span><span class="token string">&quot;b&quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>l<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">-</span> learning_rate <span class="token operator">*</span> grads<span class="token punctuation">[</span><span class="token string">&quot;db&quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>l<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
            <span class="token comment">### END CODE HERE ###</span>
                
            <span class="token keyword">return</span> parameters
        </pre><h1 class="mume-header" id="%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB-%E5%BA%94%E7%94%A8">&#x6DF1;&#x5C42;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x7684;&#x56FE;&#x50CF;&#x8BC6;&#x522B;: &#x5E94;&#x7528;</h1>
        
        <h2 class="mume-header" id="%E7%9B%AE%E6%A0%87-1">&#x76EE;&#x6807;</h2>
        
        <p>&#x5EFA;&#x7ACB;&#x548C;&#x5E94;&#x7528;&#x6DF1;&#x5EA6;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x76D1;&#x7763;&#x5B66;&#x4E60;&#x3002;</p>
        <h2 class="mume-header" id="%E5%AF%BC%E5%8C%85-1">&#x5BFC;&#x5305;</h2>
        
        <pre data-role="codeBlock" data-info="python" class="language-python"><span class="token keyword">import</span> time
        <span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
        <span class="token keyword">import</span> h5py
        <span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
        <span class="token keyword">import</span> scipy
        <span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image
        <span class="token keyword">from</span> scipy <span class="token keyword">import</span> ndimage
        <span class="token keyword">from</span> dnn_app_utils_v2 <span class="token keyword">import</span> <span class="token operator">*</span>
        
        <span class="token operator">%</span>matplotlib inline
        plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">&apos;figure.figsize&apos;</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">5.0</span><span class="token punctuation">,</span> <span class="token number">4.0</span><span class="token punctuation">)</span> <span class="token comment"># set default size of plots</span>
        plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">&apos;image.interpolation&apos;</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">&apos;nearest&apos;</span>
        plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">&apos;image.cmap&apos;</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">&apos;gray&apos;</span>
        
        <span class="token operator">%</span>load_ext autoreload
        <span class="token operator">%</span>autoreload <span class="token number">2</span>
        
        np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
        </pre><p>&#x4E3A;&#x4E86;&#x907F;&#x514D;&#x5927;&#x5BB6;&#x627E;&#x4E0D;&#x5230;&#x5305;&#xFF0C;&#x5305;&#x4EE3;&#x7801;&#x5C31;&#x8D34;&#x8FD9;&#x91CC;&#x4E86;&#xFF0C;&#x60F3;&#x8981;&#x81EA;&#x53D6;&#x5373;&#x53EF;&#x3002;</p>
        <h3 class="mume-header" id="dnn_app_utils_v2py">dnn_app_utils_v2.py</h3>
        
        <pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment"># dnn_app_untils_v2</span>
        <span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
        <span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
        <span class="token keyword">import</span> h5py
        
        
        <span class="token keyword">def</span> <span class="token function">sigmoid</span><span class="token punctuation">(</span>Z<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token triple-quoted-string string">&quot;&quot;&quot;
            Implements the sigmoid activation in numpy
            
            Arguments:
            Z -- numpy array of any shape
            
            Returns:
            A -- output of sigmoid(z), same shape as Z
            cache -- returns Z as well, useful during backpropagation
            &quot;&quot;&quot;</span>
            
            A <span class="token operator">=</span> <span class="token number">1</span><span class="token operator">/</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">+</span>np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span>Z<span class="token punctuation">)</span><span class="token punctuation">)</span>
            cache <span class="token operator">=</span> Z
            
            <span class="token keyword">return</span> A<span class="token punctuation">,</span> cache
        
        <span class="token keyword">def</span> <span class="token function">relu</span><span class="token punctuation">(</span>Z<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token triple-quoted-string string">&quot;&quot;&quot;
            Implement the RELU function.
        
            Arguments:
            Z -- Output of the linear layer, of any shape
        
            Returns:
            A -- Post-activation parameter, of the same shape as Z
            cache -- a python dictionary containing &quot;A&quot; ; stored for computing the backward pass efficiently
            &quot;&quot;&quot;</span>
            
            A <span class="token operator">=</span> np<span class="token punctuation">.</span>maximum<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span>Z<span class="token punctuation">)</span>
            
            <span class="token keyword">assert</span><span class="token punctuation">(</span>A<span class="token punctuation">.</span>shape <span class="token operator">==</span> Z<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
            
            cache <span class="token operator">=</span> Z 
            <span class="token keyword">return</span> A<span class="token punctuation">,</span> cache
        
        
        <span class="token keyword">def</span> <span class="token function">relu_backward</span><span class="token punctuation">(</span>dA<span class="token punctuation">,</span> cache<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token triple-quoted-string string">&quot;&quot;&quot;
            Implement the backward propagation for a single RELU unit.
        
            Arguments:
            dA -- post-activation gradient, of any shape
            cache -- &apos;Z&apos; where we store for computing backward propagation efficiently
        
            Returns:
            dZ -- Gradient of the cost with respect to Z
            &quot;&quot;&quot;</span>
            
            Z <span class="token operator">=</span> cache
            dZ <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>dA<span class="token punctuation">,</span> copy<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span> <span class="token comment"># just converting dz to a correct object.</span>
            
            <span class="token comment"># When z &lt;= 0, you should set dz to 0 as well. </span>
            dZ<span class="token punctuation">[</span>Z <span class="token operator">&lt;=</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>
            
            <span class="token keyword">assert</span> <span class="token punctuation">(</span>dZ<span class="token punctuation">.</span>shape <span class="token operator">==</span> Z<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
            
            <span class="token keyword">return</span> dZ
        
        <span class="token keyword">def</span> <span class="token function">sigmoid_backward</span><span class="token punctuation">(</span>dA<span class="token punctuation">,</span> cache<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token triple-quoted-string string">&quot;&quot;&quot;
            Implement the backward propagation for a single SIGMOID unit.
        
            Arguments:
            dA -- post-activation gradient, of any shape
            cache -- &apos;Z&apos; where we store for computing backward propagation efficiently
        
            Returns:
            dZ -- Gradient of the cost with respect to Z
            &quot;&quot;&quot;</span>
            
            Z <span class="token operator">=</span> cache
            
            s <span class="token operator">=</span> <span class="token number">1</span><span class="token operator">/</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">+</span>np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span>Z<span class="token punctuation">)</span><span class="token punctuation">)</span>
            dZ <span class="token operator">=</span> dA <span class="token operator">*</span> s <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span>s<span class="token punctuation">)</span>
            
            <span class="token keyword">assert</span> <span class="token punctuation">(</span>dZ<span class="token punctuation">.</span>shape <span class="token operator">==</span> Z<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
            
            <span class="token keyword">return</span> dZ
        
        
        <span class="token keyword">def</span> <span class="token function">load_data</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            train_dataset <span class="token operator">=</span> h5py<span class="token punctuation">.</span>File<span class="token punctuation">(</span><span class="token string">&apos;train_catvnoncat.h5&apos;</span><span class="token punctuation">,</span> <span class="token string">&quot;r&quot;</span><span class="token punctuation">)</span>
            train_set_x_orig <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>train_dataset<span class="token punctuation">[</span><span class="token string">&quot;train_set_x&quot;</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># your train set features</span>
            train_set_y_orig <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>train_dataset<span class="token punctuation">[</span><span class="token string">&quot;train_set_y&quot;</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># your train set labels</span>
        
            test_dataset <span class="token operator">=</span> h5py<span class="token punctuation">.</span>File<span class="token punctuation">(</span><span class="token string">&apos;test_catvnoncat.h5&apos;</span><span class="token punctuation">,</span> <span class="token string">&quot;r&quot;</span><span class="token punctuation">)</span>
            test_set_x_orig <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>test_dataset<span class="token punctuation">[</span><span class="token string">&quot;test_set_x&quot;</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># your test set features</span>
            test_set_y_orig <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>test_dataset<span class="token punctuation">[</span><span class="token string">&quot;test_set_y&quot;</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># your test set labels</span>
        
            classes <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>test_dataset<span class="token punctuation">[</span><span class="token string">&quot;list_classes&quot;</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># the list of classes</span>
            
            train_set_y_orig <span class="token operator">=</span> train_set_y_orig<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> train_set_y_orig<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            test_set_y_orig <span class="token operator">=</span> test_set_y_orig<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> test_set_y_orig<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            
            <span class="token keyword">return</span> train_set_x_orig<span class="token punctuation">,</span> train_set_y_orig<span class="token punctuation">,</span> test_set_x_orig<span class="token punctuation">,</span> test_set_y_orig<span class="token punctuation">,</span> classes
        
        
        <span class="token keyword">def</span> <span class="token function">initialize_parameters</span><span class="token punctuation">(</span>n_x<span class="token punctuation">,</span> n_h<span class="token punctuation">,</span> n_y<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token triple-quoted-string string">&quot;&quot;&quot;
            Argument:
            n_x -- size of the input layer
            n_h -- size of the hidden layer
            n_y -- size of the output layer
            
            Returns:
            parameters -- python dictionary containing your parameters:
                            W1 -- weight matrix of shape (n_h, n_x)
                            b1 -- bias vector of shape (n_h, 1)
                            W2 -- weight matrix of shape (n_y, n_h)
                            b2 -- bias vector of shape (n_y, 1)
            &quot;&quot;&quot;</span>
            
            np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
            
            W1 <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>n_h<span class="token punctuation">,</span> n_x<span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">0.01</span>
            b1 <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>n_h<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            W2 <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>n_y<span class="token punctuation">,</span> n_h<span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">0.01</span>
            b2 <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>n_y<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            
            <span class="token keyword">assert</span><span class="token punctuation">(</span>W1<span class="token punctuation">.</span>shape <span class="token operator">==</span> <span class="token punctuation">(</span>n_h<span class="token punctuation">,</span> n_x<span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token keyword">assert</span><span class="token punctuation">(</span>b1<span class="token punctuation">.</span>shape <span class="token operator">==</span> <span class="token punctuation">(</span>n_h<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token keyword">assert</span><span class="token punctuation">(</span>W2<span class="token punctuation">.</span>shape <span class="token operator">==</span> <span class="token punctuation">(</span>n_y<span class="token punctuation">,</span> n_h<span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token keyword">assert</span><span class="token punctuation">(</span>b2<span class="token punctuation">.</span>shape <span class="token operator">==</span> <span class="token punctuation">(</span>n_y<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            
            parameters <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;W1&quot;</span><span class="token punctuation">:</span> W1<span class="token punctuation">,</span>
                          <span class="token string">&quot;b1&quot;</span><span class="token punctuation">:</span> b1<span class="token punctuation">,</span>
                          <span class="token string">&quot;W2&quot;</span><span class="token punctuation">:</span> W2<span class="token punctuation">,</span>
                          <span class="token string">&quot;b2&quot;</span><span class="token punctuation">:</span> b2<span class="token punctuation">}</span>
            
            <span class="token keyword">return</span> parameters     
        
        
        <span class="token keyword">def</span> <span class="token function">initialize_parameters_deep</span><span class="token punctuation">(</span>layer_dims<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token triple-quoted-string string">&quot;&quot;&quot;
            Arguments:
            layer_dims -- python array (list) containing the dimensions of each layer in our network
            
            Returns:
            parameters -- python dictionary containing your parameters &quot;W1&quot;, &quot;b1&quot;, ..., &quot;WL&quot;, &quot;bL&quot;:
                            Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])
                            bl -- bias vector of shape (layer_dims[l], 1)
            &quot;&quot;&quot;</span>
            
            np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
            parameters <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
            L <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>layer_dims<span class="token punctuation">)</span>            <span class="token comment"># number of layers in the network</span>
        
            <span class="token keyword">for</span> l <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> L<span class="token punctuation">)</span><span class="token punctuation">:</span>
                parameters<span class="token punctuation">[</span><span class="token string">&apos;W&apos;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>l<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>layer_dims<span class="token punctuation">[</span>l<span class="token punctuation">]</span><span class="token punctuation">,</span> layer_dims<span class="token punctuation">[</span>l<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">/</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>layer_dims<span class="token punctuation">[</span>l<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment">#*0.01</span>
                parameters<span class="token punctuation">[</span><span class="token string">&apos;b&apos;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>l<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>layer_dims<span class="token punctuation">[</span>l<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                
                <span class="token keyword">assert</span><span class="token punctuation">(</span>parameters<span class="token punctuation">[</span><span class="token string">&apos;W&apos;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>l<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape <span class="token operator">==</span> <span class="token punctuation">(</span>layer_dims<span class="token punctuation">[</span>l<span class="token punctuation">]</span><span class="token punctuation">,</span> layer_dims<span class="token punctuation">[</span>l<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token keyword">assert</span><span class="token punctuation">(</span>parameters<span class="token punctuation">[</span><span class="token string">&apos;b&apos;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>l<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape <span class="token operator">==</span> <span class="token punctuation">(</span>layer_dims<span class="token punctuation">[</span>l<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        
                
            <span class="token keyword">return</span> parameters
        
        <span class="token keyword">def</span> <span class="token function">linear_forward</span><span class="token punctuation">(</span>A<span class="token punctuation">,</span> W<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token triple-quoted-string string">&quot;&quot;&quot;
            Implement the linear part of a layer&apos;s forward propagation.
        
            Arguments:
            A -- activations from previous layer (or input data): (size of previous layer, number of examples)
            W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)
            b -- bias vector, numpy array of shape (size of the current layer, 1)
        
            Returns:
            Z -- the input of the activation function, also called pre-activation parameter 
            cache -- a python dictionary containing &quot;A&quot;, &quot;W&quot; and &quot;b&quot; ; stored for computing the backward pass efficiently
            &quot;&quot;&quot;</span>
            
            Z <span class="token operator">=</span> W<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>A<span class="token punctuation">)</span> <span class="token operator">+</span> b
            
            <span class="token keyword">assert</span><span class="token punctuation">(</span>Z<span class="token punctuation">.</span>shape <span class="token operator">==</span> <span class="token punctuation">(</span>W<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> A<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            cache <span class="token operator">=</span> <span class="token punctuation">(</span>A<span class="token punctuation">,</span> W<span class="token punctuation">,</span> b<span class="token punctuation">)</span>
            
            <span class="token keyword">return</span> Z<span class="token punctuation">,</span> cache
        
        <span class="token keyword">def</span> <span class="token function">linear_activation_forward</span><span class="token punctuation">(</span>A_prev<span class="token punctuation">,</span> W<span class="token punctuation">,</span> b<span class="token punctuation">,</span> activation<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token triple-quoted-string string">&quot;&quot;&quot;
            Implement the forward propagation for the LINEAR-&gt;ACTIVATION layer
        
            Arguments:
            A_prev -- activations from previous layer (or input data): (size of previous layer, number of examples)
            W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)
            b -- bias vector, numpy array of shape (size of the current layer, 1)
            activation -- the activation to be used in this layer, stored as a text string: &quot;sigmoid&quot; or &quot;relu&quot;
        
            Returns:
            A -- the output of the activation function, also called the post-activation value 
            cache -- a python dictionary containing &quot;linear_cache&quot; and &quot;activation_cache&quot;;
                     stored for computing the backward pass efficiently
            &quot;&quot;&quot;</span>
            
            <span class="token keyword">if</span> activation <span class="token operator">==</span> <span class="token string">&quot;sigmoid&quot;</span><span class="token punctuation">:</span>
                <span class="token comment"># Inputs: &quot;A_prev, W, b&quot;. Outputs: &quot;A, activation_cache&quot;.</span>
                Z<span class="token punctuation">,</span> linear_cache <span class="token operator">=</span> linear_forward<span class="token punctuation">(</span>A_prev<span class="token punctuation">,</span> W<span class="token punctuation">,</span> b<span class="token punctuation">)</span>
                A<span class="token punctuation">,</span> activation_cache <span class="token operator">=</span> sigmoid<span class="token punctuation">(</span>Z<span class="token punctuation">)</span>
            
            <span class="token keyword">elif</span> activation <span class="token operator">==</span> <span class="token string">&quot;relu&quot;</span><span class="token punctuation">:</span>
                <span class="token comment"># Inputs: &quot;A_prev, W, b&quot;. Outputs: &quot;A, activation_cache&quot;.</span>
                Z<span class="token punctuation">,</span> linear_cache <span class="token operator">=</span> linear_forward<span class="token punctuation">(</span>A_prev<span class="token punctuation">,</span> W<span class="token punctuation">,</span> b<span class="token punctuation">)</span>
                A<span class="token punctuation">,</span> activation_cache <span class="token operator">=</span> relu<span class="token punctuation">(</span>Z<span class="token punctuation">)</span>
            
            <span class="token keyword">assert</span> <span class="token punctuation">(</span>A<span class="token punctuation">.</span>shape <span class="token operator">==</span> <span class="token punctuation">(</span>W<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> A_prev<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            cache <span class="token operator">=</span> <span class="token punctuation">(</span>linear_cache<span class="token punctuation">,</span> activation_cache<span class="token punctuation">)</span>
        
            <span class="token keyword">return</span> A<span class="token punctuation">,</span> cache
        
        <span class="token keyword">def</span> <span class="token function">L_model_forward</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> parameters<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token triple-quoted-string string">&quot;&quot;&quot;
            Implement forward propagation for the [LINEAR-&gt;RELU]*(L-1)-&gt;LINEAR-&gt;SIGMOID computation
            
            Arguments:
            X -- data, numpy array of shape (input size, number of examples)
            parameters -- output of initialize_parameters_deep()
            
            Returns:
            AL -- last post-activation value
            caches -- list of caches containing:
                        every cache of linear_relu_forward() (there are L-1 of them, indexed from 0 to L-2)
                        the cache of linear_sigmoid_forward() (there is one, indexed L-1)
            &quot;&quot;&quot;</span>
        
            caches <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
            A <span class="token operator">=</span> X
            L <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>parameters<span class="token punctuation">)</span> <span class="token operator">//</span> <span class="token number">2</span>                  <span class="token comment"># number of layers in the neural network</span>
            
            <span class="token comment"># Implement [LINEAR -&gt; RELU]*(L-1). Add &quot;cache&quot; to the &quot;caches&quot; list.</span>
            <span class="token keyword">for</span> l <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> L<span class="token punctuation">)</span><span class="token punctuation">:</span>
                A_prev <span class="token operator">=</span> A 
                A<span class="token punctuation">,</span> cache <span class="token operator">=</span> linear_activation_forward<span class="token punctuation">(</span>A_prev<span class="token punctuation">,</span> parameters<span class="token punctuation">[</span><span class="token string">&apos;W&apos;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>l<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> parameters<span class="token punctuation">[</span><span class="token string">&apos;b&apos;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>l<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> activation <span class="token operator">=</span> <span class="token string">&quot;relu&quot;</span><span class="token punctuation">)</span>
                caches<span class="token punctuation">.</span>append<span class="token punctuation">(</span>cache<span class="token punctuation">)</span>
            
            <span class="token comment"># Implement LINEAR -&gt; SIGMOID. Add &quot;cache&quot; to the &quot;caches&quot; list.</span>
            AL<span class="token punctuation">,</span> cache <span class="token operator">=</span> linear_activation_forward<span class="token punctuation">(</span>A<span class="token punctuation">,</span> parameters<span class="token punctuation">[</span><span class="token string">&apos;W&apos;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>L<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> parameters<span class="token punctuation">[</span><span class="token string">&apos;b&apos;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>L<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> activation <span class="token operator">=</span> <span class="token string">&quot;sigmoid&quot;</span><span class="token punctuation">)</span>
            caches<span class="token punctuation">.</span>append<span class="token punctuation">(</span>cache<span class="token punctuation">)</span>
            
            <span class="token keyword">assert</span><span class="token punctuation">(</span>AL<span class="token punctuation">.</span>shape <span class="token operator">==</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                    
            <span class="token keyword">return</span> AL<span class="token punctuation">,</span> caches
        
        <span class="token keyword">def</span> <span class="token function">compute_cost</span><span class="token punctuation">(</span>AL<span class="token punctuation">,</span> Y<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token triple-quoted-string string">&quot;&quot;&quot;
            Implement the cost function defined by equation (7).
        
            Arguments:
            AL -- probability vector corresponding to your label predictions, shape (1, number of examples)
            Y -- true &quot;label&quot; vector (for example: containing 0 if non-cat, 1 if cat), shape (1, number of examples)
        
            Returns:
            cost -- cross-entropy cost
            &quot;&quot;&quot;</span>
            
            m <span class="token operator">=</span> Y<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
        
            <span class="token comment"># Compute loss from aL and y.</span>
            cost <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token operator">/</span>m<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token operator">-</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>Y<span class="token punctuation">,</span>np<span class="token punctuation">.</span>log<span class="token punctuation">(</span>AL<span class="token punctuation">)</span><span class="token punctuation">.</span>T<span class="token punctuation">)</span> <span class="token operator">-</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span>Y<span class="token punctuation">,</span> np<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span>AL<span class="token punctuation">)</span><span class="token punctuation">.</span>T<span class="token punctuation">)</span><span class="token punctuation">)</span>
            
            cost <span class="token operator">=</span> np<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>cost<span class="token punctuation">)</span>      <span class="token comment"># To make sure your cost&apos;s shape is what we expect (e.g. this turns [[17]] into 17).</span>
            <span class="token keyword">assert</span><span class="token punctuation">(</span>cost<span class="token punctuation">.</span>shape <span class="token operator">==</span> <span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            
            <span class="token keyword">return</span> cost
        
        <span class="token keyword">def</span> <span class="token function">linear_backward</span><span class="token punctuation">(</span>dZ<span class="token punctuation">,</span> cache<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token triple-quoted-string string">&quot;&quot;&quot;
            Implement the linear portion of backward propagation for a single layer (layer l)
        
            Arguments:
            dZ -- Gradient of the cost with respect to the linear output (of current layer l)
            cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer
        
            Returns:
            dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev
            dW -- Gradient of the cost with respect to W (current layer l), same shape as W
            db -- Gradient of the cost with respect to b (current layer l), same shape as b
            &quot;&quot;&quot;</span>
            A_prev<span class="token punctuation">,</span> W<span class="token punctuation">,</span> b <span class="token operator">=</span> cache
            m <span class="token operator">=</span> A_prev<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
        
            dW <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token operator">/</span>m <span class="token operator">*</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>dZ<span class="token punctuation">,</span>A_prev<span class="token punctuation">.</span>T<span class="token punctuation">)</span>
            db <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token operator">/</span>m <span class="token operator">*</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dZ<span class="token punctuation">,</span> axis <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span> keepdims <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
            dA_prev <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>W<span class="token punctuation">.</span>T<span class="token punctuation">,</span>dZ<span class="token punctuation">)</span>
            
            <span class="token keyword">assert</span> <span class="token punctuation">(</span>dA_prev<span class="token punctuation">.</span>shape <span class="token operator">==</span> A_prev<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
            <span class="token keyword">assert</span> <span class="token punctuation">(</span>dW<span class="token punctuation">.</span>shape <span class="token operator">==</span> W<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
            <span class="token keyword">assert</span> <span class="token punctuation">(</span>db<span class="token punctuation">.</span>shape <span class="token operator">==</span> b<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
            
            <span class="token keyword">return</span> dA_prev<span class="token punctuation">,</span> dW<span class="token punctuation">,</span> db
        
        <span class="token keyword">def</span> <span class="token function">linear_activation_backward</span><span class="token punctuation">(</span>dA<span class="token punctuation">,</span> cache<span class="token punctuation">,</span> activation<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token triple-quoted-string string">&quot;&quot;&quot;
            Implement the backward propagation for the LINEAR-&gt;ACTIVATION layer.
            
            Arguments:
            dA -- post-activation gradient for current layer l 
            cache -- tuple of values (linear_cache, activation_cache) we store for computing backward propagation efficiently
            activation -- the activation to be used in this layer, stored as a text string: &quot;sigmoid&quot; or &quot;relu&quot;
            
            Returns:
            dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev
            dW -- Gradient of the cost with respect to W (current layer l), same shape as W
            db -- Gradient of the cost with respect to b (current layer l), same shape as b
            &quot;&quot;&quot;</span>
            linear_cache<span class="token punctuation">,</span> activation_cache <span class="token operator">=</span> cache
            
            <span class="token keyword">if</span> activation <span class="token operator">==</span> <span class="token string">&quot;relu&quot;</span><span class="token punctuation">:</span>
                dZ <span class="token operator">=</span> relu_backward<span class="token punctuation">(</span>dA<span class="token punctuation">,</span> activation_cache<span class="token punctuation">)</span>
                dA_prev<span class="token punctuation">,</span> dW<span class="token punctuation">,</span> db <span class="token operator">=</span> linear_backward<span class="token punctuation">(</span>dZ<span class="token punctuation">,</span> linear_cache<span class="token punctuation">)</span>
                
            <span class="token keyword">elif</span> activation <span class="token operator">==</span> <span class="token string">&quot;sigmoid&quot;</span><span class="token punctuation">:</span>
                dZ <span class="token operator">=</span> sigmoid_backward<span class="token punctuation">(</span>dA<span class="token punctuation">,</span> activation_cache<span class="token punctuation">)</span>
                dA_prev<span class="token punctuation">,</span> dW<span class="token punctuation">,</span> db <span class="token operator">=</span> linear_backward<span class="token punctuation">(</span>dZ<span class="token punctuation">,</span> linear_cache<span class="token punctuation">)</span>
            
            <span class="token keyword">return</span> dA_prev<span class="token punctuation">,</span> dW<span class="token punctuation">,</span> db
        
        <span class="token keyword">def</span> <span class="token function">L_model_backward</span><span class="token punctuation">(</span>AL<span class="token punctuation">,</span> Y<span class="token punctuation">,</span> caches<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token triple-quoted-string string">&quot;&quot;&quot;
            Implement the backward propagation for the [LINEAR-&gt;RELU] * (L-1) -&gt; LINEAR -&gt; SIGMOID group
            
            Arguments:
            AL -- probability vector, output of the forward propagation (L_model_forward())
            Y -- true &quot;label&quot; vector (containing 0 if non-cat, 1 if cat)
            caches -- list of caches containing:
                        every cache of linear_activation_forward() with &quot;relu&quot; (there are (L-1) or them, indexes from 0 to L-2)
                        the cache of linear_activation_forward() with &quot;sigmoid&quot; (there is one, index L-1)
            
            Returns:
            grads -- A dictionary with the gradients
                     grads[&quot;dA&quot; + str(l)] = ... 
                     grads[&quot;dW&quot; + str(l)] = ...
                     grads[&quot;db&quot; + str(l)] = ... 
            &quot;&quot;&quot;</span>
            grads <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
            L <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>caches<span class="token punctuation">)</span> <span class="token comment"># the number of layers</span>
            m <span class="token operator">=</span> AL<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
            Y <span class="token operator">=</span> Y<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>AL<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment"># after this line, Y is the same shape as AL</span>
            
            <span class="token comment"># Initializing the backpropagation</span>
            dAL <span class="token operator">=</span> <span class="token operator">-</span> <span class="token punctuation">(</span>np<span class="token punctuation">.</span>divide<span class="token punctuation">(</span>Y<span class="token punctuation">,</span> AL<span class="token punctuation">)</span> <span class="token operator">-</span> np<span class="token punctuation">.</span>divide<span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> Y<span class="token punctuation">,</span> <span class="token number">1</span> <span class="token operator">-</span> AL<span class="token punctuation">)</span><span class="token punctuation">)</span>
            
            <span class="token comment"># Lth layer (SIGMOID -&gt; LINEAR) gradients. Inputs: &quot;AL, Y, caches&quot;. Outputs: &quot;grads[&quot;dAL&quot;], grads[&quot;dWL&quot;], grads[&quot;dbL&quot;]</span>
            current_cache <span class="token operator">=</span> caches<span class="token punctuation">[</span>L<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
            grads<span class="token punctuation">[</span><span class="token string">&quot;dA&quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>L<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> grads<span class="token punctuation">[</span><span class="token string">&quot;dW&quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>L<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> grads<span class="token punctuation">[</span><span class="token string">&quot;db&quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>L<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> linear_activation_backward<span class="token punctuation">(</span>dAL<span class="token punctuation">,</span> current_cache<span class="token punctuation">,</span> activation <span class="token operator">=</span> <span class="token string">&quot;sigmoid&quot;</span><span class="token punctuation">)</span>
            
            <span class="token keyword">for</span> l <span class="token keyword">in</span> <span class="token builtin">reversed</span><span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span>L<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token comment"># lth layer: (RELU -&gt; LINEAR) gradients.</span>
                current_cache <span class="token operator">=</span> caches<span class="token punctuation">[</span>l<span class="token punctuation">]</span>
                dA_prev_temp<span class="token punctuation">,</span> dW_temp<span class="token punctuation">,</span> db_temp <span class="token operator">=</span> linear_activation_backward<span class="token punctuation">(</span>grads<span class="token punctuation">[</span><span class="token string">&quot;dA&quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>l <span class="token operator">+</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> current_cache<span class="token punctuation">,</span> activation <span class="token operator">=</span> <span class="token string">&quot;relu&quot;</span><span class="token punctuation">)</span>
                grads<span class="token punctuation">[</span><span class="token string">&quot;dA&quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>l <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> dA_prev_temp
                grads<span class="token punctuation">[</span><span class="token string">&quot;dW&quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>l <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> dW_temp
                grads<span class="token punctuation">[</span><span class="token string">&quot;db&quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>l <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> db_temp
        
            <span class="token keyword">return</span> grads
        
        <span class="token keyword">def</span> <span class="token function">update_parameters</span><span class="token punctuation">(</span>parameters<span class="token punctuation">,</span> grads<span class="token punctuation">,</span> learning_rate<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token triple-quoted-string string">&quot;&quot;&quot;
            Update parameters using gradient descent
            
            Arguments:
            parameters -- python dictionary containing your parameters 
            grads -- python dictionary containing your gradients, output of L_model_backward
            
            Returns:
            parameters -- python dictionary containing your updated parameters 
                          parameters[&quot;W&quot; + str(l)] = ... 
                          parameters[&quot;b&quot; + str(l)] = ...
            &quot;&quot;&quot;</span>
            
            L <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>parameters<span class="token punctuation">)</span> <span class="token operator">//</span> <span class="token number">2</span> <span class="token comment"># number of layers in the neural network</span>
        
            <span class="token comment"># Update rule for each parameter. Use a for loop.</span>
            <span class="token keyword">for</span> l <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>L<span class="token punctuation">)</span><span class="token punctuation">:</span>
                parameters<span class="token punctuation">[</span><span class="token string">&quot;W&quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>l<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> parameters<span class="token punctuation">[</span><span class="token string">&quot;W&quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>l<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">-</span> learning_rate <span class="token operator">*</span> grads<span class="token punctuation">[</span><span class="token string">&quot;dW&quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>l<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
                parameters<span class="token punctuation">[</span><span class="token string">&quot;b&quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>l<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> parameters<span class="token punctuation">[</span><span class="token string">&quot;b&quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>l<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">-</span> learning_rate <span class="token operator">*</span> grads<span class="token punctuation">[</span><span class="token string">&quot;db&quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>l<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
                
            <span class="token keyword">return</span> parameters
        
        <span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> parameters<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token triple-quoted-string string">&quot;&quot;&quot;
            This function is used to predict the results of a  L-layer neural network.
            
            Arguments:
            X -- data set of examples you would like to label
            parameters -- parameters of the trained model
            
            Returns:
            p -- predictions for the given dataset X
            &quot;&quot;&quot;</span>
            
            m <span class="token operator">=</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
            n <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>parameters<span class="token punctuation">)</span> <span class="token operator">//</span> <span class="token number">2</span> <span class="token comment"># number of layers in the neural network</span>
            p <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>m<span class="token punctuation">)</span><span class="token punctuation">)</span>
            
            <span class="token comment"># Forward propagation</span>
            probas<span class="token punctuation">,</span> caches <span class="token operator">=</span> L_model_forward<span class="token punctuation">(</span>X<span class="token punctuation">,</span> parameters<span class="token punctuation">)</span>
        
            
            <span class="token comment"># convert probas to 0/1 predictions</span>
            <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> probas<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token keyword">if</span> probas<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span>i<span class="token punctuation">]</span> <span class="token operator">&gt;</span> <span class="token number">0.5</span><span class="token punctuation">:</span>
                    p<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>
                <span class="token keyword">else</span><span class="token punctuation">:</span>
                    p<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>
            
            <span class="token comment">#print results</span>
            <span class="token comment">#print (&quot;predictions: &quot; + str(p))</span>
            <span class="token comment">#print (&quot;true labels: &quot; + str(y))</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;Accuracy: &quot;</span>  <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">(</span>p <span class="token operator">==</span> y<span class="token punctuation">)</span><span class="token operator">/</span>m<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                
            <span class="token keyword">return</span> p
        
        <span class="token keyword">def</span> <span class="token function">print_mislabeled_images</span><span class="token punctuation">(</span>classes<span class="token punctuation">,</span> X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> p<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token triple-quoted-string string">&quot;&quot;&quot;
            Plots images where predictions and truth were different.
            X -- dataset
            y -- true labels
            p -- predictions
            &quot;&quot;&quot;</span>
            a <span class="token operator">=</span> p <span class="token operator">+</span> y
            mislabeled_indices <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>a <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">&apos;figure.figsize&apos;</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">40.0</span><span class="token punctuation">,</span> <span class="token number">40.0</span><span class="token punctuation">)</span> <span class="token comment"># set default size of plots</span>
            num_images <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>mislabeled_indices<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_images<span class="token punctuation">)</span><span class="token punctuation">:</span>
                index <span class="token operator">=</span> mislabeled_indices<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span>
                
                plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> num_images<span class="token punctuation">,</span> i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>
                plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span>index<span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> interpolation<span class="token operator">=</span><span class="token string">&apos;nearest&apos;</span><span class="token punctuation">)</span>
                plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">&apos;off&apos;</span><span class="token punctuation">)</span>
                plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">&quot;Prediction: &quot;</span> <span class="token operator">+</span> classes<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>p<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span>index<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token string">&quot;utf-8&quot;</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">&quot; \n Class: &quot;</span> <span class="token operator">+</span> classes<span class="token punctuation">[</span>y<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span>index<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token string">&quot;utf-8&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        </pre><h2 class="mume-header" id="%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E9%9B%86">&#x52A0;&#x8F7D;&#x6570;&#x636E;&#x96C6;</h2>
        
        <pre data-role="codeBlock" data-info="python" class="language-python">train_x_orig<span class="token punctuation">,</span> train_y<span class="token punctuation">,</span> test_x_orig<span class="token punctuation">,</span> test_y<span class="token punctuation">,</span> classes <span class="token operator">=</span> load_data<span class="token punctuation">(</span><span class="token punctuation">)</span>
        </pre><h3 class="mume-header" id="%E6%B5%8B%E8%AF%95%E6%98%AF%E5%90%A6%E6%88%90%E5%8A%9F%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE%E9%9B%86">&#x6D4B;&#x8BD5;&#x662F;&#x5426;&#x6210;&#x529F;&#x5BFC;&#x5165;&#x6570;&#x636E;&#x96C6;</h3>
        
        <pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment"># &#x4E00;&#x4E2A;&#x6570;&#x636E;&#x6837;&#x672C;&#x6837;&#x4F8B;</span>
        index <span class="token operator">=</span> <span class="token number">7</span>
        plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>train_x_orig<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&quot;y = &quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>train_y<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span>index<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">&quot;. It&apos;s a &quot;</span> <span class="token operator">+</span> classes<span class="token punctuation">[</span>train_y<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span>index<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token string">&quot;utf-8&quot;</span><span class="token punctuation">)</span> <span class="token operator">+</span>  <span class="token string">&quot; picture.&quot;</span><span class="token punctuation">)</span>
        </pre><h3 class="mume-header" id="%E6%B5%8B%E8%AF%95%E7%BB%93%E6%9E%9C">&#x6D4B;&#x8BD5;&#x7ED3;&#x679C;</h3>
        
        <img src="img/QQ&#x622A;&#x56FE;20200814094138.jpg" style="zoom:67%;">
        <h3 class="mume-header" id="%E6%A3%80%E6%B5%8B%E6%95%B0%E6%8D%AE%E9%9B%86shape">&#x68C0;&#x6D4B;&#x6570;&#x636E;&#x96C6;shape</h3>
        
        <pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment"># &#x5BFC;&#x5165;&#x6570;&#x636E;&#x96C6;</span>
        m_train <span class="token operator">=</span> train_x_orig<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        num_px <span class="token operator">=</span> train_x_orig<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
        m_test <span class="token operator">=</span> test_x_orig<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        
        <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&quot;Number of training examples: &quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>m_train<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&quot;Number of testing examples: &quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>m_test<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&quot;Each image is of size: (&quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>num_px<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">&quot;, &quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>num_px<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">&quot;, 3)&quot;</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&quot;train_x_orig shape: &quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>train_x_orig<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&quot;train_y shape: &quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>train_y<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&quot;test_x_orig shape: &quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>test_x_orig<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&quot;test_y shape: &quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>test_y<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
        </pre><h2 class="mume-header" id="%E6%A0%87%E5%87%86%E5%8C%96%E5%90%91%E9%87%8F%E5%8C%96%E6%95%B0%E6%8D%AE">&#x6807;&#x51C6;&#x5316;+&#x5411;&#x91CF;&#x5316;&#x6570;&#x636E;</h2>
        
        <pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment"># &#x6539;&#x53D8;&#x6D4B;&#x8BD5;&#x6837;&#x672C;&#x548C;&#x8BAD;&#x7EC3;&#x6837;&#x672C;&#x7684;shape&#xFF0C;&#x4F7F;&#x5176;&#x7B26;&#x5408;&#x8981;&#x6C42;&#x3010;shape&#x53D8;&#x4E3A;(&#x50CF;&#x7D20;&#x603B;&#x6570;*&#x901A;&#x9053;&#x6570;,&#x6837;&#x672C;&#x6570;)&#x3011;</span>
        train_x_flatten <span class="token operator">=</span> train_x_orig<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>train_x_orig<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>T   <span class="token comment"># &quot;-1&quot;&#x6307;reshape&#x5C06;&#x5355;&#x4E2A;&#x6837;&#x672C;&#x6241;&#x5E73;&#x5316;&#x5904;&#x7406;&#xFF08;&#x5411;&#x91CF;&#x5316;&#xFF09;</span>
        test_x_flatten <span class="token operator">=</span> test_x_orig<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>test_x_orig<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>T
        
        <span class="token comment"># &#x6807;&#x51C6;&#x5316;&#x6570;&#x636E;&#xFF0C;&#x4F7F;&#x6240;&#x6709;&#x7684;&#x7279;&#x5F81;&#x503C;&#x90FD;&#x5728;0,1&#x533A;&#x95F4;.</span>
        train_x <span class="token operator">=</span> train_x_flatten<span class="token operator">/</span><span class="token number">255</span><span class="token punctuation">.</span>
        test_x <span class="token operator">=</span> test_x_flatten<span class="token operator">/</span><span class="token number">255</span><span class="token punctuation">.</span>
        
        <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&quot;train_x&apos;s shape: &quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>train_x<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&quot;test_x&apos;s shape: &quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>test_x<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
        </pre><h3 class="mume-header" id="%E7%BB%93%E6%9E%9C">&#x7ED3;&#x679C;</h3>
        
        <pre data-role="codeBlock" data-info class="language-"><code>train_x&apos;s shape: (12288, 209)
        test_x&apos;s shape: (12288, 50)
        </code></pre><p>12288=64&#xD7;64&#xD7;3&#x3002;</p>
        <h2 class="mume-header" id="2%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">2&#x5C42;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;</h2>
        
        <h3 class="mume-header" id="%E5%9F%BA%E6%9C%AC%E5%8F%82%E6%95%B0">&#x57FA;&#x672C;&#x53C2;&#x6570;</h3>
        
        <pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment">### &#x5B9A;&#x4E49;&#x6A21;&#x578B;&#x7684;&#x56FA;&#x5B9A;&#x53C2;&#x6570; ####</span>
        n_x <span class="token operator">=</span> <span class="token number">12288</span>     <span class="token comment"># num_px * num_px * 3</span>
        n_h <span class="token operator">=</span> <span class="token number">7</span>
        n_y <span class="token operator">=</span> <span class="token number">1</span>
        layers_dims <span class="token operator">=</span> <span class="token punctuation">(</span>n_x<span class="token punctuation">,</span> n_h<span class="token punctuation">,</span> n_y<span class="token punctuation">)</span>
        
        </pre><h3 class="mume-header" id="%E6%9E%84%E5%BB%BA%E6%A8%A1%E5%9E%8B">&#x6784;&#x5EFA;&#x6A21;&#x578B;</h3>
        
        <pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment"># GRADED FUNCTION: two_layer_model</span>
        
        <span class="token keyword">def</span> <span class="token function">two_layer_model</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">,</span> layers_dims<span class="token punctuation">,</span> learning_rate <span class="token operator">=</span> <span class="token number">0.0075</span><span class="token punctuation">,</span> num_iterations <span class="token operator">=</span> <span class="token number">3000</span><span class="token punctuation">,</span> print_cost<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token triple-quoted-string string">&quot;&quot;&quot;
            Implements a two-layer neural network: LINEAR-&gt;RELU-&gt;LINEAR-&gt;SIGMOID.
            
            Arguments:
            X -- input data, of shape (n_x, number of examples)
            Y -- true &quot;label&quot; vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)
            layers_dims -- dimensions of the layers (n_x, n_h, n_y)
            num_iterations -- number of iterations of the optimization loop
            learning_rate -- learning rate of the gradient descent update rule
            print_cost -- If set to True, this will print the cost every 100 iterations 
            
            Returns:
            parameters -- a dictionary containing W1, W2, b1, and b2
            &quot;&quot;&quot;</span>
            
            np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
            grads <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
            costs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>                              <span class="token comment"># &#x8FFD;&#x8E2A;&#x6210;&#x672C;&#x51FD;&#x6570;</span>
            m <span class="token operator">=</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>                           <span class="token comment"># &#x6837;&#x4F8B;&#x6570;&#x91CF;</span>
            <span class="token punctuation">(</span>n_x<span class="token punctuation">,</span> n_h<span class="token punctuation">,</span> n_y<span class="token punctuation">)</span> <span class="token operator">=</span> layers_dims
            
            <span class="token comment"># &#x521D;&#x59CB;&#x5316;&#x53C2;&#x6570;&#x5B57;&#x5178;</span>
            <span class="token comment">### START CODE HERE ### (&#x2248; 1 line of code)</span>
            parameters <span class="token operator">=</span> initialize_parameters<span class="token punctuation">(</span>n_x<span class="token punctuation">,</span> n_h<span class="token punctuation">,</span> n_y<span class="token punctuation">)</span>
            <span class="token comment">### END CODE HERE ###</span>
            
            <span class="token comment"># &#x67E5;&#x8BE2;&#x5B57;&#x5178;&#x83B7;&#x5F97;W1, b1, W2, b2</span>
            W1 <span class="token operator">=</span> parameters<span class="token punctuation">[</span><span class="token string">&quot;W1&quot;</span><span class="token punctuation">]</span>
            b1 <span class="token operator">=</span> parameters<span class="token punctuation">[</span><span class="token string">&quot;b1&quot;</span><span class="token punctuation">]</span>
            W2 <span class="token operator">=</span> parameters<span class="token punctuation">[</span><span class="token string">&quot;W2&quot;</span><span class="token punctuation">]</span>
            b2 <span class="token operator">=</span> parameters<span class="token punctuation">[</span><span class="token string">&quot;b2&quot;</span><span class="token punctuation">]</span>
            
            <span class="token comment"># Loop (gradient descent)</span>
        
            <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> num_iterations<span class="token punctuation">)</span><span class="token punctuation">:</span>
        
                <span class="token comment"># &#x524D;&#x9988; LINEAR -&gt; RELU -&gt; LINEAR -&gt; SIGMOID. Inputs: &quot;X, W1, b1&quot;. Output: &quot;A1, cache1, A2, cache2&quot;.</span>
                <span class="token comment">### START CODE HERE ### (&#x2248; 2 lines of code)</span>
                A1<span class="token punctuation">,</span> cache1 <span class="token operator">=</span> linear_activation_forward<span class="token punctuation">(</span>X<span class="token punctuation">,</span> W1<span class="token punctuation">,</span> b1<span class="token punctuation">,</span> <span class="token string">&apos;relu&apos;</span><span class="token punctuation">)</span>
                A2<span class="token punctuation">,</span> cache2 <span class="token operator">=</span> linear_activation_forward<span class="token punctuation">(</span>A1<span class="token punctuation">,</span> W2<span class="token punctuation">,</span> b2<span class="token punctuation">,</span> <span class="token string">&apos;sigmoid&apos;</span><span class="token punctuation">)</span>
                <span class="token comment">### END CODE HERE ###</span>
                
                <span class="token comment"># &#x8BA1;&#x7B97;&#x6210;&#x672C;</span>
                <span class="token comment">### START CODE HERE ### (&#x2248; 1 line of code)</span>
                cost <span class="token operator">=</span> compute_cost<span class="token punctuation">(</span>A2<span class="token punctuation">,</span> Y<span class="token punctuation">)</span>
                <span class="token comment">### END CODE HERE ###</span>
                
                <span class="token comment"># &#x521D;&#x59CB;&#x5316;&#x53CD;&#x9988;</span>
                dA2 <span class="token operator">=</span> <span class="token operator">-</span> <span class="token punctuation">(</span>np<span class="token punctuation">.</span>divide<span class="token punctuation">(</span>Y<span class="token punctuation">,</span> A2<span class="token punctuation">)</span> <span class="token operator">-</span> np<span class="token punctuation">.</span>divide<span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> Y<span class="token punctuation">,</span> <span class="token number">1</span> <span class="token operator">-</span> A2<span class="token punctuation">)</span><span class="token punctuation">)</span>
                
                <span class="token comment"># &#x53CD;&#x9988;. Inputs: &quot;dA2, cache2, cache1&quot;. Outputs: &quot;dA1, dW2, db2; also dA0 (not used), dW1, db1&quot;.</span>
                <span class="token comment">### START CODE HERE ### (&#x2248; 2 lines of code)</span>
                dA1<span class="token punctuation">,</span> dW2<span class="token punctuation">,</span> db2 <span class="token operator">=</span> linear_activation_backward<span class="token punctuation">(</span>dA2<span class="token punctuation">,</span> cache2<span class="token punctuation">,</span> <span class="token string">&apos;sigmoid&apos;</span><span class="token punctuation">)</span>
                dA0<span class="token punctuation">,</span> dW1<span class="token punctuation">,</span> db1 <span class="token operator">=</span> linear_activation_backward<span class="token punctuation">(</span>dA1<span class="token punctuation">,</span> cache1<span class="token punctuation">,</span> <span class="token string">&apos;relu&apos;</span><span class="token punctuation">)</span>
                <span class="token comment">### END CODE HERE ###</span>
                
                <span class="token comment"># Set grads[&apos;dWl&apos;] to dW1, grads[&apos;db1&apos;] to db1, grads[&apos;dW2&apos;] to dW2, grads[&apos;db2&apos;] to db2</span>
                grads<span class="token punctuation">[</span><span class="token string">&apos;dW1&apos;</span><span class="token punctuation">]</span> <span class="token operator">=</span> dW1
                grads<span class="token punctuation">[</span><span class="token string">&apos;db1&apos;</span><span class="token punctuation">]</span> <span class="token operator">=</span> db1
                grads<span class="token punctuation">[</span><span class="token string">&apos;dW2&apos;</span><span class="token punctuation">]</span> <span class="token operator">=</span> dW2
                grads<span class="token punctuation">[</span><span class="token string">&apos;db2&apos;</span><span class="token punctuation">]</span> <span class="token operator">=</span> db2
                
                <span class="token comment"># &#x66F4;&#x65B0;&#x53C2;&#x6570;.</span>
                <span class="token comment">### START CODE HERE ### (approx. 1 line of code)</span>
                parameters <span class="token operator">=</span> update_parameters<span class="token punctuation">(</span>parameters<span class="token punctuation">,</span> grads<span class="token punctuation">,</span> learning_rate<span class="token punctuation">)</span>
                <span class="token comment">### END CODE HERE ###</span>
        
                <span class="token comment"># &#x83B7;&#x53D6; W1, b1, W2, b2</span>
                W1 <span class="token operator">=</span> parameters<span class="token punctuation">[</span><span class="token string">&quot;W1&quot;</span><span class="token punctuation">]</span>
                b1 <span class="token operator">=</span> parameters<span class="token punctuation">[</span><span class="token string">&quot;b1&quot;</span><span class="token punctuation">]</span>
                W2 <span class="token operator">=</span> parameters<span class="token punctuation">[</span><span class="token string">&quot;W2&quot;</span><span class="token punctuation">]</span>
                b2 <span class="token operator">=</span> parameters<span class="token punctuation">[</span><span class="token string">&quot;b2&quot;</span><span class="token punctuation">]</span>
                
                <span class="token comment"># &#x6BCF;100&#x4E2A;&#x8BAD;&#x7EC3;&#x6837;&#x672C;&#x6253;&#x5370;&#x4E00;&#x6B21;&#x6210;&#x672C;</span>
                <span class="token keyword">if</span> print_cost <span class="token keyword">and</span> i <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;Cost after iteration {}: {}&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span> np<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>cost<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token keyword">if</span> print_cost <span class="token keyword">and</span> i <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                    costs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>cost<span class="token punctuation">)</span>
               
            <span class="token comment"># plot the cost</span>
        
            plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>np<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>costs<span class="token punctuation">)</span><span class="token punctuation">)</span>
            plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">&apos;cost&apos;</span><span class="token punctuation">)</span>
            plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">&apos;iterations (per tens)&apos;</span><span class="token punctuation">)</span>
            plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">&quot;Learning rate =&quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>learning_rate<span class="token punctuation">)</span><span class="token punctuation">)</span>
            plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
            
            <span class="token keyword">return</span> parameters
        </pre><h3 class="mume-header" id="%E8%BF%90%E7%AE%97%E5%A4%84%E7%90%86">&#x8FD0;&#x7B97;&#x5904;&#x7406;</h3>
        
        <pre data-role="codeBlock" data-info="python" class="language-python">parameters <span class="token operator">=</span> two_layer_model<span class="token punctuation">(</span>train_x<span class="token punctuation">,</span> train_y<span class="token punctuation">,</span> layers_dims <span class="token operator">=</span> <span class="token punctuation">(</span>n_x<span class="token punctuation">,</span> n_h<span class="token punctuation">,</span> n_y<span class="token punctuation">)</span><span class="token punctuation">,</span> num_iterations <span class="token operator">=</span> <span class="token number">2500</span><span class="token punctuation">,</span> print_cost<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        </pre><h3 class="mume-header" id="%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%9C">&#x6A21;&#x578B;&#x7ED3;&#x679C;</h3>
        
        <pre data-role="codeBlock" data-info class="language-"><code>Cost after iteration 0: 0.6930497356599888
        Cost after iteration 100: 0.6464320953428849
        Cost after iteration 200: 0.6325140647912678
        Cost after iteration 300: 0.6015024920354665
        Cost after iteration 400: 0.5601966311605747
        Cost after iteration 500: 0.515830477276473
        Cost after iteration 600: 0.4754901313943325
        Cost after iteration 700: 0.4339163151225749
        Cost after iteration 800: 0.400797753620389
        Cost after iteration 900: 0.3580705011323798
        Cost after iteration 1000: 0.3394281538366412
        Cost after iteration 1100: 0.3052753636196263
        Cost after iteration 1200: 0.27491377282130175
        Cost after iteration 1300: 0.2468176821061483
        Cost after iteration 1400: 0.19850735037466116
        Cost after iteration 1500: 0.17448318112556632
        Cost after iteration 1600: 0.17080762978096647
        Cost after iteration 1700: 0.1130652456216472
        Cost after iteration 1800: 0.09629426845937152
        Cost after iteration 1900: 0.08342617959726863
        Cost after iteration 2000: 0.07439078704319081
        Cost after iteration 2100: 0.06630748132267934
        Cost after iteration 2200: 0.05919329501038171
        Cost after iteration 2300: 0.053361403485605544
        Cost after iteration 2400: 0.04855478562877018
        </code></pre><img src="img/QQ&#x622A;&#x56FE;20200814094808.jpg" style="zoom:60%;">
        <h3 class="mume-header" id="%E8%AE%AD%E7%BB%83%E9%9B%86%E5%87%86%E7%A1%AE%E5%BA%A6">&#x8BAD;&#x7EC3;&#x96C6;&#x51C6;&#x786E;&#x5EA6;</h3>
        
        <pre data-role="codeBlock" data-info="python" class="language-python">predictions_train <span class="token operator">=</span> predict<span class="token punctuation">(</span>train_x<span class="token punctuation">,</span> train_y<span class="token punctuation">,</span> parameters<span class="token punctuation">)</span>
        </pre><h4 class="mume-header" id="%E7%BB%93%E6%9E%9C-1">&#x7ED3;&#x679C;</h4>
        
        <pre data-role="codeBlock" data-info class="language-"><code>Accuracy: 1.0
        </code></pre><h3 class="mume-header" id="%E6%B5%8B%E8%AF%95%E9%9B%86%E5%87%86%E7%A1%AE%E5%BA%A6">&#x6D4B;&#x8BD5;&#x96C6;&#x51C6;&#x786E;&#x5EA6;</h3>
        
        <pre data-role="codeBlock" data-info="python" class="language-python">predictions_test <span class="token operator">=</span> predict<span class="token punctuation">(</span>test_x<span class="token punctuation">,</span> test_y<span class="token punctuation">,</span> parameters<span class="token punctuation">)</span>
        </pre><h4 class="mume-header" id="%E7%BB%93%E6%9E%9C-2">&#x7ED3;&#x679C;</h4>
        
        <pre data-role="codeBlock" data-info class="language-"><code>Accuracy: 0.72
        </code></pre><h2 class="mume-header" id="5%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">5&#x5C42;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;</h2>
        
        <h3 class="mume-header" id="%E8%AE%BE%E7%BD%AE%E5%8F%82%E6%95%B0">&#x8BBE;&#x7F6E;&#x53C2;&#x6570;</h3>
        
        <pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment">### CONSTANTS ###</span>
        layers_dims <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">12288</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token comment">#  5-layer model</span>
        </pre><h3 class="mume-header" id="l%E5%B1%82%E6%A8%A1%E5%9E%8B">L&#x5C42;&#x6A21;&#x578B;</h3>
        
        <pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment"># GRADED FUNCTION: L_layer_model</span>
        
        <span class="token keyword">def</span> <span class="token function">L_layer_model</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">,</span> layers_dims<span class="token punctuation">,</span> learning_rate <span class="token operator">=</span> <span class="token number">0.0075</span><span class="token punctuation">,</span> num_iterations <span class="token operator">=</span> <span class="token number">3000</span><span class="token punctuation">,</span> print_cost<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment">#lr was 0.009</span>
            <span class="token triple-quoted-string string">&quot;&quot;&quot;
            Implements a L-layer neural network: [LINEAR-&gt;RELU]*(L-1)-&gt;LINEAR-&gt;SIGMOID.
            
            Arguments:
            X -- data, numpy array of shape (number of examples, num_px * num_px * 3)
            Y -- true &quot;label&quot; vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)
            layers_dims -- list containing the input size and each layer size, of length (number of layers + 1).
            learning_rate -- learning rate of the gradient descent update rule
            num_iterations -- number of iterations of the optimization loop
            print_cost -- if True, it prints the cost every 100 steps
            
            Returns:
            parameters -- parameters learnt by the model. They can then be used to predict.
            &quot;&quot;&quot;</span>
        
            np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
            costs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>                         <span class="token comment"># &#x8FFD;&#x8E2A;&#x6210;&#x672C;&#x51FD;&#x6570;</span>
            
            <span class="token comment"># &#x521D;&#x59CB;&#x5316;Parameters</span>
            <span class="token comment">### START CODE HERE ###</span>
            parameters <span class="token operator">=</span> initialize_parameters_deep<span class="token punctuation">(</span>layers_dims<span class="token punctuation">)</span>
            <span class="token comment">### END CODE HERE ###</span>
            
            <span class="token comment"># Loop (gradient descent)</span>
            <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> num_iterations<span class="token punctuation">)</span><span class="token punctuation">:</span>
        
                <span class="token comment"># &#x6B63;&#x5411;&#x4F20;&#x64AD;: [LINEAR -&gt; RELU]*(L-1) -&gt; LINEAR -&gt; SIGMOID.</span>
                <span class="token comment">### START CODE HERE ### (&#x2248; 1 line of code)</span>
                AL<span class="token punctuation">,</span> caches <span class="token operator">=</span> L_model_forward<span class="token punctuation">(</span>X<span class="token punctuation">,</span> parameters<span class="token punctuation">)</span>
                <span class="token comment">### END CODE HERE ###</span>
                
                <span class="token comment"># &#x8BA1;&#x7B97;&#x6210;&#x672C;.</span>
                <span class="token comment">### START CODE HERE ### (&#x2248; 1 line of code)</span>
                cost <span class="token operator">=</span> compute_cost<span class="token punctuation">(</span>AL<span class="token punctuation">,</span> Y<span class="token punctuation">)</span>
                <span class="token comment">### END CODE HERE ###</span>
            
                <span class="token comment"># &#x53CD;&#x5411;&#x4F20;&#x64AD;.</span>
                <span class="token comment">### START CODE HERE ### (&#x2248; 1 line of code)</span>
                grads <span class="token operator">=</span>  L_model_backward<span class="token punctuation">(</span>AL<span class="token punctuation">,</span> Y<span class="token punctuation">,</span> caches<span class="token punctuation">)</span>
                <span class="token comment">### END CODE HERE ###</span>
         
                <span class="token comment"># &#x66F4;&#x65B0;&#x53C2;&#x6570;.</span>
                <span class="token comment">### START CODE HERE ### (&#x2248; 1 line of code)</span>
                parameters <span class="token operator">=</span> update_parameters<span class="token punctuation">(</span>parameters<span class="token punctuation">,</span>  grads<span class="token punctuation">,</span> learning_rate<span class="token punctuation">)</span>
                <span class="token comment">### END CODE HERE ###</span>
                        
                <span class="token comment"># &#x6BCF;100&#x4E2A;&#x8BAD;&#x7EC3;&#x6837;&#x672C;&#x6253;&#x5370;&#x4E00;&#x6B21;&#x6210;&#x672C;</span>
                <span class="token keyword">if</span> print_cost <span class="token keyword">and</span> i <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                    <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&quot;Cost after iteration %i: %f&quot;</span> <span class="token operator">%</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span> cost<span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token keyword">if</span> print_cost <span class="token keyword">and</span> i <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                    costs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>cost<span class="token punctuation">)</span>
                    
            <span class="token comment"># plot the cost</span>
            plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>np<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>costs<span class="token punctuation">)</span><span class="token punctuation">)</span>
            plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">&apos;cost&apos;</span><span class="token punctuation">)</span>
            plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">&apos;iterations (per tens)&apos;</span><span class="token punctuation">)</span>
            plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">&quot;Learning rate =&quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>learning_rate<span class="token punctuation">)</span><span class="token punctuation">)</span>
            plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
            
            <span class="token keyword">return</span> parameters
        </pre><h3 class="mume-header" id="%E8%BF%90%E7%AE%97%E5%A4%84%E7%90%86-1">&#x8FD0;&#x7B97;&#x5904;&#x7406;</h3>
        
        <pre data-role="codeBlock" data-info="python" class="language-python">parameters <span class="token operator">=</span> L_layer_model<span class="token punctuation">(</span>train_x<span class="token punctuation">,</span> train_y<span class="token punctuation">,</span> layers_dims<span class="token punctuation">,</span> num_iterations <span class="token operator">=</span> <span class="token number">2500</span><span class="token punctuation">,</span> print_cost <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
        </pre><h3 class="mume-header" id="%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%9C-1">&#x6A21;&#x578B;&#x7ED3;&#x679C;</h3>
        
        <pre data-role="codeBlock" data-info class="language-"><code>Cost after iteration 0: 0.771749
        Cost after iteration 100: 0.672053
        Cost after iteration 200: 0.648263
        Cost after iteration 300: 0.611507
        Cost after iteration 400: 0.567047
        Cost after iteration 500: 0.540138
        Cost after iteration 600: 0.527930
        Cost after iteration 700: 0.465477
        Cost after iteration 800: 0.369126
        Cost after iteration 900: 0.391747
        Cost after iteration 1000: 0.315187
        Cost after iteration 1100: 0.272700
        Cost after iteration 1200: 0.237419
        Cost after iteration 1300: 0.199601
        Cost after iteration 1400: 0.189263
        Cost after iteration 1500: 0.161189
        Cost after iteration 1600: 0.148214
        Cost after iteration 1700: 0.137775
        Cost after iteration 1800: 0.129740
        Cost after iteration 1900: 0.121225
        Cost after iteration 2000: 0.113821
        Cost after iteration 2100: 0.107839
        Cost after iteration 2200: 0.102855
        Cost after iteration 2300: 0.100897
        Cost after iteration 2400: 0.092878
        </code></pre><img src="img/QQ&#x622A;&#x56FE;20200814095717.jpg" style="zoom:60%;">
        <h3 class="mume-header" id="%E8%AE%AD%E7%BB%83%E9%9B%86%E5%87%86%E7%A1%AE%E5%BA%A6-1">&#x8BAD;&#x7EC3;&#x96C6;&#x51C6;&#x786E;&#x5EA6;</h3>
        
        <pre data-role="codeBlock" data-info="python" class="language-python">pred_train <span class="token operator">=</span> predict<span class="token punctuation">(</span>train_x<span class="token punctuation">,</span> train_y<span class="token punctuation">,</span> parameters<span class="token punctuation">)</span>
        </pre><h4 class="mume-header" id="%E7%BB%93%E6%9E%9C-3">&#x7ED3;&#x679C;</h4>
        
        <pre data-role="codeBlock" data-info class="language-"><code>Accuracy: 0.985645933014
        </code></pre><h3 class="mume-header" id="%E6%B5%8B%E8%AF%95%E9%9B%86%E5%87%86%E7%A1%AE%E5%BA%A6-1">&#x6D4B;&#x8BD5;&#x96C6;&#x51C6;&#x786E;&#x5EA6;</h3>
        
        <pre data-role="codeBlock" data-info="python" class="language-python">pred_test <span class="token operator">=</span> predict<span class="token punctuation">(</span>test_x<span class="token punctuation">,</span> test_y<span class="token punctuation">,</span> parameters<span class="token punctuation">)</span>
        </pre><h4 class="mume-header" id="%E7%BB%93%E6%9E%9C-4">&#x7ED3;&#x679C;</h4>
        
        <pre data-role="codeBlock" data-info class="language-"><code>Accuracy: 0.8
        </code></pre><h2 class="mume-header" id="%E6%89%93%E5%8D%B0%E6%9C%AA%E8%AF%86%E5%88%AB%E6%AD%A3%E7%A1%AE%E5%9B%BE%E7%89%87">&#x6253;&#x5370;&#x672A;&#x8BC6;&#x522B;&#x6B63;&#x786E;&#x56FE;&#x7247;</h2>
        
        <pre data-role="codeBlock" data-info="python" class="language-python">print_mislabeled_images<span class="token punctuation">(</span>classes<span class="token punctuation">,</span> test_x<span class="token punctuation">,</span> test_y<span class="token punctuation">,</span> pred_test<span class="token punctuation">)</span>
        </pre><p><img src="img/QQ%E6%88%AA%E5%9B%BE20200814100118.jpg" alt></p>
        <h2 class="mume-header" id="%E6%B5%8B%E8%AF%95%E8%87%AA%E5%B7%B1%E7%9A%84%E7%8C%AB%E7%8C%AB">&#x6D4B;&#x8BD5;&#x81EA;&#x5DF1;&#x7684;&#x732B;&#x732B;</h2>
        
        <pre data-role="codeBlock" data-info="python" class="language-python"><span class="token keyword">import</span> imageio
        <span class="token keyword">from</span> skimage<span class="token punctuation">.</span>transform <span class="token keyword">import</span> resize
        <span class="token comment">## START CODE HERE ##</span>
        my_image <span class="token operator">=</span> <span class="token string">&quot;cat1.jpg&quot;</span> <span class="token comment"># change this to the name of your image file </span>
        my_label_y <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token comment"># the true class of your image (1 -&gt; cat, 0 -&gt; non-cat)</span>
        <span class="token comment">## END CODE HERE ##</span>
        
        fname <span class="token operator">=</span> <span class="token string">&quot;images/&quot;</span> <span class="token operator">+</span> my_image
        image <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>imageio<span class="token punctuation">.</span>imread<span class="token punctuation">(</span>fname<span class="token punctuation">)</span><span class="token punctuation">)</span>
        my_image <span class="token operator">=</span> resize<span class="token punctuation">(</span>image<span class="token punctuation">,</span> output_shape<span class="token operator">=</span><span class="token punctuation">(</span>num_px<span class="token punctuation">,</span>num_px<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span>num_px<span class="token operator">*</span>num_px<span class="token operator">*</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        my_predicted_image <span class="token operator">=</span> predict<span class="token punctuation">(</span>my_image<span class="token punctuation">,</span> my_label_y<span class="token punctuation">,</span> parameters<span class="token punctuation">)</span>
        
        plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>image<span class="token punctuation">)</span>
        <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&quot;y = &quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>my_predicted_image<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">&quot;, your L-layer model predicts a \&quot;&quot;</span> <span class="token operator">+</span> classes<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>my_predicted_image<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">]</span><span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token string">&quot;utf-8&quot;</span><span class="token punctuation">)</span> <span class="token operator">+</span>  <span class="token string">&quot;\&quot; picture.&quot;</span><span class="token punctuation">)</span>
        </pre><img src="img/QQ&#x622A;&#x56FE;20200814100237.jpg" style="zoom:60%;">
        
              </div>
          </main>
        </div>
      </div>

    </body></html>
    