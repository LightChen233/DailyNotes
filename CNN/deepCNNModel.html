<!DOCTYPE html><html><head>
      <title>deepCNNModel</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      
        <script type="text/x-mathjax-config">
          MathJax.Hub.Config({"extensions":["tex2jax.js"],"jax":["input/TeX","output/HTML-CSS"],"messageStyle":"none","tex2jax":{"processEnvironments":false,"processEscapes":true,"inlineMath":[["$","$"],["\\(","\\)"]],"displayMath":[["$$","$$"],["\\[","\\]"]]},"TeX":{"extensions":["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]},"HTML-CSS":{"availableFonts":["TeX"]}});
        </script>
        <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"></script>
        
      
      
      
      
      
      
      
      
      
      <style>
      /**
 * prism.js Github theme based on GitHub's theme.
 * @author Sam Clarke
 */
code[class*="language-"],
pre[class*="language-"] {
  color: #333;
  background: none;
  font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.4;

  -moz-tab-size: 8;
  -o-tab-size: 8;
  tab-size: 8;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

/* Code blocks */
pre[class*="language-"] {
  padding: .8em;
  overflow: auto;
  /* border: 1px solid #ddd; */
  border-radius: 3px;
  /* background: #fff; */
  background: #f5f5f5;
}

/* Inline code */
:not(pre) > code[class*="language-"] {
  padding: .1em;
  border-radius: .3em;
  white-space: normal;
  background: #f5f5f5;
}

.token.comment,
.token.blockquote {
  color: #969896;
}

.token.cdata {
  color: #183691;
}

.token.doctype,
.token.punctuation,
.token.variable,
.token.macro.property {
  color: #333;
}

.token.operator,
.token.important,
.token.keyword,
.token.rule,
.token.builtin {
  color: #a71d5d;
}

.token.string,
.token.url,
.token.regex,
.token.attr-value {
  color: #183691;
}

.token.property,
.token.number,
.token.boolean,
.token.entity,
.token.atrule,
.token.constant,
.token.symbol,
.token.command,
.token.code {
  color: #0086b3;
}

.token.tag,
.token.selector,
.token.prolog {
  color: #63a35c;
}

.token.function,
.token.namespace,
.token.pseudo-element,
.token.class,
.token.class-name,
.token.pseudo-class,
.token.id,
.token.url-reference .token.variable,
.token.attr-name {
  color: #795da3;
}

.token.entity {
  cursor: help;
}

.token.title,
.token.title .token.punctuation {
  font-weight: bold;
  color: #1d3e81;
}

.token.list {
  color: #ed6a43;
}

.token.inserted {
  background-color: #eaffea;
  color: #55a532;
}

.token.deleted {
  background-color: #ffecec;
  color: #bd2c00;
}

.token.bold {
  font-weight: bold;
}

.token.italic {
  font-style: italic;
}


/* JSON */
.language-json .token.property {
  color: #183691;
}

.language-markup .token.tag .token.punctuation {
  color: #333;
}

/* CSS */
code.language-css,
.language-css .token.function {
  color: #0086b3;
}

/* YAML */
.language-yaml .token.atrule {
  color: #63a35c;
}

code.language-yaml {
  color: #183691;
}

/* Ruby */
.language-ruby .token.function {
  color: #333;
}

/* Markdown */
.language-markdown .token.url {
  color: #795da3;
}

/* Makefile */
.language-makefile .token.symbol {
  color: #795da3;
}

.language-makefile .token.variable {
  color: #183691;
}

.language-makefile .token.builtin {
  color: #0086b3;
}

/* Bash */
.language-bash .token.keyword {
  color: #0086b3;
}

/* highlight */
pre[data-line] {
  position: relative;
  padding: 1em 0 1em 3em;
}
pre[data-line] .line-highlight-wrapper {
  position: absolute;
  top: 0;
  left: 0;
  background-color: transparent;
  display: block;
  width: 100%;
}

pre[data-line] .line-highlight {
  position: absolute;
  left: 0;
  right: 0;
  padding: inherit 0;
  margin-top: 1em;
  background: hsla(24, 20%, 50%,.08);
  background: linear-gradient(to right, hsla(24, 20%, 50%,.1) 70%, hsla(24, 20%, 50%,0));
  pointer-events: none;
  line-height: inherit;
  white-space: pre;
}

pre[data-line] .line-highlight:before, 
pre[data-line] .line-highlight[data-end]:after {
  content: attr(data-start);
  position: absolute;
  top: .4em;
  left: .6em;
  min-width: 1em;
  padding: 0 .5em;
  background-color: hsla(24, 20%, 50%,.4);
  color: hsl(24, 20%, 95%);
  font: bold 65%/1.5 sans-serif;
  text-align: center;
  vertical-align: .3em;
  border-radius: 999px;
  text-shadow: none;
  box-shadow: 0 1px white;
}

pre[data-line] .line-highlight[data-end]:after {
  content: attr(data-end);
  top: auto;
  bottom: .4em;
}html body{font-family:"Helvetica Neue",Helvetica,"Segoe UI",Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ul,html body>ol{margin-bottom:16px}html body ul,html body ol{padding-left:2em}html body ul.no-list,html body ol.no-list{padding:0;list-style-type:none}html body ul ul,html body ul ol,html body ol ol,html body ol ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;background-color:#f0f0f0;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:bold;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:bold}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em !important;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::before,html body code::after{letter-spacing:-0.2em;content:"\00a0"}html body pre>code{padding:0;margin:0;font-size:.85em !important;word-break:normal;white-space:pre;background:transparent;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;font-size:.85em !important;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:before,html body pre tt:before,html body pre code:after,html body pre tt:after{content:normal}html body p,html body blockquote,html body ul,html body ol,html body dl,html body pre{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body pre,html body code{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview .pagebreak,.markdown-preview .newpage{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center !important}.markdown-preview:not([for="preview"]) .code-chunk .btn-group{display:none}.markdown-preview:not([for="preview"]) .code-chunk .status{display:none}.markdown-preview:not([for="preview"]) .code-chunk .output-div{margin-bottom:16px}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for="html-export"]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0}@media screen and (min-width:914px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px + 2em)}}@media screen and (max-width:914px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{font-size:14px !important;padding:1em}}@media print{html body[for="html-export"]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for="html-export"]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,0.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc ul{padding:0 1.6em;margin-top:.8em}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc li{margin-bottom:.8em}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc ul{list-style-type:none}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% -  300px);padding:2em calc(50% - 457px -  150px);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for="html-export"]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for="html-export"]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */

      </style>
    </head>
    <body for="html-export">
      <div class="mume markdown-preview  ">
      <h1 class="mume-header" id="%E6%B7%B1%E5%BA%A6%E5%8D%B7%E7%A7%AF%E6%A8%A1%E5%9E%8B%E6%A1%88%E4%BE%8B%E7%A0%94%E7%A9%B6">&#x6DF1;&#x5EA6;&#x5377;&#x79EF;&#x6A21;&#x578B;&#xFF1A;&#x6848;&#x4F8B;&#x7814;&#x7A76;</h1>

<h2 class="mume-header" id="%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E8%BF%9B%E8%A1%8C%E5%AE%9E%E4%BE%8B%E6%8E%A2%E7%A9%B6">&#x4E3A;&#x4EC0;&#x4E48;&#x8981;&#x8FDB;&#x884C;&#x5B9E;&#x4F8B;&#x63A2;&#x7A76;</h2>

<p>&#x672C;&#x5468;&#x8BFE;&#x7A0B;&#x5C06;&#x4E3B;&#x8981;&#x4ECB;&#x7ECD;&#x51E0;&#x4E2A;&#x5178;&#x578B;&#x7684;CNN&#x6848;&#x4F8B;&#x3002;&#x901A;&#x8FC7;&#x5BF9;&#x5177;&#x4F53;CNN&#x6A21;&#x578B;&#x53CA;&#x6848;&#x4F8B;&#x7684;&#x7814;&#x7A76;&#xFF0C;&#x6765;&#x5E2E;&#x52A9;&#x6211;&#x4EEC;&#x7406;&#x89E3;&#x77E5;&#x8BC6;&#x5E76;&#x8BAD;&#x7EC3;&#x5B9E;&#x9645;&#x7684;&#x6A21;&#x578B;&#x3002;</p>
<p>&#x5178;&#x578B;&#x7684;CNN&#x6A21;&#x578B;&#x5305;&#x62EC;&#xFF1A;</p>
<ul>
<li><strong>LeNet-5</strong></li>
<li><strong>AlexNet</strong></li>
<li><strong>VGG</strong></li>
</ul>
<p>&#x9664;&#x4E86;&#x8FD9;&#x4E9B;&#x6027;&#x80FD;&#x826F;&#x597D;&#x7684;CNN&#x6A21;&#x578B;&#x4E4B;&#x5916;&#xFF0C;&#x6211;&#x4EEC;&#x8FD8;&#x4F1A;&#x4ECB;&#x7ECD;Residual Network&#xFF08;ResNet&#xFF09;&#x3002;&#x5176;&#x7279;&#x70B9;&#x662F;&#x53EF;&#x4EE5;&#x6784;&#x5EFA;&#x5F88;&#x6DF1;&#x5F88;&#x6DF1;&#x7684;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#xFF08;&#x76EE;&#x524D;&#x6700;&#x6DF1;&#x7684;&#x597D;&#x50CF;&#x6709;152&#x5C42;&#xFF09;&#x3002;</p>
<p>&#x53E6;&#x5916;&#xFF0C;&#x8FD8;&#x4F1A;&#x4ECB;&#x7ECD;Inception&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x3002;&#x63A5;&#x4E0B;&#x6765;&#xFF0C;&#x6211;&#x4EEC;&#x5C06;&#x4E00;&#x4E00;&#x8BB2;&#x89E3;&#x3002;</p>
<h3 class="mume-header" id="%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C">&#x7ECF;&#x5178;&#x7F51;&#x7EDC;</h3>

<h4 class="mume-header" id="lenet-5%E6%A8%A1%E5%9E%8B">LeNet-5&#x6A21;&#x578B;</h4>

<p>LeNet-5&#x6A21;&#x578B;&#x662F;Yann LeCun&#x6559;&#x6388;&#x4E8E;1998&#x5E74;&#x63D0;&#x51FA;&#x6765;&#x7684;&#xFF0C;&#x5B83;&#x662F;&#x7B2C;&#x4E00;&#x4E2A;&#x6210;&#x529F;&#x5E94;&#x7528;&#x4E8E;&#x6570;&#x5B57;&#x8BC6;&#x522B;&#x95EE;&#x9898;&#x7684;&#x5377;&#x79EF;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x3002;&#x5728;MNIST&#x6570;&#x636E;&#x4E2D;&#xFF0C;&#x5B83;&#x7684;&#x51C6;&#x786E;&#x7387;&#x8FBE;&#x5230;&#x5927;&#x7EA6;99.2%&#x3002;</p>
<p>&#x5178;&#x578B;&#x7684;LeNet-5&#x7ED3;&#x6784;&#x5305;&#x542B;CONV&#x5C42;&#xFF0C;POOL&#x5C42;&#x548C;FC&#x5C42;&#xFF0C;&#x987A;&#x5E8F;&#x4E00;&#x822C;&#x662F;&#xFF1A;</p>
<p>CONV&#x5C42;-&gt;POOL&#x5C42;-&gt;CONV&#x5C42;-&gt;POOL&#x5C42;-&gt;FC&#x5C42;-&gt;FC&#x5C42;-&gt;OUTPUT&#x5C42;(&#x5373;<span class="mathjax-exps">$\hat y$</span>)&#x3002;&#x4E0B;&#x56FE;&#x6240;&#x793A;&#x7684;&#x662F;&#x4E00;&#x4E2A;&#x6570;&#x5B57;&#x8BC6;&#x522B;&#x7684;LeNet-5&#x7684;&#x6A21;&#x578B;&#x7ED3;&#x6784;&#xFF1A;</p>
<p><img src="img/23.jpg" alt></p>
<p>&#x8BE5;LeNet&#x6A21;&#x578B;&#x603B;&#x5171;&#x5305;&#x542B;&#x4E86;&#x5927;&#x7EA6;6&#x4E07;&#x4E2A;&#x53C2;&#x6570;&#x3002;&#x503C;&#x5F97;&#x4E00;&#x63D0;&#x7684;&#x662F;&#xFF0C;&#x5F53;&#x65F6;Yann LeCun&#x63D0;&#x51FA;&#x7684;LeNet-5&#x6A21;&#x578B;&#x6C60;&#x5316;&#x5C42;&#x4F7F;&#x7528;&#x7684;&#x662F;&#x5E73;&#x5747;&#x6C60;&#x5316;average pool&#xFF0C;&#x800C;&#x4E14;&#x5404;&#x5C42;&#x6FC0;&#x6D3B;&#x51FD;&#x6570;&#x4E00;&#x822C;&#x662F;Sigmoid&#x548C;tanh&#x3002;</p>
<p>&#x73B0;&#x5728;&#xFF0C;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x6839;&#x636E;&#x9700;&#x8981;&#xFF0C;&#x505A;&#x51FA;&#x6539;&#x8FDB;&#xFF0C;&#x4F7F;&#x7528;&#x6700;&#x5927;&#x6C60;&#x5316;max pool&#x548C;&#x6FC0;&#x6D3B;&#x51FD;&#x6570;ReLU&#x3002;</p>
<h4 class="mume-header" id="alexnet%E6%A8%A1%E5%9E%8B">AlexNet&#x6A21;&#x578B;</h4>

<p>AlexNet&#x6A21;&#x578B;&#x662F;&#x7531;Alex Krizhevsky&#x3001;Ilya Sutskever&#x548C;Geoffrey Hinton&#x5171;&#x540C;&#x63D0;&#x51FA;&#x7684;&#xFF0C;&#x5176;&#x7ED3;&#x6784;&#x5982;&#x4E0B;&#x6240;&#x793A;&#xFF1A;</p>
<p><img src="img/24.jpg" alt></p>
<p>AlexNet&#x6A21;&#x578B;&#x4E0E;LeNet-5&#x6A21;&#x578B;&#x7C7B;&#x4F3C;&#xFF0C;&#x53EA;&#x662F;&#x8981;&#x590D;&#x6742;&#x4E00;&#x4E9B;&#xFF0C;&#x603B;&#x5171;&#x5305;&#x542B;&#x4E86;&#x5927;&#x7EA6;6&#x5343;&#x4E07;&#x4E2A;&#x53C2;&#x6570;&#x3002;&#x540C;&#x6837;&#x53EF;&#x4EE5;&#x6839;&#x636E;&#x5B9E;&#x9645;&#x60C5;&#x51B5;&#x4F7F;&#x7528;&#x6FC0;&#x6D3B;&#x51FD;&#x6570;ReLU&#x3002;&#x539F;&#x4F5C;&#x8005;&#x8FD8;&#x63D0;&#x5230;&#x4E86;&#x4E00;&#x79CD;&#x4F18;&#x5316;&#x6280;&#x5DE7;&#xFF0C;&#x53EB;&#x505A;<strong>&#x5C40;&#x90E8;&#x54CD;&#x5E94;&#x6B63;&#x5219;&#x5316; Local Response Normalization(LRN)</strong>&#x3002; &#x800C;&#x5728;&#x5B9E;&#x9645;&#x5E94;&#x7528;&#x4E2D;&#xFF0C;LRN&#x7684;&#x6548;&#x679C;&#x5E76;&#x4E0D;&#x7A81;&#x51FA;&#x3002;</p>
<h4 class="mume-header" id="vgg-16%E6%A8%A1%E5%9E%8B">VGG-16&#x6A21;&#x578B;</h4>

<p>VGG-16&#x6A21;&#x578B;&#x66F4;&#x52A0;&#x590D;&#x6742;&#x4E00;&#x4E9B;&#xFF0C;&#x4E00;&#x822C;&#x60C5;&#x51B5;&#x4E0B;&#xFF0C;&#x5176;CONV layer&#x548C;POOL layer&#x8BBE;&#x7F6E;&#x5982;&#x4E0B;&#xFF1A;</p>
<ul>
<li><strong>CONV = 3x3 filters, s = 1, same</strong></li>
<li><strong>MAX-POOL = 2x2, s = 2</strong></li>
</ul>
<p>VGG-16&#x7ED3;&#x6784;&#x5982;&#x4E0B;&#x6240;&#x793A;&#xFF1A;</p>
<p><img src="img/25.jpg" alt></p>
<p>VGG-16&#x7684;&#x53C2;&#x6570;&#x591A;&#x8FBE;1&#x4EBF;3&#x5343;&#x4E07;&#x3002;</p>
<h2 class="mume-header" id="%E6%AE%8B%E5%B7%AE%E7%BD%91%E7%BB%9C">&#x6B8B;&#x5DEE;&#x7F51;&#x7EDC;</h2>

<p>&#x6211;&#x4EEC;&#x77E5;&#x9053;&#xFF0C;&#x5982;&#x679C;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x5C42;&#x6570;&#x8D8A;&#x591A;&#xFF0C;&#x7F51;&#x7EDC;&#x8D8A;&#x6DF1;&#xFF0C;&#x6E90;&#x4E8E;&#x68AF;&#x5EA6;&#x6D88;&#x5931;&#x548C;&#x68AF;&#x5EA6;&#x7206;&#x70B8;&#x7684;&#x5F71;&#x54CD;&#xFF0C;&#x6574;&#x4E2A;&#x6A21;&#x578B;&#x96BE;&#x4EE5;&#x8BAD;&#x7EC3;&#x6210;&#x529F;&#x3002;&#x89E3;&#x51B3;&#x7684;&#x65B9;&#x6CD5;&#x4E4B;&#x4E00;&#x662F;&#x4EBA;&#x4E3A;&#x5730;&#x8BA9;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x67D0;&#x4E9B;&#x5C42;&#x8DF3;&#x8FC7;&#x4E0B;&#x4E00;&#x5C42;&#x795E;&#x7ECF;&#x5143;&#x7684;&#x8FDE;&#x63A5;&#xFF0C;&#x9694;&#x5C42;&#x76F8;&#x8FDE;&#xFF0C;&#x5F31;&#x5316;&#x6BCF;&#x5C42;&#x4E4B;&#x95F4;&#x7684;&#x5F3A;&#x8054;&#x7CFB;&#x3002;&#x8FD9;&#x79CD;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x88AB;&#x79F0;&#x4E3A;<strong>&#x6B8B;&#x5DEE;&#x7F51;&#x7EDC;</strong>(ResNets)&#x3002;</p>
<p>&#x6B8B;&#x5DEE;&#x7F51;&#x7EDC;&#x7531;&#x8BB8;&#x591A;&#x9694;&#x5C42;&#x76F8;&#x8FDE;&#x7684;&#x795E;&#x7ECF;&#x5143;&#x5B50;&#x6A21;&#x5757;&#x7EC4;&#x6210;&#xFF0C;&#x6211;&#x4EEC;&#x79F0;&#x4E4B;&#x4E3A;<strong>&#x6B8B;&#x5DEE;&#x5757;</strong>&#xFF08;Residual block&#xFF09;&#x3002;&#x5355;&#x4E2A;&#x6B8B;&#x5DEE;&#x5757;&#x7684;&#x7ED3;&#x6784;&#x5982;&#x4E0B;&#x56FE;&#x6240;&#x793A;&#xFF1A;</p>
<p><img src="img/26.jpg" alt></p>
<p>&#x4E0A;&#x56FE;&#x4E2D;&#x7EA2;&#x8272;&#x90E8;&#x5206;&#x5C31;&#x662F;&#x8DF3;&#x8DC3;&#x5F0F;&#x8FDE;&#x63A5;(skip connection)&#xFF0C;&#x76F4;&#x63A5;&#x5EFA;&#x7ACB;<span class="mathjax-exps">$a[l]$</span>&#x4E0E;<span class="mathjax-exps">$a[l+2]$</span>&#x4E4B;&#x95F4;&#x7684;&#x9694;&#x5C42;&#x8054;&#x7CFB;&#x3002;&#x76F8;&#x5E94;&#x7684;&#x8868;&#x8FBE;&#x5F0F;&#x5982;&#x4E0B;&#xFF1A;</p>
<p></p><div class="mathjax-exps">$$z^{[l+1]}=W^{[l+1]}a^{[l]}+b^{[l+1]}$$</div><p></p>
<p></p><div class="mathjax-exps">$$a^{[l+1]}=g(z^{[l+1]})$$</div><p></p>
<p></p><div class="mathjax-exps">$$z^{[l+2]}=W^{[l+2]}a^{[l+1]}+b^{[l+2]}$$</div><p></p>
<p></p><div class="mathjax-exps">$$a^{[l+2]}=g(z^{[l+2]}+a^{[l]})$$</div><p></p>
<p><span class="mathjax-exps">$a^{[l]}$</span>&#x76F4;&#x63A5;&#x9694;&#x5C42;&#x4E0E;&#x4E0B;&#x4E00;&#x5C42;&#x7684;&#x7EBF;&#x6027;&#x8F93;&#x51FA;&#x76F8;&#x8FDE;&#xFF0C;&#x4E0E;<span class="mathjax-exps">$z^{[l+2]}$</span>&#x5171;&#x540C;&#x901A;&#x8FC7;&#x6FC0;&#x6D3B;&#x51FD;&#x6570;&#xFF08;ReLU&#xFF09;&#x8F93;&#x51FA;<span class="mathjax-exps">$a^{[l+2]}$</span>&#x3002;</p>
<p>&#x8BE5;&#x6A21;&#x578B;&#x7531;Kaiming He, Xiangyu Zhang, Shaoqing Ren&#x548C;Jian Sun&#x5171;&#x540C;&#x63D0;&#x51FA;&#x3002;&#x7531;&#x591A;&#x4E2A;&#x6B8B;&#x5DEE;&#x5757;&#x7EC4;&#x6210;&#x7684;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x5C31;&#x662F;<strong>&#x6B8B;&#x5DEE;&#x7F51;&#x7EDC;</strong>&#x3002;</p>
<p>&#x5B9E;&#x9A8C;&#x8868;&#x660E;&#xFF0C;&#x8FD9;&#x79CD;&#x6A21;&#x578B;&#x7ED3;&#x6784;&#x5BF9;&#x4E8E;&#x8BAD;&#x7EC3;&#x975E;&#x5E38;&#x6DF1;&#x7684;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#xFF0C;&#x6548;&#x679C;&#x5F88;&#x597D;&#x3002;&#x53E6;&#x5916;&#xFF0C;&#x4E3A;&#x4E86;&#x4FBF;&#x4E8E;&#x533A;&#x5206;&#xFF0C;&#x6211;&#x4EEC;&#x628A;&#x975E;&#x6B8B;&#x5DEE;&#x7F51;&#x7EDC;&#x79F0;&#x4E3A;&#x5E73;&#x9762;&#x7F51;&#x7EDC;(Plain Network)&#x3002;</p>
<p><img src="img/27.jpg" alt></p>
<p>&#x6B8B;&#x5DEE;&#x7F51;&#x7EDC;&#x7684;&#x7ED3;&#x6784;&#x5982;&#x4E0A;&#x56FE;&#x6240;&#x793A;&#x3002;</p>
<p>&#x4E0E;Plain&#x7F51;&#x7EDC;&#x76F8;&#x6BD4;&#xFF0C;&#x6B8B;&#x5DEE;&#x7F51;&#x7EDC;&#x80FD;&#x591F;<strong>&#x8BAD;&#x7EC3;&#x66F4;&#x6DF1;&#x5C42;&#x7684;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;</strong>&#xFF0C;<strong>&#x6709;&#x6548;&#x907F;&#x514D;&#x53D1;&#x751F;&#x53D1;&#x751F;&#x68AF;&#x5EA6;&#x6D88;&#x5931;&#x548C;&#x68AF;&#x5EA6;&#x7206;&#x70B8;</strong>&#x3002;</p>
<p>&#x4ECE;&#x4E0B;&#x9762;&#x4E24;&#x5F20;&#x56FE;&#x7684;&#x5BF9;&#x6BD4;&#x4E2D;&#x53EF;&#x4EE5;&#x770B;&#x51FA;&#xFF0C;&#x968F;&#x7740;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x5C42;&#x6570;&#x589E;&#x52A0;&#xFF0C;Plain&#x7F51;&#x7EDC;&#x5B9E;&#x9645;&#x6027;&#x80FD;&#x4F1A;&#x53D8;&#x5DEE;&#xFF0C;&#x8BAD;&#x7EC3;&#x8BEF;&#x5DEE;&#x751A;&#x81F3;&#x4F1A;&#x53D8;&#x5927;&#x3002;&#x7136;&#x800C;&#xFF0C;&#x6B8B;&#x5DEE;&#x7F51;&#x7EDC;&#x7684;&#x8BAD;&#x7EC3;&#x6548;&#x679C;&#x5374;&#x5F88;&#x597D;&#xFF0C;&#x8BAD;&#x7EC3;&#x8BEF;&#x5DEE;&#x4E00;&#x76F4;&#x5448;&#x4E0B;&#x964D;&#x8D8B;&#x52BF;&#x3002;</p>
<p><img src="img/28.jpg" alt></p>
<h2 class="mume-header" id="%E6%AE%8B%E5%B7%AE%E7%BD%91%E7%BB%9C%E5%8E%9F%E7%90%86">&#x6B8B;&#x5DEE;&#x7F51;&#x7EDC;&#x539F;&#x7406;</h2>

<p>&#x4E0B;&#x9762;&#x7528;&#x4E2A;&#x4F8B;&#x5B50;&#x6765;&#x89E3;&#x91CA;&#x4E3A;&#x4EC0;&#x4E48;&#x6B8B;&#x5DEE;&#x7F51;&#x7EDC;&#x80FD;&#x591F;&#x8BAD;&#x7EC3;&#x66F4;&#x6DF1;&#x5C42;&#x7684;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x3002;</p>
<p><img src="img/29.jpg" alt></p>
<p>&#x5982;&#x4E0A;&#x56FE;&#x6240;&#x793A;&#xFF0C;&#x8F93;&#x5165;x&#x7ECF;&#x8FC7;&#x5F88;&#x591A;&#x5C42;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x540E;&#x8F93;&#x51FA;<span class="mathjax-exps">$a^{[l]}$</span>&#xFF0C;<span class="mathjax-exps">$a^{[l]}$</span>&#x7ECF;&#x8FC7;&#x4E00;&#x4E2A;Residual block&#x8F93;&#x51FA;<span class="mathjax-exps">$a^{[l+2]}$</span>&#x3002;<span class="mathjax-exps">$a^{[l+2]}$</span>&#x7684;&#x8868;&#x8FBE;&#x5F0F;&#x4E3A;&#xFF1A;</p>
<p></p><div class="mathjax-exps">$$a^{[l+2]}=g(z^{[l+2]}+a^{[l]})=g(W^{[l+2]}a^{[l+1]}+b^{[l+2]}+a^{[l]})$$</div><br>
&#x8F93;&#x5165;x&#x7ECF;&#x8FC7;&#x5927;&#x578B;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;(Big NN)&#x540E;&#xFF0C;&#x5982;&#x679C;&#x6709;<span class="mathjax-exps">$W^{[l+2]}\approx0$</span>&#xFF0C;<span class="mathjax-exps">$b^{[l+2]}\approx0$</span>&#xFF0C;&#x5219;&#x6709;&#xFF1A;<p></p>
<p></p><div class="mathjax-exps">$$a^{[l+2]}=g(a^{[l]})=ReLU(a^{[l]})=a^{[l]}\ \ \ \ when\ a^{[l]}\geq0$$</div><br>
&#x53EF;&#x4EE5;&#x770B;&#x51FA;&#xFF0C;&#x5373;&#x4F7F;&#x53D1;&#x751F;&#x4E86;&#x68AF;&#x5EA6;&#x6D88;&#x5931;<span class="mathjax-exps">$W^{[l+2]}\approx0$</span>&#xFF0C;<span class="mathjax-exps">$b^{[l+2]}\approx0$</span>&#xFF0C;&#x4E5F;&#x80FD;&#x76F4;&#x63A5;&#x5EFA;&#x7ACB;<span class="mathjax-exps">$a^{[l+2]}$</span>&#x4E0E;<span class="mathjax-exps">$a^{[l]}$</span>&#x7684;&#x7EBF;&#x6027;&#x5173;&#x7CFB;&#xFF0C;&#x4E14;<span class="mathjax-exps">$a^{[l+2]}=a^{[l]}$</span>&#xFF0C;&#x8FD9;&#x5176;&#x5B9E;&#x5C31;&#x662F;<strong>&#x6052;&#x7B49;&#x51FD;&#x6570;</strong>&#x3002;<p></p>
<h3 class="mume-header" id="%E8%AF%84%E4%BB%B7">&#x8BC4;&#x4EF7;</h3>

<p><strong>&#x6548;&#x679C;</strong>&#xFF1A;<span class="mathjax-exps">$a^{[l]}$</span>&#x76F4;&#x63A5;&#x8FDE;&#x5230;<span class="mathjax-exps">$a^{[l+2]}$</span>&#xFF0C;&#x4ECE;&#x6548;&#x679C;&#x6765;&#x8BF4;&#xFF0C;&#x76F8;&#x5F53;&#x4E8E;&#x76F4;&#x63A5;&#x5FFD;&#x7565;&#x4E86;<span class="mathjax-exps">$a^{[l]}$</span>&#x4E4B;&#x540E;&#x7684;&#x8FD9;&#x4E24;&#x5C42;&#x795E;&#x7ECF;&#x5C42;&#x3002;&#x8FD9;&#x6837;&#xFF0C;&#x770B;&#x4F3C;&#x5F88;&#x6DF1;&#x7684;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#xFF0C;&#x5176;&#x5B9E;&#x7531;&#x4E8E;&#x8BB8;&#x591A;&#x6B8B;&#x5DEE;&#x5757;&#x7684;&#x5B58;&#x5728;&#xFF0C;<strong>&#x5F31;&#x5316;&#x524A;&#x51CF;</strong>&#x4E86;&#x67D0;&#x4E9B;&#x795E;&#x7ECF;&#x5C42;&#x4E4B;&#x95F4;&#x7684;<strong>&#x8054;&#x7CFB;</strong>&#xFF0C;&#x5B9E;&#x73B0;&#x9694;&#x5C42;&#x7EBF;&#x6027;&#x4F20;&#x9012;&#xFF0C;&#x800C;&#x4E0D;&#x662F;&#x4E00;&#x5473;&#x8FFD;&#x6C42;&#x975E;&#x7EBF;&#x6027;&#x5173;&#x7CFB;&#xFF0C;&#x6A21;&#x578B;&#x672C;&#x8EAB;&#x4E5F;&#x5C31;&#x80FD;&#x201C;&#x5BB9;&#x5FCD;&#x201D;&#x66F4;&#x6DF1;&#x5C42;&#x7684;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x4E86;&#x3002;</p>
<p><strong>&#x6027;&#x80FD;</strong>&#xFF1A;&#x8FD9;&#x4E24;&#x5C42;&#x989D;&#x5916;&#x7684;&#x6B8B;&#x5DEE;&#x5757;&#x4E5F;&#x4E0D;&#x4F1A;&#x964D;&#x4F4E;Big NN&#x7684;&#x6027;&#x80FD;&#x3002;</p>
<p>&#x5F53;&#x7136;&#xFF0C;&#x5982;&#x679C;&#x6B8B;&#x5DEE;&#x5757;&#x786E;&#x5B9E;&#x80FD;&#x8BAD;&#x7EC3;&#x5F97;&#x5230;&#x975E;&#x7EBF;&#x6027;&#x5173;&#x7CFB;&#xFF0C;&#x90A3;&#x4E48;&#x4E5F;&#x4F1A;&#x5FFD;&#x7565;&#x5C0F;&#x7684;&#x7F29;&#x51CF;(short cut)&#xFF0C;&#x8DDF;Plain &#x7F51;&#x7EDC;&#x8D77;&#x5230;&#x540C;&#x6837;&#x7684;&#x6548;&#x679C;&#x3002;</p>
<h3 class="mume-header" id="%E7%BB%B4%E5%BA%A6%E9%97%AE%E9%A2%98">&#x7EF4;&#x5EA6;&#x95EE;&#x9898;</h3>

<p>&#x6709;&#x4E00;&#x70B9;&#x9700;&#x8981;&#x6CE8;&#x610F;&#x7684;&#x662F;&#xFF0C;&#x5982;&#x679C;&#x6B8B;&#x5DEE;&#x5757;&#x4E2D;<span class="mathjax-exps">$a^{[l+2]}$</span>&#x4E0E;<span class="mathjax-exps">$a^{[l]}$</span>&#x7684;&#x7EF4;&#x5EA6;&#x4E0D;&#x540C;&#xFF0C;&#x901A;&#x5E38;&#x53EF;&#x4EE5;&#x5F15;&#x5165;&#x77E9;&#x9635;<span class="mathjax-exps">$W_s$</span>&#xFF0C;&#x4E0E;<span class="mathjax-exps">$a^{[l]}$</span>&#x76F8;&#x4E58;&#xFF0C;&#x4F7F;&#x5F97;<span class="mathjax-exps">$W_s&#x2217;a^{[l]}$</span>&#x7684;&#x7EF4;&#x5EA6;&#x4E0E;<span class="mathjax-exps">$a^{[l+2]}$</span>&#x4E00;&#x81F4;&#x3002;</p>
<p>&#x53C2;&#x6570;&#x77E9;&#x9635;<span class="mathjax-exps">$W_s$</span>&#x6709;&#x6765;&#x4E24;&#x79CD;&#x65B9;&#x6CD5;&#x5F97;&#x5230;&#xFF1A;</p>
<p>A.&#x5C06;<span class="mathjax-exps">$W_s$</span>&#x4F5C;&#x4E3A;&#x5B66;&#x4E60;&#x53C2;&#x6570;&#xFF0C;&#x901A;&#x8FC7;&#x6A21;&#x578B;&#x8BAD;&#x7EC3;&#x5F97;&#x5230;&#xFF1B;</p>
<p>B.&#x56FA;&#x5B9A;<span class="mathjax-exps">$W_s$</span>&#x503C;&#xFF08;&#x7C7B;&#x4F3C;&#x5355;&#x4F4D;&#x77E9;&#x9635;&#xFF09;&#xFF0C;&#x4E0D;&#x9700;&#x8981;&#x8BAD;&#x7EC3;&#xFF0C;<span class="mathjax-exps">$W_s$</span>&#x4E0E;<span class="mathjax-exps">$a^{[l]}$</span>&#x7684;&#x4E58;&#x79EF;&#x4EC5;&#x4EC5;&#x4F7F;&#x5F97;<span class="mathjax-exps">$a^{[l]}$</span>&#x622A;&#x65AD;&#x6216;&#x8005;&#x8865;&#x96F6;&#x3002;&#x8FD9;&#x4E24;&#x79CD;&#x65B9;&#x6CD5;&#x90FD;&#x53EF;&#x884C;&#x3002;</p>
<p>&#x4E0B;&#x56FE;&#x6240;&#x793A;&#x7684;&#x662F;CNN&#x4E2D;&#x6B8B;&#x5DEE;&#x7F51;&#x7EDC;&#x7684;&#x7ED3;&#x6784;&#xFF1A;</p>
<p><img src="img/30.jpg" alt></p>
<p>&#x6B8B;&#x5DEE;&#x7F51;&#x7EDC;&#x540C;&#x7C7B;&#x578B;&#x5C42;&#x4E4B;&#x95F4;&#xFF0C;&#x4F8B;&#x5982;CONV&#x5C42;&#xFF0C;&#x5927;&#x591A;&#x4F7F;&#x7528;&#x76F8;&#x540C;&#x7C7B;&#x578B;&#xFF0C;&#x4FDD;&#x6301;&#x7EF4;&#x5EA6;&#x76F8;&#x540C;&#x3002;&#x5982;&#x679C;&#x662F;&#x4E0D;&#x540C;&#x7C7B;&#x578B;&#x5C42;&#x4E4B;&#x95F4;&#x7684;&#x8FDE;&#x63A5;&#xFF0C;&#x4F8B;&#x5982;CONV&#x5C42;r&#x4E0E;POOL&#x5C42;&#x4E4B;&#x95F4;&#xFF0C;&#x5982;&#x679C;&#x7EF4;&#x5EA6;&#x4E0D;&#x540C;&#xFF0C;&#x5219;&#x5F15;&#x5165;&#x77E9;&#x9635;<span class="mathjax-exps">$W_s$</span>&#x3002;</p>
<h2 class="mume-header" id="%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E7%BD%91%E7%BB%9C%E4%BB%A5%E5%8F%8A-11-%E5%8D%B7%E7%A7%AF%E6%A0%B8">&#x7F51;&#x7EDC;&#x4E2D;&#x7684;&#x7F51;&#x7EDC;&#x4EE5;&#x53CA; 1&#xD7;1 &#x5377;&#x79EF;&#x6838;</h2>

<h3 class="mume-header" id="%E5%AE%9A%E4%B9%89">&#x5B9A;&#x4E49;</h3>

<p>Min Lin, Qiang Chen&#x7B49;&#x4EBA;&#x63D0;&#x51FA;&#x4E86;&#x4E00;&#x79CD;&#x65B0;&#x7684;CNN&#x7ED3;&#x6784;&#xFF0C;&#x5373;1x1 &#x5377;&#x79EF;&#x6838;&#xFF0C;&#x4E5F;&#x79F0;&#x7F51;&#x7EDC;&#x4E2D;&#x7684;&#x7F51;&#x7EDC;&#x3002;&#x8FD9;&#x79CD;&#x7ED3;&#x6784;&#x7684;&#x7279;&#x70B9;&#x662F;&#x6EE4;&#x6CE2;&#x5668;&#x7B97;&#x5B50;filter&#x7684;&#x7EF4;&#x5EA6;&#x4E3A;1x1&#x3002;</p>
<h3 class="mume-header" id="%E6%95%88%E6%9E%9C">&#x6548;&#x679C;</h3>

<p>&#x5BF9;&#x4E8E;<strong>&#x5355;&#x4E2A;</strong>filter&#xFF0C;1x1&#x7684;&#x7EF4;&#x5EA6;&#xFF0C;&#x610F;&#x5473;&#x7740;&#x5377;&#x79EF;&#x64CD;&#x4F5C;&#x7B49;&#x540C;&#x4E8E;&#x4E58;&#x79EF;&#x64CD;&#x4F5C;&#x3002;</p>
<p><img src="img/31.jpg" alt></p>
<p>&#x90A3;&#x4E48;&#xFF0C;&#x5BF9;&#x4E8E;<strong>&#x591A;&#x4E2A;</strong>filter&#xFF0C;1x1 &#x5377;&#x79EF;&#x6838;&#x7684;&#x4F5C;&#x7528;&#x5B9E;&#x9645;&#x4E0A;&#x7C7B;&#x4F3C;&#x5168;&#x8FDE;&#x63A5;&#x5C42;&#x7684;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x7ED3;&#x6784;&#x3002;&#x6548;&#x679C;&#x7B49;&#x540C;&#x4E8E;Plain&#x7F51;&#x7EDC;&#x4E2D;<span class="mathjax-exps">$a^{[l]}$</span>&#x5230;<span class="mathjax-exps">$a^{[l+1]}$</span>&#x7684;&#x8FC7;&#x7A0B;&#x3002;&#x3010;&#x538B;&#x6241;&#xFF01;&#x3011;</p>
<p><img src="img/32.jpg" alt></p>
<p>1x1 &#x5377;&#x79EF;&#x6838;&#x53EF;&#x4EE5;&#x7528;&#x6765;<strong>&#x7F29;&#x51CF;</strong>&#x8F93;&#x5165;&#x56FE;&#x7247;&#x7684;<strong>&#x901A;&#x9053;&#x6570;&#x76EE;</strong>&#x3002;</p>
<p>&#x65B9;&#x6CD5;&#x5982;&#x4E0B;&#x56FE;&#xFF1A;</p>
<p><img src="img/33.jpg" alt></p>
<h2 class="mume-header" id="inception%E7%BD%91%E7%BB%9C">Inception&#x7F51;&#x7EDC;</h2>

<h3 class="mume-header" id="%E7%AE%80%E4%BB%8B">&#x7B80;&#x4ECB;</h3>

<p>&#x4E4B;&#x524D;&#x6211;&#x4EEC;&#x4ECB;&#x7ECD;&#x7684;CNN&#x5355;&#x5C42;&#x7684;&#x6EE4;&#x6CE2;&#x7B97;&#x5B50;filter&#x5C3A;&#x5BF8;&#x662F;&#x56FA;&#x5B9A;&#x7684;&#xFF0C;1x1&#x6216;&#x8005;3x3&#x7B49;&#x3002;&#x800C;Inception&#x7F51;&#x7EDC;&#x5728;&#x5355;&#x5C42;&#x7F51;&#x7EDC;&#x4E0A;&#x53EF;&#x4EE5;&#x4F7F;&#x7528;&#x591A;&#x4E2A;&#x4E0D;&#x540C;&#x5C3A;&#x5BF8;&#x7684;filters&#xFF0C;&#x8FDB;&#x884C;&#x76F8;&#x540C;&#x65B9;&#x5F0F;&#x7684;&#x5377;&#x79EF;&#xFF0C;&#x628A;&#x5404;filter&#x4E0B;&#x5F97;&#x5230;&#x7684;&#x8F93;&#x51FA;&#x62FC;&#x63A5;&#x8D77;&#x6765;&#x3002;&#x9664;&#x6B64;&#x4E4B;&#x5916;&#xFF0C;&#x8FD8;&#x53EF;&#x4EE5;&#x5C06;CONV&#x5C42;&#x4E0E;POOL&#x5C42;&#x6DF7;&#x5408;&#xFF0C;&#x540C;&#x65F6;&#x5B9E;&#x73B0;&#x5404;&#x79CD;&#x6548;&#x679C;&#x3002;&#x4F46;&#x662F;&#x8981;&#x6CE8;&#x610F;&#x4FDD;&#x6301;&#x76F8;&#x540C;&#x7684;&#x6C60;&#x5316;&#x3002;</p>
<p><img src="img/34.jpg" alt></p>
<h3 class="mume-header" id="%E5%AE%9A%E4%B9%89-1">&#x5B9A;&#x4E49;</h3>

<p>Inception&#x7F51;&#x7EDC;&#x7531;Christian Szegedy, Wei Liu&#x7B49;&#x4EBA;&#x63D0;&#x51FA;&#x3002;&#x4E0E;&#x5176;&#x5B83;&#x53EA;&#x9009;&#x62E9;&#x5355;&#x4E00;&#x5C3A;&#x5BF8;&#x548C;&#x529F;&#x80FD;&#x7684;filter&#x4E0D;&#x540C;&#xFF0C;Inception&#x7F51;&#x7EDC;&#x4F7F;&#x7528;&#x4E0D;&#x540C;&#x5C3A;&#x5BF8;&#x7684;filters&#x5E76;&#x5C06;CONV&#x548C;POOL&#x6DF7;&#x5408;&#x8D77;&#x6765;&#xFF0C;&#x5C06;&#x6240;&#x6709;&#x529F;&#x80FD;&#x8F93;&#x51FA;&#x7EC4;&#x5408;&#x62FC;&#x63A5;&#xFF0C;&#x518D;&#x7531;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x672C;&#x8EAB;&#x53BB;&#x5B66;&#x4E60;&#x53C2;&#x6570;&#x5E76;&#x9009;&#x62E9;&#x6700;&#x597D;&#x7684;&#x6A21;&#x5757;&#x3002;</p>
<h3 class="mume-header" id="%E8%AF%84%E4%BB%B7-1">&#x8BC4;&#x4EF7;</h3>

<p>Inception&#x7F51;&#x7EDC;&#x5728;<strong>&#x63D0;&#x5347;&#x6027;&#x80FD;</strong>&#x7684;&#x540C;&#x65F6;&#xFF0C;&#x4F1A;&#x5E26;&#x6765;<strong>&#x8BA1;&#x7B97;&#x91CF;&#x5927;</strong>&#x7684;&#x95EE;&#x9898;&#x3002;&#x4F8B;&#x5982;&#x4E0B;&#x9762;&#x8FD9;&#x4E2A;&#x4F8B;&#x5B50;&#xFF1A;</p>
<p><img src="img/35.jpg" alt></p>
<h4 class="mume-header" id="%E4%BC%98%E5%8C%96">&#x4F18;&#x5316;</h4>

<p>&#x6B64;CONV&#x5C42;&#x9700;&#x8981;&#x7684;&#x8BA1;&#x7B97;&#x91CF;&#x4E3A;&#xFF1A;28x28x32x5x5x192=120M&#xFF0C;&#x5176;&#x4E2D;M&#x8868;&#x793A;&#x767E;&#x4E07;&#x5355;&#x4F4D;&#x3002;&#x53EF;&#x4EE5;&#x770B;&#x51FA;&#x4F46;&#x8FD9;&#x4E00;&#x5C42;&#x7684;&#x8BA1;&#x7B97;&#x91CF;&#x90FD;&#x662F;&#x5F88;&#x5927;&#x7684;&#x3002;&#x4E3A;&#x6B64;&#xFF0C;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x5F15;&#x5165;1x1&#x5377;&#x79EF;&#x6765;<strong>&#x51CF;&#x5C11;&#x5176;&#x8BA1;&#x7B97;&#x91CF;</strong>&#xFF0C;&#x7ED3;&#x6784;&#x5982;&#x4E0B;&#x56FE;&#x6240;&#x793A;&#xFF1A;</p>
<p><img src="img/36.jpg" alt></p>
<p>&#x901A;&#x5E38;&#x6211;&#x4EEC;&#x628A;&#x8BE5;1x1&#x5377;&#x79EF;&#x79F0;&#x4E3A;&#x201C;&#x74F6;&#x9888;&#x5C42;&#x201D;&#xFF08;bottleneck layer&#xFF09;&#x3002;&#x5F15;&#x5165;&#x74F6;&#x9888;&#x5C42;&#x4E4B;&#x540E;&#xFF0C;&#x603B;&#x5171;&#x9700;&#x8981;&#x7684;&#x8BA1;&#x7B97;&#x91CF;&#x4E3A;&#xFF1A;28x28x16x192+28x28x32x5x5x16=12.4M&#x3002;&#x660E;&#x663E;&#x5730;&#xFF0C;&#x867D;&#x7136;&#x591A;&#x5F15;&#x5165;&#x4E86;1x1&#x5377;&#x79EF;&#x5C42;&#xFF0C;&#x4F46;&#x662F;&#x603B;&#x5171;&#x7684;&#x8BA1;&#x7B97;&#x91CF;&#x51CF;&#x5C11;&#x4E86;&#x8FD1;90%&#xFF0C;&#x6548;&#x679C;&#x8FD8;&#x662F;&#x975E;&#x5E38;&#x660E;&#x663E;&#x7684;&#x3002;&#x7531;&#x6B64;&#x53EF;&#x89C1;&#xFF0C;1x1 &#x5377;&#x79EF;&#x8FD8;&#x53EF;&#x4EE5;&#x6709;&#x6548;&#x51CF;&#x5C11;CONV&#x5C42;&#x7684;&#x8BA1;&#x7B97;&#x91CF;&#x3002;</p>
<h3 class="mume-header" id="%E5%BD%A2%E6%88%90inception%E7%BD%91%E7%BB%9C">&#x5F62;&#x6210;Inception&#x7F51;&#x7EDC;</h3>

<p>&#x4E0A;&#x4E00;&#x8282;&#x6211;&#x4EEC;&#x4F7F;&#x7528;1x1 &#x5377;&#x79EF;&#x6765;&#x51CF;&#x5C11;Inception&#x7F51;&#x7EDC;&#x8BA1;&#x7B97;&#x91CF;&#x5927;&#x7684;&#x95EE;&#x9898;&#x3002;&#x5F15;&#x5165;1x1 &#x5377;&#x79EF;&#x540E;&#x7684;Inception&#x6A21;&#x5757;&#x5982;&#x4E0B;&#x56FE;&#x6240;&#x793A;&#xFF1A;</p>
<p><img src="img/37.jpg" alt></p>
<p>&#x591A;&#x4E2A;Inception&#x6A21;&#x5757;&#x7EC4;&#x6210;Inception&#x7F51;&#x7EDC;&#xFF0C;&#x6548;&#x679C;&#x5982;&#x4E0B;&#x56FE;&#x6240;&#x793A;&#xFF1A;</p>
<p><img src="img/38.jpg" alt></p>
<h4 class="mume-header" id="%E6%B3%A8%E6%84%8F">&#x6CE8;&#x610F;</h4>

<p>&#x4E0A;&#x8FF0;Inception&#x7F51;&#x7EDC;k&#x9664;&#x4E86;&#x7531;&#x8BB8;&#x591A;Inception&#x6A21;&#x5757;&#x7EC4;&#x6210;&#x4E4B;&#x5916;&#xFF0C;&#x503C;&#x5F97;&#x4E00;&#x63D0;&#x7684;&#x662F;&#x7F51;&#x7EDC;&#x4E2D;&#x95F4;&#x9690;&#x85CF;&#x5C42;&#x4E5F;&#x53EF;&#x4EE5;&#x4F5C;&#x4E3A;&#x8F93;&#x51FA;&#x5C42;Softmax&#xFF0C;&#x6709;&#x5229;&#x4E8E;&#x9632;&#x6B62;&#x53D1;&#x751F;&#x8FC7;&#x62DF;&#x5408;&#x3002;</p>
<h2 class="mume-header" id="%E4%BD%BF%E7%94%A8%E5%BC%80%E6%BA%90%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%96%B9%E6%A1%88%E7%95%A5">&#x4F7F;&#x7528;&#x5F00;&#x6E90;&#x7684;&#x5B9E;&#x73B0;&#x65B9;&#x6848;&#xFF08;&#x7565;&#xFF09;</h2>

<p>&#x672C;&#x8282;&#x4E3B;&#x8981;&#x4ECB;&#x7ECD;GitHub&#x7684;&#x4F7F;&#x7528;&#xFF0C;GitHub&#x662F;&#x4E00;&#x4E2A;&#x9762;&#x5411;&#x5F00;&#x6E90;&#x53CA;&#x79C1;&#x6709;&#x8F6F;&#x4EF6;&#x9879;&#x76EE;&#x7684;&#x6258;&#x7BA1;&#x5E73;&#x53F0;&#xFF0C;&#x4E0A;&#x9762;&#x5305;&#x542B;&#x6709;&#x8BB8;&#x591A;&#x4F18;&#x79C0;&#x7684;CNN&#x5F00;&#x6E90;&#x9879;&#x76EE;&#x3002;</p>
<h2 class="mume-header" id="%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%95%A5">&#x8FC1;&#x79FB;&#x5B66;&#x4E60;&#xFF08;&#x7565;&#xFF09;</h2>

<p>&#x8BE6;&#x89C1;&#x4E0A;&#x5468;&#x7684;&#x8FC1;&#x79FB;&#x5B66;&#x4E60;</p>
<h2 class="mume-header" id="%E6%95%B0%E6%8D%AE%E6%89%A9%E5%85%85">&#x6570;&#x636E;&#x6269;&#x5145;</h2>

<p>&#x5E38;&#x7528;&#x7684;<strong>&#x6570;&#x636E;&#x6269;&#x5145;</strong>&#x65B9;&#x6CD5;&#x662F;&#x5BF9;&#x5DF2;&#x6709;&#x7684;&#x6837;&#x672C;&#x96C6;&#x8FDB;&#x884C;<strong>&#x955C;&#x50CF;</strong>&#x548C;<strong>&#x968F;&#x673A;&#x88C1;&#x526A;</strong>&#x5904;&#x7406;&#x3002;</p>
<p><img src="img/39.jpg" alt></p>
<p>&#x53E6;&#x4E00;&#x79CD;&#x6570;&#x636E;&#x6269;&#x5145;&#x7684;&#x65B9;&#x6CD5;&#x662F;&#x8C03;&#x8272;&#x3002;&#x8C03;&#x8272;&#x5C31;&#x662F;&#x5BF9;&#x56FE;&#x7247;&#x7684;RGB&#x901A;&#x9053;&#x6570;&#x503C;&#x8FDB;&#x884C;&#x968F;&#x610F;&#x589E;&#x52A0;&#x6216;&#x8005;&#x51CF;&#x5C11;&#xFF0C;&#x6539;&#x53D8;&#x56FE;&#x7247;&#x8272;&#x8C03;&#x3002;</p>
<p><img src="img/40.jpg" alt></p>
<p>&#x9664;&#x4E86;&#x968F;&#x610F;&#x6539;&#x53D8;RGB&#x901A;&#x9053;&#x6570;&#x503C;&#x5916;&#xFF0C;&#x8FD8;&#x53EF;&#x4EE5;&#x66F4;&#x6709;&#x9488;&#x5BF9;&#x6027;&#x5730;&#x5BF9;&#x56FE;&#x7247;&#x7684;RGB&#x901A;&#x9053;&#x8FDB;&#x884C;PCA &#x989C;&#x8272;&#x6269;&#x5145;&#xFF0C;&#x4E5F;&#x5C31;&#x662F;&#x5BF9;&#x56FE;&#x7247;&#x989C;&#x8272;&#x8FDB;&#x884C;&#x4E3B;&#x6210;&#x5206;&#x5206;&#x6790;&#xFF0C;&#x5BF9;&#x4E3B;&#x8981;&#x7684;&#x901A;&#x9053;&#x989C;&#x8272;&#x8FDB;&#x884C;&#x589E;&#x52A0;&#x6216;&#x51CF;&#x5C11;&#xFF0C;&#x53EF;&#x4EE5;&#x91C7;&#x7528;&#x9AD8;&#x65AF;&#x6270;&#x52A8;&#x505A;&#x6CD5;&#x3002;&#x8FD9;&#x6837;&#x4E5F;&#x80FD;&#x589E;&#x52A0;&#x6709;&#x6548;&#x7684;&#x6837;&#x672C;&#x6570;&#x91CF;&#x3002;&#x5177;&#x4F53;&#x7684;PCA &#x989C;&#x8272;&#x6269;&#x5145;&#x505A;&#x6CD5;&#x53EF;&#x4EE5;&#x67E5;&#x9605;AlexNet&#x7684;&#x76F8;&#x5173;&#x8BBA;&#x6587;&#x3002;</p>
<p>&#x6700;&#x540E;&#x63D0;&#x4E00;&#x4E0B;&#xFF0C;&#x5728;&#x6784;&#x5EFA;&#x5927;&#x578B;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x7684;&#x65F6;&#x5019;&#xFF0C;&#x6570;&#x636E;&#x6269;&#x5145;&#x548C;&#x8BAD;&#x7EC3;&#x53EF;&#x4EE5;&#x7531;<strong>&#x4E24;&#x4E2A;&#x4E0D;&#x540C;&#x7684;&#x7EBF;&#x7A0B;</strong>&#x6765;&#x8FDB;&#x884C;&#x3002;</p>
<h3 class="mume-header" id="%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E6%89%A9%E5%85%85">&#x8BA1;&#x7B97;&#x673A;&#x89C6;&#x89C9;&#x6269;&#x5145;</h3>

<p>&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x9700;&#x8981;&#x6570;&#x636E;&#xFF0C;&#x4E0D;&#x540C;&#x7684;&#x7F51;&#x7EDC;&#x6A21;&#x578B;&#x6240;&#x9700;&#x7684;&#x6570;&#x636E;&#x91CF;&#x662F;&#x4E0D;&#x540C;&#x7684;&#x3002;&#x76EE;&#x6807;&#x68C0;&#x6D4B;&#xFF0C;&#x56FE;&#x50CF;&#x8BC6;&#x522B;&#xFF0C;&#x8BED;&#x97F3;&#x8BC6;&#x522B;&#x6240;&#x9700;&#x7684;&#x6570;&#x636E;&#x91CF;&#x4F9D;&#x6B21;&#x589E;&#x52A0;&#x3002;&#x4E00;&#x822C;&#x6765;&#x8BF4;&#xFF0C;&#x5982;&#x679C;&#x6570;&#x636E;&#x8F83;&#x5C11;&#xFF0C;&#x90A3;&#x4E48;&#x5C31;&#x9700;&#x8981;&#x66F4;&#x591A;&#x7684;&#x624B;&#x52A8;&#x8BBE;&#x8BA1;&#xFF0C;&#x5BF9;&#x5DF2;&#x6709;&#x6570;&#x636E;&#x8FDB;&#x884C;&#x5904;&#x7406;&#xFF0C;&#x6BD4;&#x5982;&#x4E0A;&#x4E00;&#x8282;&#x4ECB;&#x7ECD;&#x7684;&#x6570;&#x636E;&#x6269;&#x5145;&#x3002;&#x6A21;&#x578B;&#x7B97;&#x6CD5;&#x4E5F;&#x4F1A;&#x76F8;&#x5BF9;&#x8981;&#x590D;&#x6742;&#x4E00;&#x4E9B;&#x3002;&#x5982;&#x679C;&#x6570;&#x636E;&#x5F88;&#x591A;&#xFF0C;&#x53EF;&#x4EE5;&#x6784;&#x5EFA;&#x6DF1;&#x5C42;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#xFF0C;&#x4E0D;&#x9700;&#x8981;&#x592A;&#x591A;&#x7684;&#x624B;&#x52A8;&#x8BBE;&#x8BA1;&#xFF0C;&#x6A21;&#x578B;&#x7B97;&#x6CD5;&#x4E5F;&#x5C31;&#x76F8;&#x5BF9;&#x7B80;&#x5355;&#x4E00;&#x4E9B;&#x3002;</p>
<p><img src="img/41.jpg" alt></p>
<p>&#x503C;&#x5F97;&#x4E00;&#x63D0;&#x7684;&#x662F;&#x624B;&#x52A8;&#x8BBE;&#x8BA1;&#x662F;&#x4E00;&#x9879;&#x975E;&#x5E38;&#x91CD;&#x8981;&#x4E5F;&#x6BD4;&#x8F83;&#x56F0;&#x96BE;&#x7684;&#x5DE5;&#x4F5C;&#x3002;&#x5F88;&#x591A;&#x65F6;&#x5019;&#xFF0C;&#x624B;&#x52A8;&#x8BBE;&#x8BA1;&#x5BF9;&#x6A21;&#x578B;&#x8BAD;&#x7EC3;&#x6548;&#x679C;&#x5F71;&#x54CD;&#x5F88;&#x5927;&#xFF0C;&#x7279;&#x522B;&#x662F;&#x5728;&#x6570;&#x636E;&#x91CF;&#x4E0D;&#x591A;&#x7684;&#x60C5;&#x51B5;&#x4E0B;&#x3002;</p>
<p>&#x5728;&#x6A21;&#x578B;&#x7814;&#x7A76;&#x6216;&#x8005;&#x7ADE;&#x8D5B;&#x65B9;&#x9762;&#xFF0C;&#x6709;&#x4E00;&#x4E9B;&#x65B9;&#x6CD5;&#x80FD;&#x591F;&#x6709;&#x52A9;&#x4E8E;&#x63D0;&#x5347;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x6A21;&#x578B;&#x7684;&#x6027;&#x80FD;&#xFF1A;</p>
<ul>
<li><strong>&#x96C6;&#x6210;:&#x72EC;&#x7ACB;&#x5730;&#x8BAD;&#x7EC3;&#x51E0;&#x4E2A;&#x7F51;&#x7EDC;&#x5E76;&#x5E73;&#x5747;&#x5B83;&#x4EEC;&#x7684;&#x8F93;&#x51FA;&#x3002;</strong></li>
<li><strong>&#x6D4B;&#x8BD5;&#x65F6;&#x591A;&#x91CD;&#x88C1;&#x526A;:&#x5BF9;&#x591A;&#x4E2A;&#x7248;&#x672C;&#x7684;&#x6D4B;&#x8BD5;&#x56FE;&#x50CF;&#x548C;&#x5E73;&#x5747;&#x7ED3;&#x679C;&#x8FD0;&#x884C;&#x5206;&#x7C7B;&#x5668;&#x3002;</strong></li>
</ul>
<p><img src="img/42.jpg" alt></p>
<p>&#x4F46;&#x662F;&#x7531;&#x4E8E;&#x8FD9;&#x4E24;&#x79CD;&#x65B9;&#x6CD5;&#x8BA1;&#x7B97;&#x6210;&#x672C;&#x8F83;&#x5927;&#xFF0C;&#x4E00;&#x822C;&#x4E0D;&#x9002;&#x7528;&#x4E8E;&#x5B9E;&#x9645;&#x9879;&#x76EE;&#x5F00;&#x53D1;&#x3002;</p>
<h2 class="mume-header" id="%E6%B3%A8%E6%84%8F-1">&#x6CE8;&#x610F;</h2>

<p>&#x6700;&#x540E;&#xFF0C;&#x6211;&#x4EEC;&#x8FD8;&#x8981;&#x7075;&#x6D3B;&#x4F7F;&#x7528;&#x5F00;&#x6E90;&#x4EE3;&#x7801;&#xFF1A;</p>
<ul>
<li><strong>&#x4F7F;&#x7528;&#x6587;&#x732E;&#x4E2D;&#x53D1;&#x5E03;&#x7684;&#x7F51;&#x7EDC;&#x67B6;&#x6784;</strong></li>
<li><strong>&#x5C3D;&#x53EF;&#x80FD;&#x4F7F;&#x7528;&#x5F00;&#x6E90;&#x5B9E;&#x73B0;</strong></li>
<li><strong>&#x4F7F;&#x7528;&#x9884;&#x5148;&#x8BAD;&#x7EC3;&#x597D;&#x7684;&#x6A21;&#x578B;&#x5E76;&#x5BF9;&#x6570;&#x636E;&#x96C6;&#x8FDB;&#x884C;&#x5FAE;&#x8C03;</strong></li>
</ul>
<h1 class="mume-header" id="keras-%E6%95%99%E7%A8%8B-%E5%BC%80%E5%BF%83%E7%9A%84%E6%88%BF%E5%AD%90happy-house">Keras &#x6559;&#x7A0B; - &#x5F00;&#x5FC3;&#x7684;&#x623F;&#x5B50;&#xFF08;Happy House&#xFF09;</h1>

<p>&#x5728;&#x8FD9;&#x4E2A;&#x4EFB;&#x52A1;&#x4E2D;&#xFF0C;&#x60A8;&#x5C06;&#xFF1A;</p>
<ol>
<li>&#x5B66;&#x4E60;&#x4F7F;&#x7528;Keras&#xFF0C;&#x8FD9;&#x662F;&#x4E00;&#x4E2A;&#x7528;Python&#x7F16;&#x5199;&#x7684;&#x9AD8;&#x7EA7;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;API&#xFF08;&#x7F16;&#x7A0B;&#x6846;&#x67B6;&#xFF09;&#xFF0C;&#x80FD;&#x591F;&#x5728;&#x5305;&#x62EC;TensorFlow&#x548C;CNTK&#x5728;&#x5185;&#x7684;&#x51E0;&#x4E2A;&#x5E95;&#x5C42;&#x6846;&#x67B6;&#x4E0A;&#x8FD0;&#x884C;&#x3002;</li>
<li>&#x770B;&#x770B;&#x5982;&#x4F55;&#x5728;&#x51E0;&#x4E2A;&#x5C0F;&#x65F6;&#x5185;&#x5EFA;&#x7ACB;&#x4E00;&#x4E2A;&#x6DF1;&#x5EA6;&#x5B66;&#x4E60;&#x7B97;&#x6CD5;&#x3002;</li>
</ol>
<p>&#x4E3A;&#x4EC0;&#x4E48;&#x6211;&#x4EEC;&#x4F7F;&#x7528;Keras&#xFF1F;Keras&#x7684;&#x5F00;&#x53D1;&#x662F;&#x4E3A;&#x4E86;&#x8BA9;&#x6DF1;&#x5EA6;&#x5B66;&#x4E60;&#x7684;&#x5DE5;&#x7A0B;&#x5E08;&#x80FD;&#x591F;&#x975E;&#x5E38;&#x5FEB;&#x901F;&#x5730;&#x5EFA;&#x7ACB;&#x548C;&#x5C1D;&#x8BD5;&#x4E0D;&#x540C;&#x7684;&#x6A21;&#x578B;&#x3002;&#x5C31;&#x50CF;TensorFlow&#x662F;&#x4E00;&#x4E2A;&#x6BD4;Python&#x66F4;&#x9AD8;&#x7EA7;&#x522B;&#x7684;&#x6846;&#x67B6;&#x4E00;&#x6837;&#xFF0C;Keras&#x662F;&#x4E00;&#x4E2A;&#x66F4;&#x9AD8;&#x5C42;&#x6B21;&#x7684;&#x6846;&#x67B6;&#xFF0C;&#x5E76;&#x63D0;&#x4F9B;&#x989D;&#x5916;&#x7684;&#x62BD;&#x8C61;&#x3002;&#x80FD;&#x591F;&#x4EE5;&#x6700;&#x5C11;&#x7684;&#x65F6;&#x95F4;&#x6839;&#x636E;ideal&#x83B7;&#x53D6;&#x7ED3;&#x679C;&#x662F;&#x5BFB;&#x627E;&#x597D;&#x6A21;&#x578B;&#x7684;&#x5173;&#x952E;&#x3002;&#x53EF;&#x662F;&#xFF0C;Keras&#x76F8;&#x5BF9;&#x5E95;&#x5C42;&#x6846;&#x67B6;&#x62E5;&#x6709;&#x66F4;&#x591A;&#x7684;&#x9650;&#x5236;&#xFF0C;&#x6240;&#x4EE5;&#x6709;&#x4E9B;&#x80FD;&#x5728;TensorFlow&#x4E2D;&#x5B9E;&#x73B0;&#x7684;&#x975E;&#x5E38;&#x590D;&#x6742;&#x7684;&#x6A21;&#x578B;&#x5728;Keras&#x4E2D;&#x5374;&#x4E0D;&#x80FD;&#x5B9E;&#x73B0;&#x3002;&#x4E5F;&#x5C31;&#x662F;&#x8BF4;&#xFF0C;Keras &#x53EA;&#x5BF9;&#x5E38;&#x89C1;&#x7684;&#x6A21;&#x578B;&#x652F;&#x6301;&#x826F;&#x597D;&#x3002;</p>
<h2 class="mume-header" id="%E5%AF%BC%E5%8C%85">&#x5BFC;&#x5305;</h2>

<pre data-role="codeBlock" data-info="python" class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> keras <span class="token keyword">import</span> layers
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> Input<span class="token punctuation">,</span> Dense<span class="token punctuation">,</span> Activation<span class="token punctuation">,</span> ZeroPadding2D<span class="token punctuation">,</span> BatchNormalization<span class="token punctuation">,</span> Flatten<span class="token punctuation">,</span> Conv2D
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> AveragePooling2D<span class="token punctuation">,</span> MaxPooling2D<span class="token punctuation">,</span> Dropout<span class="token punctuation">,</span> GlobalMaxPooling2D<span class="token punctuation">,</span> GlobalAveragePooling2D
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>models <span class="token keyword">import</span> Model
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> image
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>utils <span class="token keyword">import</span> layer_utils
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data_utils <span class="token keyword">import</span> get_file
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>applications<span class="token punctuation">.</span>imagenet_utils <span class="token keyword">import</span> preprocess_input
<span class="token keyword">import</span> pydot
<span class="token keyword">from</span> IPython<span class="token punctuation">.</span>display <span class="token keyword">import</span> SVG
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>vis_utils <span class="token keyword">import</span> model_to_dot
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>utils <span class="token keyword">import</span> plot_model
<span class="token keyword">from</span> kt_utils <span class="token keyword">import</span> <span class="token operator">*</span>

<span class="token keyword">import</span> keras<span class="token punctuation">.</span>backend <span class="token keyword">as</span> K
K<span class="token punctuation">.</span>set_image_data_format<span class="token punctuation">(</span><span class="token string">&apos;channels_last&apos;</span><span class="token punctuation">)</span>
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">from</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">import</span> imshow

<span class="token operator">%</span>matplotlib inline
</pre><h2 class="mume-header" id="%E5%BC%80%E5%BF%83%E7%9A%84%E6%88%BF%E5%AD%90">&#x5F00;&#x5FC3;&#x7684;&#x623F;&#x5B50;</h2>

<p>&#x4F60;&#x7684;&#x4E0B;&#x4E00;&#x4E2A;&#x5047;&#x671F;&#xFF0C;&#x4F60;&#x51B3;&#x5B9A;&#x82B1;&#x4E00;&#x4E2A;&#x661F;&#x671F;&#x4E0E;&#x4F60;&#x5B66;&#x6821;&#x91CC;&#x7684;&#x4E94;&#x4E2A;&#x670B;&#x53CB;&#x5728;&#x4E00;&#x8D77;&#x73A9;&#x3002;&#x8FD9;&#x662F;&#x4E00;&#x4E2A;&#x975E;&#x5E38;&#x65B9;&#x4FBF;&#x7684;&#x623F;&#x5B50;&#xFF0C;&#x9644;&#x8FD1;&#x6709;&#x5F88;&#x591A;&#x4E8B;&#x60C5;&#x53EF;&#x4EE5;&#x505A;&#x3002;&#x4F46;&#x6700;&#x91CD;&#x8981;&#x7684;&#x597D;&#x5904;&#x662F;&#xFF0C;&#x6BCF;&#x4E2A;&#x4EBA;&#x5728;&#x623F;&#x5B50;&#x91CC;&#x7684;&#x65F6;&#x5019;&#x90FD;&#x611F;&#x5230;&#x5FEB;&#x4E50;&#x3002;&#x4EFB;&#x4F55;&#x60F3;&#x8981;&#x8FDB;&#x5165;&#x623F;&#x5B50;&#x7684;&#x4EBA;&#x90FD;&#x5FC5;&#x987B;&#x8BC1;&#x660E;&#x81EA;&#x5DF1;&#x5F53;&#x524D;&#x662F;&#x5F00;&#x5FC3;&#x5FEB;&#x4E50;&#x7684;&#x3002;</p>
<h3 class="mume-header" id="%E5%BC%80%E5%BF%83%E7%9A%84%E6%88%BF%E5%AD%90-1">&#x5F00;&#x5FC3;&#x7684;&#x623F;&#x5B50;</h3>

<p>&#x4F5C;&#x4E3A;&#x4E00;&#x540D;&#x6DF1;&#x5EA6;&#x5B66;&#x4E60;&#x4E13;&#x5BB6;&#xFF0C;&#x4E3A;&#x4E86;&#x786E;&#x4FDD; &quot;&#x5F00;&#x5FC3;&quot; &#x7684;&#x89C4;&#x5219;&#x5F97;&#x5230;&#x4E25;&#x683C;&#x5B9E;&#x65BD;, &#x60A8;&#x5C06;&#x6253;&#x7B97;&#x4F7F;&#x7528;&#x524D;&#x95E8;&#x6444;&#x50CF;&#x5934;&#x62CD;&#x6444;&#x7684;&#x56FE;&#x7247;&#x6765;&#x68C0;&#x67E5;&#x8BE5;&#x4EBA;&#x662F;&#x5426;&#x5FEB;&#x4E50;&#x3002;&#x53EA;&#x6709;&#x5F53;&#x4EBA;&#x611F;&#x5230;&#x5FEB;&#x4E50;&#x65F6;&#xFF0C;&#x95E8;&#x624D;&#x4F1A;&#x6253;&#x5F00;&#x3002;</p>
<p>&#x4F60;&#x6536;&#x96C6;&#x4E86;&#x4F60;&#x7684;&#x670B;&#x53CB;&#x548C;&#x4F60;&#x81EA;&#x5DF1;&#x7684;&#x7167;&#x7247;&#xFF0C;&#x7531;&#x524D;&#x95E8;&#x6444;&#x50CF;&#x5934;&#x62CD;&#x6444;&#x3002;&#x6570;&#x636E;&#x96C6;&#x662F;&#x5E26;&#x6709;&#x6807;&#x7B7E;&#x7684;&#x3002;</p>
<h4 class="mume-header" id="%E4%BA%86%E8%A7%A3%E6%95%B0%E6%8D%AE%E7%9A%84shape">&#x4E86;&#x89E3;&#x6570;&#x636E;&#x7684;shape</h4>

<p>&#x8FD0;&#x884C;&#x4E0B;&#x9762;&#x7684;&#x4EE3;&#x7801;&#x6765;&#x6807;&#x51C6;&#x5316;&#x6570;&#x636E;&#x96C6;&#x5E76;&#x4E86;&#x89E3;&#x5B83;&#x7684;&#x5F62;&#x72B6;&#x3002;</p>
<pre data-role="codeBlock" data-info="python" class="language-python">X_train_orig<span class="token punctuation">,</span> Y_train_orig<span class="token punctuation">,</span> X_test_orig<span class="token punctuation">,</span> Y_test_orig<span class="token punctuation">,</span> classes <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># &#x6B63;&#x5219;&#x5316;&#x5411;&#x91CF;</span>
X_train <span class="token operator">=</span> X_train_orig<span class="token operator">/</span><span class="token number">255</span><span class="token punctuation">.</span>
X_test <span class="token operator">=</span> X_test_orig<span class="token operator">/</span><span class="token number">255</span><span class="token punctuation">.</span>

<span class="token comment"># Reshape</span>
Y_train <span class="token operator">=</span> Y_train_orig<span class="token punctuation">.</span>T
Y_test <span class="token operator">=</span> Y_test_orig<span class="token punctuation">.</span>T

<span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&quot;number of training examples = &quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>X_train<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&quot;number of test examples = &quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>X_test<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&quot;X_train shape: &quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>X_train<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&quot;Y_train shape: &quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>Y_train<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&quot;X_test shape: &quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>X_test<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&quot;Y_test shape: &quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>Y_test<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
</pre><h4 class="mume-header" id="%E7%BB%93%E6%9E%9C">&#x7ED3;&#x679C;</h4>

<pre data-role="codeBlock" data-info class="language-"><code>number of training examples = 600
number of test examples = 150
X_train shape: (600, 64, 64, 3)
Y_train shape: (600, 1)
X_test shape: (150, 64, 64, 3)
Y_test shape: (150, 1)
</code></pre><p><strong>&#x201C;Happy&#x201D;&#x6570;&#x636E;&#x96C6;&#x7684;&#x8BE6;&#x7EC6;&#x4FE1;&#x606F;&#xFF1A;</strong>:</p>
<ul>
<li>Images are of shape (64,64,3)</li>
<li>Training: 600 pictures</li>
<li>Test: 150 pictures</li>
</ul>
<p>It is now time to solve the &quot;Happy&quot; Challenge.</p>
<h2 class="mume-header" id="%E7%94%A8keras%E5%BB%BA%E7%AB%8B%E6%A8%A1%E5%9E%8B">&#x7528;Keras&#x5EFA;&#x7ACB;&#x6A21;&#x578B;</h2>

<p>Keras &#x975E;&#x5E38;&#x9002;&#x5408;&#x5FEB;&#x901F;&#x5236;&#x4F5C;&#x539F;&#x578B;&#x3002;&#x5728;&#x5F88;&#x77ED;&#x7684;&#x65F6;&#x95F4;&#x5185;&#xFF0C;&#x4F60;&#x5C31;&#x80FD;&#x591F;&#x6784;&#x5EFA;&#x4E00;&#x4E2A;&#x6A21;&#x578B;&#xFF0C;&#x5E76;&#x83B7;&#x5F97;&#x51FA;&#x8272;&#x7684;&#x6210;&#x679C;&#x3002;</p>
<pre data-role="codeBlock" data-info="python" class="language-python"><span class="token keyword">def</span> <span class="token function">model</span><span class="token punctuation">(</span>input_shape<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># &#x5C06;&#x8F93;&#x5165;&#x5360;&#x4F4D;&#x7B26;&#x5B9A;&#x4E49;&#x4E3A;shape&#x4E3A;input_shape&#x7684;&#x5F20;&#x91CF;&#x3002;&#x628A;&#x5B83;&#x770B;&#x4F5C;&#x60A8;&#x7684;&#x8F93;&#x5165;&#x56FE;&#x50CF;!</span>
    X_input <span class="token operator">=</span> Input<span class="token punctuation">(</span>input_shape<span class="token punctuation">)</span>

    <span class="token comment"># Zero-Padding: &#x96F6;&#x586B;&#x5145;</span>
    X <span class="token operator">=</span> ZeroPadding2D<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X_input<span class="token punctuation">)</span>

    <span class="token comment"># CONV -&gt; &#x6B63;&#x5219;&#x5316;BN -&gt; RELU</span>
    X <span class="token operator">=</span> Conv2D<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> name <span class="token operator">=</span> <span class="token string">&apos;conv0&apos;</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    X <span class="token operator">=</span> BatchNormalization<span class="token punctuation">(</span>axis <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span> name <span class="token operator">=</span> <span class="token string">&apos;bn0&apos;</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    X <span class="token operator">=</span> Activation<span class="token punctuation">(</span><span class="token string">&apos;relu&apos;</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>

    <span class="token comment"># MAXPOOL</span>
    X <span class="token operator">=</span> MaxPooling2D<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">&apos;max_pool&apos;</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>

    <span class="token comment"># FLATTEN X &#x6241;&#x5E73;&#x5316; + FULLYCONNECTED &#x5168;&#x8FDE;&#x63A5;</span>
    X <span class="token operator">=</span> Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    X <span class="token operator">=</span> Dense<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">&apos;sigmoid&apos;</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">&apos;fc&apos;</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>

    <span class="token comment"># &#x521B;&#x5EFA;&#x6A21;&#x578B;&#x3002;&#x8FD9;&#x4F1A;&#x521B;&#x5EFA;&#x4F60;&#x7684;Keras&#x6A21;&#x578B;&#x5B9E;&#x4F8B;&#xFF0C;&#x4F60;&#x5C06;&#x4F7F;&#x7528;&#x8FD9;&#x4E2A;&#x5B9E;&#x4F8B;&#x6765;&#x8BAD;&#x7EC3;/&#x6D4B;&#x8BD5;&#x6A21;&#x578B;&#x3002;</span>
    model <span class="token operator">=</span> Model<span class="token punctuation">(</span>inputs <span class="token operator">=</span> X_input<span class="token punctuation">,</span> outputs <span class="token operator">=</span> X<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">&apos;HappyModel&apos;</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> model
</pre><p>&#x6CE8;&#x610F;&#xFF0C;Keras&#x5BF9;&#x53D8;&#x91CF;&#x540D;&#x4F7F;&#x7528;&#x7684;&#x7EA6;&#x5B9A;&#x4E0E;&#x6211;&#x4EEC;&#x4E4B;&#x524D;&#x5BF9;numpy&#x548C;TensorFlow&#x4F7F;&#x7528;&#x7684;&#x4E0D;&#x540C;&#x3002;&#x7279;&#x522B;&#x662F;&#xFF0C;&#x800C;&#x4E0D;&#x662F;&#x5728;&#x524D;&#x5411;&#x4F20;&#x64AD;&#x7684;&#x6BCF;&#x4E00;&#x6B65;&#x521B;&#x5EFA;&#x548C;&#x5206;&#x914D;&#x4E00;&#x4E2A;&#x65B0;&#x7684;&#x53D8;&#x91CF;&#xFF0C;&#x5982; <code>X</code>, <code>Z1</code>, <code>A1</code>, <code>Z2</code>, <code>A2</code>&#x7B49;&#x3002;&#x5BF9;&#x4E8E;&#x4E0D;&#x540C;&#x5C42;&#x7684;&#x8BA1;&#x7B97;&#xFF0C;&#x5728;Keras&#x4EE3;&#x7801;&#x4E2D;&#xFF0C;&#x4E0A;&#x9762;&#x7684;&#x6BCF;&#x4E00;&#x884C;&#x90FD;&#x4F7F;&#x7528;<code>X =&#x2026;</code>&#x5C06;<code>X</code>&#x91CD;&#x65B0;&#x8D4B;&#x503C;&#x7ED9;&#x4E00;&#x4E2A;&#x65B0;&#x503C;&#x3002;&#x6362;&#x53E5;&#x8BDD;&#x8BF4;&#xFF0C;&#x5728;&#x6B63;&#x5411;&#x4F20;&#x64AD;&#x7684;&#x6BCF;&#x4E00;&#x6B65;&#x4E2D;&#xFF0C;&#x6211;&#x4EEC;&#x53EA;&#x662F;&#x5C06;&#x5206;&#x914D;&#x4E2D;&#x7684;&#x6700;&#x65B0;&#x503C;&#x5199;&#x5165;&#x540C;&#x4E00;&#x4E2A;&#x53D8;&#x91CF;<code>X</code>&#x4E2D;&#x3002; &#x552F;&#x4E00;&#x7684;&#x4F8B;&#x5916;&#x662F;<code>X_input</code>&#xFF0C;&#x6211;&#x4EEC;&#x5C06;&#x5B83;&#x5206;&#x79BB;&#xFF0C;&#x6CA1;&#x6709;&#x8986;&#x76D6;&#x5B83;&#xFF0C;&#x56E0;&#x4E3A;&#x6211;&#x4EEC;&#x9700;&#x8981;&#x5B83;&#x5728;&#x6700;&#x540E;&#x521B;&#x5EFA;Keras&#x6A21;&#x578B;&#x5B9E;&#x4F8B;(<code>model = Model(inputs = X_input, ...)</code> ).</p>
<pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment"># GRADED FUNCTION: HappyModel</span>

<span class="token keyword">def</span> <span class="token function">HappyModel</span><span class="token punctuation">(</span>input_shape<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&quot;&quot;&quot;
    Implementation of the HappyModel.
    
    Arguments:
    input_shape -- shape of the images of the dataset

    Returns:
    model -- a Model() instance in Keras
    &quot;&quot;&quot;</span>
    
    <span class="token comment">### START CODE HERE ###</span>
    
    X_input <span class="token operator">=</span> Input<span class="token punctuation">(</span>input_shape<span class="token punctuation">)</span>

    X <span class="token operator">=</span> ZeroPadding2D<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X_input<span class="token punctuation">)</span>

    X <span class="token operator">=</span> Conv2D<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> name <span class="token operator">=</span> <span class="token string">&apos;conv0&apos;</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    X <span class="token operator">=</span> BatchNormalization<span class="token punctuation">(</span>axis <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span> name <span class="token operator">=</span> <span class="token string">&apos;bn0&apos;</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    X <span class="token operator">=</span> Activation<span class="token punctuation">(</span><span class="token string">&apos;relu&apos;</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>

    <span class="token comment"># MAXPOOL</span>
    X <span class="token operator">=</span> MaxPooling2D<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">&apos;max_pool&apos;</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>

    <span class="token comment"># FLATTEN + FULLYCONNECTED</span>
    X <span class="token operator">=</span> Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    X <span class="token operator">=</span> Dense<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">&apos;sigmoid&apos;</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">&apos;fc&apos;</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>

    model <span class="token operator">=</span> Model<span class="token punctuation">(</span>inputs <span class="token operator">=</span> X_input<span class="token punctuation">,</span> outputs <span class="token operator">=</span> X<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">&apos;HappyModel&apos;</span><span class="token punctuation">)</span>
    
    
    <span class="token comment">### END CODE HERE ###</span>
    
    <span class="token keyword">return</span> model
</pre><p>&#x73B0;&#x5728;&#x60A8;&#x5DF2;&#x7ECF;&#x6784;&#x5EFA;&#x4E86;&#x4E00;&#x4E2A;&#x51FD;&#x6570;&#x6765;&#x63CF;&#x8FF0;&#x60A8;&#x7684;&#x6A21;&#x578B;&#x3002;&#x4E3A;&#x4E86;&#x8BAD;&#x7EC3;&#x548C;&#x6D4B;&#x8BD5;&#x8BE5;&#x6A21;&#x578B;&#xFF0C;Keras&#x5206;&#x4E3A;&#x56DB;&#x4E2A;&#x6B65;&#x9AA4;:</p>
<ol>
<li>&#x901A;&#x8FC7;&#x8C03;&#x7528;&#x4E0A;&#x9762;&#x7684;&#x51FD;&#x6570;&#x6765;&#x521B;&#x5EFA;&#x6A21;&#x578B;</li>
<li>&#x901A;&#x8FC7;&#x8C03;&#x7528; <code>model.compile(optimizer = &quot;...&quot;, loss = &quot;...&quot;, metrics = [&quot;accuracy&quot;])</code>&#x6765;&#x7F16;&#x8BD1;&#x6A21;&#x578B;</li>
<li>&#x901A;&#x8FC7;&#x8C03;&#x7528; <code>model.fit(x = ..., y = ..., epochs = ..., batch_size = ...)</code>&#x6765;&#x8BAD;&#x7EC3;&#x6A21;&#x578B;</li>
<li>&#x901A;&#x8FC7;&#x8C03;&#x7528; <code>model.evaluate(x = ..., y = ...)</code>&#x6765;&#x6D4B;&#x8BD5;&#x6A21;&#x578B;</li>
</ol>
<h3 class="mume-header" id="%E5%88%9B%E5%BB%BA%E6%A8%A1%E5%9E%8B">&#x521B;&#x5EFA;&#x6A21;&#x578B;</h3>

<pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment">### START CODE HERE ### (1 line)</span>
happyModel <span class="token operator">=</span> HappyModel<span class="token punctuation">(</span>X_train<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment">### END CODE HERE ###</span>
</pre><h3 class="mume-header" id="%E7%BC%96%E8%AF%91%E6%A8%A1%E5%9E%8B">&#x7F16;&#x8BD1;&#x6A21;&#x578B;</h3>

<pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment">### START CODE HERE ### (1 line)</span>
happyModel<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>optimizer <span class="token operator">=</span> <span class="token string">&quot;Adam&quot;</span><span class="token punctuation">,</span> loss <span class="token operator">=</span> <span class="token string">&quot;binary_crossentropy&quot;</span><span class="token punctuation">,</span> metrics <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&quot;accuracy&quot;</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment">### END CODE HERE ###</span>
</pre><h3 class="mume-header" id="%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B">&#x8BAD;&#x7EC3;&#x6A21;&#x578B;</h3>

<pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment">### START CODE HERE ### (1 line)</span>
happyModel<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x<span class="token operator">=</span>X_train<span class="token punctuation">,</span> y <span class="token operator">=</span> Y_train<span class="token punctuation">,</span> epochs <span class="token operator">=</span> <span class="token number">39</span><span class="token punctuation">,</span> batch_size <span class="token operator">=</span> <span class="token number">16</span><span class="token punctuation">)</span>
<span class="token comment">### END CODE HERE ###</span>
</pre><h4 class="mume-header" id="%E7%BB%93%E6%9E%9C-1">&#x7ED3;&#x679C;</h4>

<pre data-role="codeBlock" data-info class="language-"><code>Epoch 1/39
600/600 [==============================] - 26s - loss: 1.5768 - acc: 0.7183    
Epoch 2/39
600/600 [==============================] - 26s - loss: 0.3022 - acc: 0.8850    
Epoch 3/39
600/600 [==============================] - 25s - loss: 0.1880 - acc: 0.9183    
Epoch 4/39
600/600 [==============================] - 25s - loss: 0.1269 - acc: 0.9567    
Epoch 5/39
600/600 [==============================] - 25s - loss: 0.1374 - acc: 0.9433    
Epoch 6/39
600/600 [==============================] - 26s - loss: 0.1624 - acc: 0.9550    
Epoch 7/39
600/600 [==============================] - 27s - loss: 0.0701 - acc: 0.9767    
Epoch 8/39
600/600 [==============================] - 26s - loss: 0.1520 - acc: 0.9417    
Epoch 9/39
600/600 [==============================] - 25s - loss: 0.1620 - acc: 0.9483    
Epoch 10/39
600/600 [==============================] - 25s - loss: 0.1383 - acc: 0.9467    
Epoch 11/39
600/600 [==============================] - 25s - loss: 0.1588 - acc: 0.9517    
Epoch 12/39
600/600 [==============================] - 25s - loss: 0.1038 - acc: 0.9683    
Epoch 13/39
600/600 [==============================] - 25s - loss: 0.0895 - acc: 0.9683    
Epoch 14/39
600/600 [==============================] - 25s - loss: 0.0828 - acc: 0.9717    
Epoch 15/39
600/600 [==============================] - 25s - loss: 0.0456 - acc: 0.9917    
Epoch 16/39
600/600 [==============================] - 26s - loss: 0.0616 - acc: 0.9800    
Epoch 17/39
600/600 [==============================] - 25s - loss: 0.0463 - acc: 0.9817    
Epoch 18/39
600/600 [==============================] - 28s - loss: 0.0772 - acc: 0.9683    
Epoch 19/39
600/600 [==============================] - 28s - loss: 0.0486 - acc: 0.9850    
Epoch 20/39
600/600 [==============================] - 26s - loss: 0.0235 - acc: 0.9900    
Epoch 21/39
600/600 [==============================] - 25s - loss: 0.0403 - acc: 0.9933    
Epoch 22/39
600/600 [==============================] - 25s - loss: 0.0554 - acc: 0.9850    
Epoch 23/39
600/600 [==============================] - 25s - loss: 0.0221 - acc: 0.9967    
Epoch 24/39
600/600 [==============================] - 25s - loss: 0.0430 - acc: 0.9800    
Epoch 25/39
600/600 [==============================] - 25s - loss: 0.0286 - acc: 0.9967    
Epoch 26/39
600/600 [==============================] - 25s - loss: 0.0245 - acc: 0.9917    
Epoch 27/39
600/600 [==============================] - 25s - loss: 0.0168 - acc: 0.9933    
Epoch 28/39
600/600 [==============================] - 25s - loss: 0.0414 - acc: 0.9867    
Epoch 29/39
600/600 [==============================] - 25s - loss: 0.0281 - acc: 0.9900    
Epoch 30/39
600/600 [==============================] - 26s - loss: 0.0445 - acc: 0.9883    
Epoch 31/39
600/600 [==============================] - 25s - loss: 0.0693 - acc: 0.9733    
Epoch 32/39
600/600 [==============================] - 25s - loss: 0.1834 - acc: 0.9383    
Epoch 33/39
600/600 [==============================] - 25s - loss: 0.3500 - acc: 0.9150    
Epoch 34/39
600/600 [==============================] - 25s - loss: 0.0899 - acc: 0.9683    
Epoch 35/39
600/600 [==============================] - 26s - loss: 0.1298 - acc: 0.9717    
Epoch 36/39
600/600 [==============================] - 26s - loss: 0.1342 - acc: 0.9667    
Epoch 37/39
600/600 [==============================] - 25s - loss: 0.0550 - acc: 0.9767    
Epoch 38/39
600/600 [==============================] - 25s - loss: 0.0812 - acc: 0.9767    
Epoch 39/39
600/600 [==============================] - 25s - loss: 0.0726 - acc: 0.9867    
</code></pre><h3 class="mume-header" id="%E8%AF%84%E4%BC%B0%E6%A8%A1%E5%9E%8B">&#x8BC4;&#x4F30;&#x6A21;&#x578B;</h3>

<pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment">### START CODE HERE ### (1 line)</span>
preds <span class="token operator">=</span> happyModel<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>x <span class="token operator">=</span> X_test<span class="token punctuation">,</span> y <span class="token operator">=</span> Y_test<span class="token punctuation">)</span>
<span class="token comment">### END CODE HERE ###</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&quot;Loss = &quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>preds<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&quot;Test Accuracy = &quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>preds<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</pre><h4 class="mume-header" id="%E7%BB%93%E6%9E%9C-2">&#x7ED3;&#x679C;</h4>

<pre data-role="codeBlock" data-info class="language-"><code>150/150 [==============================] - 3s     

Loss = 0.596558374564
Test Accuracy = 0.846666665872
</code></pre><p>&#x7ED9;&#x4F60;&#x4E00;&#x4E2A;&#x7528;&#x4E8E;&#x6BD4;&#x8F83;&#x8282;&#x70B9;&#xFF0C;&#x6211;&#x4EEC;&#x7684;&#x6A21;&#x578B;<strong>&#x5728;40&#x4E2A;epoch&#x65F6;&#x80FD;&#x591F;&#x8FBE;&#x5230;95%&#x7684;&#x6D4B;&#x8BD5;&#x51C6;&#x786E;&#x5EA6;</strong>(&#x548C;99%&#x7684;&#x8BAD;&#x7EC3;&#x51C6;&#x786E;&#x5EA6;)&#x3010;minibatch&#x5927;&#x5C0F;&#x4E3A;16&#xFF0C;&#x91C7;&#x7528;&#x201C;adam&#x201D;&#x4F18;&#x5316;&#x5668;&#x3011;&#x3002;&#x4F46;&#x662F;&#x6211;&#x4EEC;&#x7684;&#x6A21;&#x578B;&#x5728;2-5&#x4E2A;epoch&#x4E4B;&#x540E;&#x5C31;&#x5F97;&#x5230;&#x4E86;&#x4E0D;&#x9519;&#x7684;&#x7CBE;&#x5EA6;&#xFF0C;&#x6240;&#x4EE5;&#x5982;&#x679C;&#x4F60;&#x6BD4;&#x8F83;&#x4E0D;&#x540C;&#x7684;&#x6A21;&#x578B;&#xFF0C;&#x4F60;&#x4E5F;&#x53EF;&#x4EE5;&#x5728;&#x51E0;&#x4E2A;epoch&#x4E0A;&#x8BAD;&#x7EC3;&#x4E0D;&#x540C;&#x7684;&#x6A21;&#x578B;&#xFF0C;&#x770B;&#x770B;&#x5B83;&#x4EEC;&#x6548;&#x679C;&#x5982;&#x4F55;&#x3002;</p>
<p>&#x5982;&#x679C;&#x4F60;&#x8FD8;&#x6CA1;&#x6709;&#x8FBE;&#x5230;&#x4E00;&#x4E2A;&#x975E;&#x5E38;&#x597D;&#x7684;&#x51C6;&#x786E;&#x5EA6;(&#x5047;&#x8BBE;&#x8D85;&#x8FC7;80%)&#xFF0C;&#x8FD9;&#x91CC;&#x6709;&#x4E00;&#x4E9B;&#x4E1C;&#x897F;&#x4F60;&#x53EF;&#x4EE5;&#x5C1D;&#x8BD5;&#x5B9E;&#x73B0;&#x5B83;:</p>
<ul>
<li>
<p>&#x5C1D;&#x8BD5;&#x4F7F;&#x7528; CONV-&gt;BATCHNORM-&gt;RELU</p>
<pre data-role="codeBlock" data-info="python" class="language-python">X <span class="token operator">=</span> Conv2D<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> name <span class="token operator">=</span> <span class="token string">&apos;conv0&apos;</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
X <span class="token operator">=</span> BatchNormalization<span class="token punctuation">(</span>axis <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span> name <span class="token operator">=</span> <span class="token string">&apos;bn0&apos;</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
X <span class="token operator">=</span> Activation<span class="token punctuation">(</span><span class="token string">&apos;relu&apos;</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
</pre><p>&#x76F4;&#x5230;&#x4F60;&#x7684;&#x9AD8;&#x5EA6;&#x548C;&#x5BBD;&#x5EA6;&#x5C3A;&#x5BF8;&#x975E;&#x5E38;&#x4F4E;&#xFF0C;&#x800C;&#x901A;&#x9053;&#x7684;&#x6570;&#x91CF;&#x975E;&#x5E38;&#x5927;(&#x4F8B;&#x5982;&#x2248;32)&#x3002;&#x7136;&#x540E;&#x4F60;&#x53EF;&#x4EE5;&#x6241;&#x5E73;&#x5316;&#x8FD9;&#x4E2A;volume&#xFF0C;&#x4F7F;&#x7528;&#x4E00;&#x4E2A;&#x5B8C;&#x5168;&#x8FDE;&#x63A5;&#x7684;&#x5C42;&#x3002;</p>
</li>
<li>
<p>&#x4F60;&#x53EF;&#x4EE5;&#x4F7F;&#x7528; MAXPOOL &#x3002;&#x53EF;&#x4EE5;&#x5E2E;&#x52A9;&#x4F60;&#x964D;&#x4F4E;&#x9AD8;&#x548C;&#x5BBD;&#x7684;&#x7EF4;&#x5EA6;&#x3002;</p>
</li>
<li>
<p>&#x6539;&#x53D8;&#x4F18;&#x5316;&#x5668;</p>
</li>
<li>
<p>&#x5982;&#x679C;&#x6A21;&#x578B;&#x8FD0;&#x884C;&#x56F0;&#x96BE;&#xFF0C;&#x800C;&#x60A8;&#x9047;&#x5230;&#x5185;&#x5B58;&#x95EE;&#x9898;&#xFF0C;&#x90A3;&#x4E48;&#x964D;&#x4F4E;batch_size(12&#x901A;&#x5E38;&#x662F;&#x4E00;&#x4E2A;&#x4E0D;&#x9519;&#x7684;&#x65B9;&#x6848;)</p>
</li>
<li>
<p>&#x8FD0;&#x884C;&#x66F4;&#x591A;epoch&#xFF0C;&#x76F4;&#x5230;&#x8BAD;&#x7EC3;&#x51C6;&#x786E;&#x5EA6;&#x505C;&#x6EDE;&#x3002;</p>
</li>
</ul>
<p>&#x5373;&#x4F7F;&#x60A8;&#x5DF2;&#x7ECF;&#x53D6;&#x5F97;&#x4E86;&#x4E00;&#x4E2A;&#x5F88;&#x597D;&#x7684;&#x7CBE;&#x5EA6;&#xFF0C;&#x8BF7;&#x653E;&#x5FC3;&#x7EE7;&#x7EED;&#x73A9;&#x60A8;&#x7684;&#x6A21;&#x578B;&#xFF0C;&#x4EE5;&#x83B7;&#x5F97;&#x66F4;&#x597D;&#x7684;&#x7ED3;&#x679C;&#x3002;</p>
<p><strong>&#x6CE8;&#x610F;</strong>:&#x5982;&#x679C;&#x60A8;&#x5BF9;&#x6A21;&#x578B;&#x6267;&#x884C;&#x8D85;&#x53C2;&#x6570;&#x8C03;&#x4F18;&#xFF0C;&#x90A3;&#x4E48;&#x6D4B;&#x8BD5;&#x96C6;&#x5B9E;&#x9645;&#x4E0A;&#x4F1A;&#x53D8;&#x6210;&#x5F00;&#x53D1;&#x96C6;&#xFF0C;&#x5E76;&#x4E14;&#x60A8;&#x7684;&#x6A21;&#x578B;&#x6700;&#x7EC8;&#x53EF;&#x80FD;&#x4F1A;&#x8FC7;&#x5EA6;&#x62DF;&#x5408;&#x6D4B;&#x8BD5;(dev)&#x96C6;&#x3002;</p>
<h2 class="mume-header" id="%E6%80%BB%E7%BB%93">&#x603B;&#x7ED3;</h2>

<ul>
<li>Keras&#x662F;&#x6211;&#x4EEC;&#x63A8;&#x8350;&#x7528;&#x4E8E;&#x5FEB;&#x901F;&#x539F;&#x578B;&#x7684;&#x4E00;&#x4E2A;&#x5DE5;&#x5177;&#x3002;&#x5B83;&#x5141;&#x8BB8;&#x60A8;&#x5FEB;&#x901F;&#x5C1D;&#x8BD5;&#x4E0D;&#x540C;&#x7684;&#x6A21;&#x578B;&#x67B6;&#x6784;&#x3002;&#x4F60;&#x662F;&#x5426;&#x60F3;&#x7528;Keras&#x6765;&#x5B9E;&#x73B0;&#x65E5;&#x5E38;&#x751F;&#x6D3B;&#x4E2D;&#x7684;&#x6DF1;&#x5EA6;&#x5B66;&#x4E60;&#x5E94;&#x7528;?</li>
<li>&#x8BB0;&#x5F97;&#x5982;&#x4F55;&#x5728;Keras&#x4E2D;&#x7F16;&#x5199;&#x4E00;&#x4E2A;&#x6A21;&#x578B;&#xFF0C;&#x4EE5;&#x53CA;&#x5728;&#x6D4B;&#x8BD5;&#x96C6;&#x4E2D;&#x8BC4;&#x4F30;&#x4F60;&#x7684;&#x6A21;&#x578B;&#x7684;&#x56DB;&#x4E2A;&#x6B65;&#x9AA4;&#x3002;</li>
</ul>
<h2 class="mume-header" id="%E6%B5%8B%E8%AF%95%E8%87%AA%E5%B7%B1%E7%9A%84%E5%9B%BE%E7%89%87-%E9%80%89%E5%81%9A">&#x6D4B;&#x8BD5;&#x81EA;&#x5DF1;&#x7684;&#x56FE;&#x7247; (&#x9009;&#x505A;)</h2>

<pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment">### START CODE HERE ###</span>
img_path <span class="token operator">=</span> <span class="token string">&apos;images/my_image.jpg&apos;</span>
<span class="token comment">### END CODE HERE ###</span>
img <span class="token operator">=</span> image<span class="token punctuation">.</span>load_img<span class="token punctuation">(</span>img_path<span class="token punctuation">,</span> target_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
imshow<span class="token punctuation">(</span>img<span class="token punctuation">)</span>

x <span class="token operator">=</span> image<span class="token punctuation">.</span>img_to_array<span class="token punctuation">(</span>img<span class="token punctuation">)</span>
x <span class="token operator">=</span> np<span class="token punctuation">.</span>expand_dims<span class="token punctuation">(</span>x<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
x <span class="token operator">=</span> preprocess_input<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>happyModel<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
</pre><p>&#x7ED3;&#x679C;</p>
<pre data-role="codeBlock" data-info class="language-"><code>[[  8.44492405e-08]]
</code></pre><p><img src="img/2.png" alt="img"></p>
<h2 class="mume-header" id="keras%E4%B8%AD%E5%85%B6%E4%BB%96%E6%9C%89%E7%94%A8%E7%9A%84%E5%87%BD%E6%95%B0-%E9%80%89%E5%81%9A">Keras&#x4E2D;&#x5176;&#x4ED6;&#x6709;&#x7528;&#x7684;&#x51FD;&#x6570; (&#x9009;&#x505A;)</h2>

<ul>
<li>
<p><code>model.summary()</code>:</p>
<p>&#x6253;&#x5370;&#x4F60;&#x7684;&#x5C42;&#x7684;&#x8BE6;&#x7EC6;&#x4FE1;&#x606F;&#x5728;&#x4E00;&#x4E2A;&#x8868;&#x3010;&#x8F93;&#x5165;/&#x8F93;&#x51FA;&#x7684;&#x5927;&#x5C0F;&#x3011;</p>
</li>
<li>
<p><code>plot_model()</code>:</p>
<p>&#x4EE5;&#x826F;&#x597D;&#x7684;&#x5E03;&#x5C40;&#x7ED8;&#x5236;&#x60A8;&#x7684;&#x56FE;&#x8868;&#x3002;&#x4F60;&#x751A;&#x81F3;&#x53EF;&#x4EE5;&#x4F7F;&#x7528;SVG() &#x628A;&#x5B83;&#x5B58;&#x4E3A; &quot;.png&quot; &#x683C;&#x5F0F;&#x3002;</p>
</li>
</ul>
<h4 class="mume-header" id="%E6%B5%8B%E8%AF%95">&#x6D4B;&#x8BD5;</h4>

<pre data-role="codeBlock" data-info="python" class="language-python">happyModel<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span>
</pre><h4 class="mume-header" id="%E7%BB%93%E6%9E%9C-3">&#x7ED3;&#x679C;</h4>

<pre data-role="codeBlock" data-info class="language-"><code>_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 64, 64, 3)         0         
_________________________________________________________________
zero_padding2d_1 (ZeroPaddin (None, 70, 70, 3)         0         
_________________________________________________________________
conv0 (Conv2D)               (None, 64, 64, 32)        4736      
_________________________________________________________________
bn0 (BatchNormalization)     (None, 64, 64, 32)        128       
_________________________________________________________________
activation_1 (Activation)    (None, 64, 64, 32)        0         
_________________________________________________________________
max_pool (MaxPooling2D)      (None, 32, 32, 32)        0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 32768)             0         
_________________________________________________________________
fc (Dense)                   (None, 1)                 32769     
=================================================================
Total params: 37,633
Trainable params: 37,569
Non-trainable params: 64
_________________________________________________________________
</code></pre><h1 class="mume-header" id="%E6%AE%8B%E5%B7%AE%E7%BD%91%E7%BB%9C-1">&#x6B8B;&#x5DEE;&#x7F51;&#x7EDC;</h1>

<p>&#x672C;&#x7AE0;&#x5C06;&#x5B66;&#x4E60;&#x5982;&#x4F55;&#x4F7F;&#x7528;&#x6B8B;&#x5DEE;&#x7F51;&#x7EDC;(ResNets)&#x6784;&#x5EFA;&#x975E;&#x5E38;&#x6DF1;&#x7684;&#x5377;&#x79EF;&#x7F51;&#x7EDC;&#x3002;&#x7406;&#x8BBA;&#x4E0A;&#xFF0C;&#x6DF1;&#x5EA6;&#x5F88;&#x6DF1;&#x7684;&#x7F51;&#x7EDC;&#x53EF;&#x4EE5;&#x4EE3;&#x8868;&#x975E;&#x5E38;&#x590D;&#x6742;&#x7684;&#x529F;&#x80FD;;&#x4F46;&#x5B9E;&#x9645;&#x4E0A;&#xFF0C;&#x4ED6;&#x4EEC;&#x5F88;&#x96BE;&#x8BAD;&#x7EC3;&#x3002;&#x6B8B;&#x5DEE;&#x7F51;&#x7EDC;&#x7531;<a href="https://arxiv.org/pdf/1512.03385.pdf">He&#x7B49;&#x4EBA;</a>&#x63A8;&#x8350;&#xFF0C;&#x5B83;&#x5141;&#x8BB8;&#x4F60;&#x8BAD;&#x7EC3;&#x6BD4;&#x4EE5;&#x524D;&#x5B9E;&#x9645;&#x53EF;&#x884C;&#x7684;&#x66F4;&#x6DF1;&#x5C42;&#x6B21;&#x7684;&#x7F51;&#x7EDC;&#x3002;</p>
<h2 class="mume-header" id="%E7%9B%AE%E6%A0%87">&#x76EE;&#x6807;</h2>

<ul>
<li>&#x5B9E;&#x73B0;&#x6B8B;&#x5DEE;&#x7F51;&#x7EDC;&#x7684;&#x57FA;&#x672C;&#x6784;&#x5EFA;&#x5757;&#x3002;</li>
<li>&#x628A;&#x8FD9;&#x4E9B;&#x6784;&#x5EFA;&#x5757;&#x653E;&#x5728;&#x4E00;&#x8D77;&#x6765;&#x5B9E;&#x73B0;&#x548C;&#x8BAD;&#x7EC3;&#x4E00;&#x4E2A;&#x6700;&#x5148;&#x8FDB;&#x7684;&#x56FE;&#x50CF;&#x5206;&#x7C7B;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x3002;</li>
</ul>
<h2 class="mume-header" id="%E5%AF%BC%E5%8C%85-1">&#x5BFC;&#x5305;</h2>

<pre data-role="codeBlock" data-info="python" class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> keras <span class="token keyword">import</span> layers
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> Input<span class="token punctuation">,</span> Add<span class="token punctuation">,</span> Dense<span class="token punctuation">,</span> Activation<span class="token punctuation">,</span> ZeroPadding2D<span class="token punctuation">,</span> BatchNormalization<span class="token punctuation">,</span> Flatten<span class="token punctuation">,</span> Conv2D<span class="token punctuation">,</span> AveragePooling2D<span class="token punctuation">,</span> MaxPooling2D<span class="token punctuation">,</span> GlobalMaxPooling2D
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>models <span class="token keyword">import</span> Model<span class="token punctuation">,</span> load_model
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> image
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>utils <span class="token keyword">import</span> layer_utils
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data_utils <span class="token keyword">import</span> get_file
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>applications<span class="token punctuation">.</span>imagenet_utils <span class="token keyword">import</span> preprocess_input
<span class="token keyword">import</span> pydot
<span class="token keyword">from</span> IPython<span class="token punctuation">.</span>display <span class="token keyword">import</span> SVG
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>vis_utils <span class="token keyword">import</span> model_to_dot
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>utils <span class="token keyword">import</span> plot_model
<span class="token keyword">from</span> resnets_utils <span class="token keyword">import</span> <span class="token operator">*</span>
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>initializers <span class="token keyword">import</span> glorot_uniform
<span class="token keyword">import</span> scipy<span class="token punctuation">.</span>misc
<span class="token keyword">from</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">import</span> imshow
<span class="token operator">%</span>matplotlib inline

<span class="token keyword">import</span> keras<span class="token punctuation">.</span>backend <span class="token keyword">as</span> K
K<span class="token punctuation">.</span>set_image_data_format<span class="token punctuation">(</span><span class="token string">&apos;channels_last&apos;</span><span class="token punctuation">)</span>
K<span class="token punctuation">.</span>set_learning_phase<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
Using TensorFlow backend<span class="token punctuation">.</span>
</pre><h2 class="mume-header" id="%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E9%97%AE%E9%A2%98">&#x6DF1;&#x5EA6;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x7684;&#x95EE;&#x9898;</h2>

<p>&#x8FD1;&#x5E74;&#x6765;&#xFF0C;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x53D8;&#x5F97;&#x66F4;&#x52A0;&#x6DF1;&#x5165;&#xFF0C;&#x6700;&#x5148;&#x8FDB;&#x7684;&#x7F51;&#x7EDC;&#x4ECE;&#x53EA;&#x6709;&#x51E0;&#x5C42;(&#x5982;AlexNet)&#x53D1;&#x5C55;&#x5230;&#x8D85;&#x8FC7;100&#x5C42;&#x3002;</p>
<p>&#x6DF1;&#x5EA6;&#x7F51;&#x7EDC;&#x7684;&#x4E3B;&#x8981;&#x597D;&#x5904;&#x662F;&#x5B83;&#x53EF;&#x4EE5;&#x4EE3;&#x8868;&#x975E;&#x5E38;&#x590D;&#x6742;&#x7684;&#x529F;&#x80FD;&#x3002;&#x5B83;&#x8FD8;&#x53EF;&#x4EE5;&#x5B66;&#x4E60;&#x8BB8;&#x591A;&#x4E0D;&#x540C;&#x62BD;&#x8C61;&#x7EA7;&#x522B;&#x7684;&#x7279;&#x6027;&#xFF0C;&#x4ECE;&#x8FB9;&#x7F18;(&#x8F83;&#x4F4E;&#x7684;&#x5C42;)&#x5230;&#x975E;&#x5E38;&#x590D;&#x6742;&#x7684;&#x7279;&#x6027;(&#x8F83;&#x6DF1;&#x7684;&#x5C42;)&#x3002;</p>
<p>&#x7136;&#x800C;&#xFF0C;&#x4F7F;&#x7528;&#x66F4;&#x6DF1;&#x5C42;&#x6B21;&#x7684;&#x7F51;&#x7EDC;&#x5E76;&#x4E0D;&#x603B;&#x662F;&#x6709;&#x5E2E;&#x52A9;&#x3002;&#x8BAD;&#x7EC3;&#x5B83;&#x4EEC;&#x7684;&#x4E00;&#x4E2A;&#x5DE8;&#x5927;&#x969C;&#x788D;&#x662F;&#x68AF;&#x5EA6;&#x6D88;&#x5931;:&#x6DF1;&#x5EA6;&#x5F88;&#x6DF1;&#x7684;&#x7F51;&#x7EDC;&#x901A;&#x5E38;&#x4F1A;&#x6709;&#x4E00;&#x4E2A;&#x68AF;&#x5EA6;&#x4FE1;&#x53F7;&#x8FC5;&#x901F;&#x53D8;&#x4E3A;&#x96F6;&#xFF0C;&#x4ECE;&#x800C;&#x4F7F;<strong>&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x6162;&#x5F97;&#x96BE;&#x4EE5;&#x63A5;&#x53D7;</strong>&#x3002;&#x66F4;&#x5177;&#x4F53;&#x5730;&#x8BF4;,&#x5728;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x6CD5;,&#x4ECE;&#x6700;&#x540E;&#x4E00;&#x5C42;&#x53CD;&#x5411;&#x4F20;&#x64AD;&#x56DE;&#x5230;&#x7B2C;&#x4E00;&#x5C42;,&#x6BCF;&#x4E00;&#x6B65;&#x4F60;&#x4E58;&#x4EE5;&#x6743;&#x91CD;&#x77E9;&#x9635;,&#x4ECE;&#x800C;&#x80FD;&#x591F;&#x8FC5;&#x901F;&#x51CF;&#x5C11;&#x6307;&#x6570;&#x68AF;&#x5EA6;&#x4E3A;&#x96F6;(&#x6216;&#x8005;,&#x5728;&#x7F55;&#x89C1;&#x7684;&#x60C5;&#x51B5;&#x4E0B;,&#x6210;&#x500D;&#x589E;&#x957F;&#x8FC5;&#x901F;,&#x201C;&#x7206;&#x70B8;&#x201D;&#x975E;&#x5E38;&#x5927;&#x7684;&#x503C;)&#x3002;</p>
<p>&#x73B0;&#x5728;&#x5C06;&#x901A;&#x8FC7;&#x6784;&#x5EFA;&#x4E00;&#x4E2A;&#x6B8B;&#x5DEE;&#x7F51;&#x7EDC;&#x6765;&#x89E3;&#x51B3;&#x8FD9;&#x4E2A;&#x95EE;&#x9898;!</p>
<h2 class="mume-header" id="%E6%9E%84%E5%BB%BA%E6%AE%8B%E5%B7%AE%E7%BD%91%E7%BB%9C">&#x6784;&#x5EFA;&#x6B8B;&#x5DEE;&#x7F51;&#x7EDC;</h2>

<p>&#x5728;&#x6B8B;&#x5DEE;&#x7F51;&#x7EDC;&#x4E2D;&#xFF0C; &quot;shortcut&quot; &#x6216;&#x8005; &quot;skip connection&quot; &#x5141;&#x8BB8;&#x68AF;&#x5EA6;&#x76F4;&#x63A5;&#x53CD;&#x9988;&#x5230;&#x66F4;&#x524D;&#x7684;&#x5C42;&#x4E2D;&#x3002;</p>
<p>&#x6B8B;&#x5DEE;&#x7F51;&#x7EDC;&#x5728;&#x8BFE;&#x5802;&#x4E0A;&#x6211;&#x4EEC;&#x4E5F;&#x770B;&#x5230;,ResNet&#x5757;&#x4E5F;&#x5F88;&#x5BB9;&#x6613;&#x5B66;&#x4E60;&#x4E00;&#x4E2A;&#x6052;&#x7B49;&#xFF08;identity&#xFF09;&#x51FD;&#x6570;&#x5757;&#x3002;&#x8FD9;&#x610F;&#x5473;&#x7740;&#x60A8;&#x53EF;&#x4EE5;&#x5806;&#x53E0;&#x989D;&#x5916;&#x7684;ResNet&#x5757;&#xFF0C;&#x51E0;&#x4E4E;&#x6CA1;&#x6709;&#x635F;&#x5BB3;&#x8BAD;&#x7EC3;&#x96C6;&#x6027;&#x80FD;&#x7684;&#x98CE;&#x9669;&#x3002;(&#x4E5F;&#x6709;&#x4E00;&#x4E9B;&#x8BC1;&#x636E;&#x8868;&#x660E;&#xFF0C;ResNets&#x7684;&#x5353;&#x8D8A;&#x6027;&#x80FD;&#x662F;&#x7531;&#x4E8E;&#x6613;&#x4E8E;&#x5B66;&#x4E60;&#x6807;&#x8BC6;&#x51FD;&#x6570;&#xFF0C;&#x751A;&#x81F3;&#x6BD4;&#x8DF3;&#x8FC7;&#x8FDE;&#x63A5;&#x66F4;&#x6709;&#x52A9;&#x4E8E;&#x6D88;&#x9664;&#x68AF;&#x5EA6;&#x6D88;&#x5931;&#x3002;)</p>
<p>ResNet&#x4E2D;&#x4E3B;&#x8981;&#x4F7F;&#x7528;&#x4E24;&#x79CD;&#x7C7B;&#x578B;&#x7684;&#x5757;&#xFF0C;&#x4E3B;&#x8981;&#x53D6;&#x51B3;&#x4E8E;&#x8F93;&#x5165;/&#x8F93;&#x51FA;&#x7EF4;&#x5EA6;&#x662F;&#x76F8;&#x540C;&#x7684;&#x8FD8;&#x662F;&#x4E0D;&#x540C;&#x7684;&#x3002;&#x60A8;&#x5C06;&#x540C;&#x65F6;&#x5B9E;&#x73B0;&#x5B83;&#x4EEC;&#x3002;</p>
<p><img src="img/20180117221359702.png" alt></p>
<p><img src="img/20180117212234657.png" alt></p>
<h3 class="mume-header" id="identity%E5%9D%97">Identity&#x5757;</h3>

<p>identity&#x5757;&#x662F;ResNets&#x4E2D;&#x4F7F;&#x7528;&#x7684;&#x6807;&#x51C6;&#x5757;&#xFF0C;&#x5B83;&#x5BF9;&#x5E94;&#x4E8E;&#x8F93;&#x5165;&#x6FC0;&#x6D3B;(&#x6BD4;&#x5982;<span class="mathjax-exps">$a^{[l]}$</span>)&#x4E0E;&#x8F93;&#x51FA;&#x6FC0;&#x6D3B;(&#x6BD4;&#x5982;<span class="mathjax-exps">$a^{[l+2]}$</span>)&#x5177;&#x6709;<strong>&#x76F8;&#x540C;&#x7EF4;&#x5EA6;</strong>&#x7684;&#x60C5;&#x51B5;&#x3002;</p>
<pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment"># GRADED FUNCTION: identity_block</span>

<span class="token keyword">def</span> <span class="token function">identity_block</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> f<span class="token punctuation">,</span> filters<span class="token punctuation">,</span> stage<span class="token punctuation">,</span> block<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&quot;&quot;&quot;
    Implementation of the identity block as defined in Figure 3
    
    Arguments:
    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)
    f -- integer, specifying the shape of the middle CONV&apos;s window for the main path
    filters -- python list of integers, defining the number of filters in the CONV layers of the main path
    stage -- integer, used to name the layers, depending on their position in the network
    block -- string/character, used to name the layers, depending on their position in the network
    
    Returns:
    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)
    &quot;&quot;&quot;</span>
    
    <span class="token comment"># &#x5B9A;&#x4E49;&#x540D;&#x79F0;</span>
    conv_name_base <span class="token operator">=</span> <span class="token string">&apos;res&apos;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>stage<span class="token punctuation">)</span> <span class="token operator">+</span> block <span class="token operator">+</span> <span class="token string">&apos;_branch&apos;</span>
    bn_name_base <span class="token operator">=</span> <span class="token string">&apos;bn&apos;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>stage<span class="token punctuation">)</span> <span class="token operator">+</span> block <span class="token operator">+</span> <span class="token string">&apos;_branch&apos;</span>
    
    <span class="token comment"># &#x53D6;&#x5F97;filters</span>
    F1<span class="token punctuation">,</span> F2<span class="token punctuation">,</span> F3 <span class="token operator">=</span> filters
    
    <span class="token comment"># &#x4FDD;&#x5B58;&#x8F93;&#x51FA;&#x503C;&#x3002;&#x7A0D;&#x540E;&#x9700;&#x8981;&#x5C06;&#x5176;&#x6DFB;&#x52A0;&#x56DE;main&#x8DEF;&#x5F84;&#x3002;</span>
    X_shortcut <span class="token operator">=</span> X
    
    <span class="token comment"># main&#x8DEF;&#x5F84;&#x7684;&#x7B2C;&#x4E00;&#x4E2A;&#x7EC4;&#x6210;&#x90E8;&#x5206;&#xFF08;2D&#x5377;&#x79EF;&#xFF0C;&#x6B63;&#x5219;&#x5316;&#xFF0C;&#x6FC0;&#x6D3B;&#xFF09;</span>
    X <span class="token operator">=</span> Conv2D<span class="token punctuation">(</span>filters <span class="token operator">=</span> F1<span class="token punctuation">,</span> kernel_size <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding <span class="token operator">=</span> <span class="token string">&apos;valid&apos;</span><span class="token punctuation">,</span> name <span class="token operator">=</span> conv_name_base <span class="token operator">+</span> <span class="token string">&apos;2a&apos;</span><span class="token punctuation">,</span> kernel_initializer <span class="token operator">=</span> glorot_uniform<span class="token punctuation">(</span>seed<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    X <span class="token operator">=</span> BatchNormalization<span class="token punctuation">(</span>axis <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span> name <span class="token operator">=</span> bn_name_base <span class="token operator">+</span> <span class="token string">&apos;2a&apos;</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    X <span class="token operator">=</span> Activation<span class="token punctuation">(</span><span class="token string">&apos;relu&apos;</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    
    <span class="token comment">### START CODE HERE ###</span>
    
    <span class="token comment"># main&#x8DEF;&#x5F84;&#x7684;&#x7B2C;&#x4E8C;&#x4E2A;&#x7EC4;&#x6210;&#x90E8;&#x5206;&#xFF08;2D&#x5377;&#x79EF;&#xFF0C;&#x6B63;&#x5219;&#x5316;&#xFF0C;&#x6FC0;&#x6D3B;&#xFF09; (&#x2248;3 lines)</span>
    X <span class="token operator">=</span> Conv2D<span class="token punctuation">(</span>filters <span class="token operator">=</span> F2<span class="token punctuation">,</span> kernel_size <span class="token operator">=</span> <span class="token punctuation">(</span>f<span class="token punctuation">,</span> f<span class="token punctuation">)</span><span class="token punctuation">,</span> strides <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding <span class="token operator">=</span> <span class="token string">&apos;same&apos;</span><span class="token punctuation">,</span> name <span class="token operator">=</span> conv_name_base <span class="token operator">+</span> <span class="token string">&apos;2b&apos;</span><span class="token punctuation">,</span> kernel_initializer <span class="token operator">=</span> glorot_uniform<span class="token punctuation">(</span>seed<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    X <span class="token operator">=</span> BatchNormalization<span class="token punctuation">(</span>axis <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span> name <span class="token operator">=</span> bn_name_base <span class="token operator">+</span> <span class="token string">&apos;2b&apos;</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    X <span class="token operator">=</span> Activation<span class="token punctuation">(</span><span class="token string">&apos;relu&apos;</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>

    <span class="token comment"># main&#x8DEF;&#x5F84;&#x7684;&#x7B2C;&#x4E09;&#x4E2A;&#x7EC4;&#x6210;&#x90E8;&#x5206;&#xFF08;2D&#x5377;&#x79EF;&#xFF0C;&#x6B63;&#x5219;&#x5316;&#xFF09; (&#x2248;2 lines)</span>
    X <span class="token operator">=</span> Conv2D<span class="token punctuation">(</span>filters <span class="token operator">=</span> F3<span class="token punctuation">,</span> kernel_size <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding <span class="token operator">=</span> <span class="token string">&apos;valid&apos;</span><span class="token punctuation">,</span> name <span class="token operator">=</span> conv_name_base <span class="token operator">+</span> <span class="token string">&apos;2c&apos;</span><span class="token punctuation">,</span>kernel_initializer <span class="token operator">=</span> glorot_uniform<span class="token punctuation">(</span>seed<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    X <span class="token operator">=</span> BatchNormalization<span class="token punctuation">(</span>axis <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span> name <span class="token operator">=</span> bn_name_base <span class="token operator">+</span> <span class="token string">&apos;2c&apos;</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>

    <span class="token comment"># &#x6700;&#x540E;&#x4E00;&#x6B65;: &#x5C06;shortcut&#x7684;&#x503C;&#x6DFB;&#x52A0;&#x5230;main&#x8DEF;&#x5F84;&#xFF0C;&#x5E76;&#x4E14;&#x7528;ReLU&#x6FC0;&#x6D3B; (&#x2248;2 lines)</span>
    X <span class="token operator">=</span> Add<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token punctuation">[</span>X<span class="token punctuation">,</span> X_shortcut<span class="token punctuation">]</span><span class="token punctuation">)</span>
    X <span class="token operator">=</span> Activation<span class="token punctuation">(</span><span class="token string">&apos;relu&apos;</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    
    <span class="token comment">### END CODE HERE ###</span>
    
    <span class="token keyword">return</span> X
</pre><h4 class="mume-header" id="%E6%B5%8B%E8%AF%95%E8%BF%90%E8%A1%8C">&#x6D4B;&#x8BD5;&#x8FD0;&#x884C;</h4>

<pre data-role="codeBlock" data-info="python" class="language-python">tf<span class="token punctuation">.</span>reset_default_graph<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">with</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> test<span class="token punctuation">:</span>
    np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
    A_prev <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span><span class="token string">&quot;float&quot;</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    X <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span>
    A <span class="token operator">=</span> identity_block<span class="token punctuation">(</span>A_prev<span class="token punctuation">,</span> f <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span> filters <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">,</span> stage <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span> block <span class="token operator">=</span> <span class="token string">&apos;a&apos;</span><span class="token punctuation">)</span>
    test<span class="token punctuation">.</span>run<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>global_variables_initializer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    out <span class="token operator">=</span> test<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token punctuation">[</span>A<span class="token punctuation">]</span><span class="token punctuation">,</span> feed_dict<span class="token operator">=</span><span class="token punctuation">{</span>A_prev<span class="token punctuation">:</span> X<span class="token punctuation">,</span> K<span class="token punctuation">.</span>learning_phase<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;out = &quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>out<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

</pre><h4 class="mume-header" id="%E7%BB%93%E6%9E%9C-4">&#x7ED3;&#x679C;</h4>

<pre data-role="codeBlock" data-info class="language-"><code>out = [ 0.94822985  0.          1.16101444  2.747859    0.          1.36677003]
</code></pre><h3 class="mume-header" id="%E5%8D%B7%E7%A7%AF%E5%9D%97">&#x5377;&#x79EF;&#x5757;</h3>

<p>&#x60A8;&#x5DF2;&#x7ECF;&#x5B9E;&#x73B0;&#x4E86;ResNet&#x7684;&#x6052;&#x7B49;&#x5757;&#x3002;&#x63A5;&#x4E0B;&#x6765;&#xFF0C;ResNet&#x7684;&#x201C;&#x5377;&#x79EF;&#x5757;&#x201D;&#x662F;&#x53E6;&#x4E00;&#x79CD;&#x7C7B;&#x578B;&#x7684;&#x5757;&#x3002;&#x5F53;<strong>&#x8F93;&#x5165;&#x548C;&#x8F93;&#x51FA;&#x7EF4;&#x5EA6;&#x4E0D;&#x5339;&#x914D;</strong>&#x65F6;&#xFF0C;&#x53EF;&#x4EE5;&#x4F7F;&#x7528;&#x8FD9;&#x79CD;&#x7C7B;&#x578B;&#x7684;&#x5757;&#x3002;&#x4E0E;&#x6807;&#x8BC6;&#x5757;&#x4E0D;&#x540C;&#x7684;&#x662F;&#xFF0C;&#x5728;shortcut&#x8DEF;&#x5F84;&#x4E2D;&#x6709;&#x4E00;&#x4E2A;CONV2D&#x5C42;&#x3002;</p>
<p>shortcut&#x8DEF;&#x5F84;&#x4E2D;&#x7684;CONV2D&#x5C42;&#x7528;&#x4E8E;&#x5C06;&#x8F93;&#x5165;<span class="mathjax-exps">$x$</span>&#x7684;&#x5927;&#x5C0F;&#x8C03;&#x6574;&#x4E3A;&#x4E0D;&#x540C;&#x7684;&#x7EF4;&#x5EA6;&#xFF0C;&#x4EE5;&#x4FBF;&#x5728;&#x5C06;shortcut&#x503C;&#x6DFB;&#x52A0;&#x56DE;main&#x8DEF;&#x5F84;&#x65F6;&#xFF0C;&#x6700;&#x7EC8;&#x6DFB;&#x52A0;&#x7684;&#x7EF4;&#x5EA6;&#x4E0E;&#x4E4B;&#x5339;&#x914D;&#x3002;(&#x5176;&#x4F5C;&#x7528;&#x7C7B;&#x4F3C;&#x4E8E;&#x8BFE;&#x5802;&#x4E0A;&#x8BA8;&#x8BBA;&#x7684;&#x77E9;&#x9635;<span class="mathjax-exps">$W_s$</span>)&#x4F8B;&#x5982;&#xFF0C;&#x8981;&#x5C06;&#x6FC0;&#x6D3B;&#x7EF4;&#x5EA6;&#x7684;&#x9AD8;&#x5EA6;&#x548C;&#x5BBD;&#x5EA6;&#x51CF;&#x5C0F;&#x5230;&#x539F;&#x6765;&#x7684;2&#x500D;&#xFF0C;&#x53EF;&#x4EE5;&#x4F7F;&#x7528;&#x4E00;&#x4E2A;1&#xD7;1&#x5377;&#x79EF;&#xFF0C;&#x6B65;&#x957F;&#x4E3A;2&#x3002;&#x5728;&#x5FEB;&#x6377;&#x8DEF;&#x5F84;&#x4E0A;&#x7684;CONV2D&#x5C42;&#x4E0D;&#x4F7F;&#x7528;&#x4EFB;&#x4F55;&#x975E;&#x7EBF;&#x6027;&#x6FC0;&#x6D3B;&#x51FD;&#x6570;&#x3002;&#x5B83;&#x7684;&#x4E3B;&#x8981;<strong>&#x4F5C;&#x7528;</strong>&#x662F;&#x5E94;&#x7528;&#x4E00;&#x4E2A;(&#x5B66;&#x4E60;&#x8FC7;&#x7684;)&#x7EBF;&#x6027;&#x51FD;&#x6570;&#x6765;<strong>&#x964D;&#x4F4E;&#x8F93;&#x5165;&#x7684;&#x7EF4;&#x6570;</strong>&#xFF0C;&#x4EE5;&#x4FBF;&#x7EF4;&#x6570;&#x4E0E;&#x540E;&#x9762;&#x7684;&#x52A0;&#x6CD5;&#x6B65;&#x9AA4;&#x76F8;&#x5339;&#x914D;&#x3002;</p>
<pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment"># GRADED FUNCTION: convolutional_block</span>

<span class="token keyword">def</span> <span class="token function">convolutional_block</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> f<span class="token punctuation">,</span> filters<span class="token punctuation">,</span> stage<span class="token punctuation">,</span> block<span class="token punctuation">,</span> s <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&quot;&quot;&quot;
    Implementation of the convolutional block as defined in Figure 4
    
    Arguments:
    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)
    f -- integer, specifying the shape of the middle CONV&apos;s window for the main path
    filters -- python list of integers, defining the number of filters in the CONV layers of the main path
    stage -- integer, used to name the layers, depending on their position in the network
    block -- string/character, used to name the layers, depending on their position in the network
    s -- Integer, specifying the stride to be used
    
    Returns:
    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)
    &quot;&quot;&quot;</span>
    
    
    conv_name_base <span class="token operator">=</span> <span class="token string">&apos;res&apos;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>stage<span class="token punctuation">)</span> <span class="token operator">+</span> block <span class="token operator">+</span> <span class="token string">&apos;_branch&apos;</span>
    bn_name_base <span class="token operator">=</span> <span class="token string">&apos;bn&apos;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>stage<span class="token punctuation">)</span> <span class="token operator">+</span> block <span class="token operator">+</span> <span class="token string">&apos;_branch&apos;</span>
    
    
    F1<span class="token punctuation">,</span> F2<span class="token punctuation">,</span> F3 <span class="token operator">=</span> filters
    
    <span class="token comment"># &#x4FDD;&#x5B58;&#x8F93;&#x51FA;&#x503C;</span>
    X_shortcut <span class="token operator">=</span> X


    <span class="token comment">##### MAIN PATH #####</span>
    <span class="token comment"># main&#x8DEF;&#x5F84;&#x7684;&#x7B2C;&#x4E00;&#x7EC4;&#x6210;&#x90E8;&#x5206;</span>
    X <span class="token operator">=</span> Conv2D<span class="token punctuation">(</span>filters <span class="token operator">=</span> F1<span class="token punctuation">,</span> kernel_size <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides <span class="token operator">=</span> <span class="token punctuation">(</span>s<span class="token punctuation">,</span>s<span class="token punctuation">)</span><span class="token punctuation">,</span> padding <span class="token operator">=</span> <span class="token string">&apos;valid&apos;</span><span class="token punctuation">,</span> name <span class="token operator">=</span> conv_name_base <span class="token operator">+</span> <span class="token string">&apos;2a&apos;</span><span class="token punctuation">,</span> kernel_initializer <span class="token operator">=</span> glorot_uniform<span class="token punctuation">(</span>seed<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    X <span class="token operator">=</span> BatchNormalization<span class="token punctuation">(</span>axis <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span> name <span class="token operator">=</span> bn_name_base <span class="token operator">+</span> <span class="token string">&apos;2a&apos;</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    X <span class="token operator">=</span> Activation<span class="token punctuation">(</span><span class="token string">&apos;relu&apos;</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    
    <span class="token comment">### START CODE HERE ###</span>

    <span class="token comment"># main&#x8DEF;&#x5F84;&#x7684;&#x7B2C;&#x4E8C;&#x7EC4;&#x6210;&#x90E8;&#x5206; (&#x2248;3 lines)</span>
    X <span class="token operator">=</span> Conv2D<span class="token punctuation">(</span>filters <span class="token operator">=</span> F2<span class="token punctuation">,</span> kernel_size <span class="token operator">=</span> <span class="token punctuation">(</span>f<span class="token punctuation">,</span> f<span class="token punctuation">)</span><span class="token punctuation">,</span> strides <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding <span class="token operator">=</span> <span class="token string">&apos;same&apos;</span><span class="token punctuation">,</span> name <span class="token operator">=</span> conv_name_base <span class="token operator">+</span> <span class="token string">&apos;2b&apos;</span><span class="token punctuation">,</span> kernel_initializer <span class="token operator">=</span> glorot_uniform<span class="token punctuation">(</span>seed<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    X <span class="token operator">=</span> BatchNormalization<span class="token punctuation">(</span>axis <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span> name <span class="token operator">=</span> bn_name_base <span class="token operator">+</span> <span class="token string">&apos;2b&apos;</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    X <span class="token operator">=</span> Activation<span class="token punctuation">(</span><span class="token string">&apos;relu&apos;</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>

    <span class="token comment"># main&#x8DEF;&#x5F84;&#x7684;&#x7B2C;&#x4E09;&#x7EC4;&#x6210;&#x90E8;&#x5206; (&#x2248;2 lines)</span>
    X <span class="token operator">=</span> Conv2D<span class="token punctuation">(</span>filters <span class="token operator">=</span> F3<span class="token punctuation">,</span> kernel_size <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding <span class="token operator">=</span> <span class="token string">&apos;valid&apos;</span><span class="token punctuation">,</span> name <span class="token operator">=</span> conv_name_base <span class="token operator">+</span> <span class="token string">&apos;2c&apos;</span><span class="token punctuation">,</span> kernel_initializer <span class="token operator">=</span> glorot_uniform<span class="token punctuation">(</span>seed<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    X <span class="token operator">=</span> BatchNormalization<span class="token punctuation">(</span>axis <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span> name <span class="token operator">=</span> bn_name_base <span class="token operator">+</span> <span class="token string">&apos;2c&apos;</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>

    <span class="token comment">##### SHORTCUT PATH #### (&#x2248;2 lines)</span>
    X_shortcut <span class="token operator">=</span> Conv2D<span class="token punctuation">(</span>filters <span class="token operator">=</span> F3<span class="token punctuation">,</span> kernel_size <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides <span class="token operator">=</span> <span class="token punctuation">(</span>s<span class="token punctuation">,</span> s<span class="token punctuation">)</span><span class="token punctuation">,</span> padding <span class="token operator">=</span> <span class="token string">&apos;valid&apos;</span><span class="token punctuation">,</span> name <span class="token operator">=</span> conv_name_base <span class="token operator">+</span> <span class="token string">&apos;1&apos;</span><span class="token punctuation">,</span> kernel_initializer <span class="token operator">=</span> glorot_uniform<span class="token punctuation">(</span>seed<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X_shortcut<span class="token punctuation">)</span>
    X_shortcut <span class="token operator">=</span> BatchNormalization<span class="token punctuation">(</span>axis <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span> name <span class="token operator">=</span> bn_name_base <span class="token operator">+</span> <span class="token string">&apos;1&apos;</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X_shortcut<span class="token punctuation">)</span>

    <span class="token comment"># &#x6700;&#x540E;&#x4E00;&#x6B65;: &#x5C06;shortcut&#x7684;&#x503C;&#x6DFB;&#x52A0;&#x5230;main&#xFF0C;&#x5E76;&#x4E14;&#x7528;ReLU&#x6FC0;&#x6D3B; (&#x2248;2 lines)</span>
    X <span class="token operator">=</span> Add<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token punctuation">[</span>X<span class="token punctuation">,</span> X_shortcut<span class="token punctuation">]</span><span class="token punctuation">)</span>
    X <span class="token operator">=</span> Activation<span class="token punctuation">(</span><span class="token string">&apos;relu&apos;</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    
    <span class="token comment">### END CODE HERE ###</span>
    
    <span class="token keyword">return</span> X
</pre><h4 class="mume-header" id="%E6%B5%8B%E8%AF%95-1">&#x6D4B;&#x8BD5;</h4>

<pre data-role="codeBlock" data-info="python" class="language-python">tf<span class="token punctuation">.</span>reset_default_graph<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">with</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> test<span class="token punctuation">:</span>
    np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
    A_prev <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span><span class="token string">&quot;float&quot;</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    X <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span>
    A <span class="token operator">=</span> convolutional_block<span class="token punctuation">(</span>A_prev<span class="token punctuation">,</span> f <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span> filters <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">,</span> stage <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span> block <span class="token operator">=</span> <span class="token string">&apos;a&apos;</span><span class="token punctuation">)</span>
    test<span class="token punctuation">.</span>run<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>global_variables_initializer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    out <span class="token operator">=</span> test<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token punctuation">[</span>A<span class="token punctuation">]</span><span class="token punctuation">,</span> feed_dict<span class="token operator">=</span><span class="token punctuation">{</span>A_prev<span class="token punctuation">:</span> X<span class="token punctuation">,</span> K<span class="token punctuation">.</span>learning_phase<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;out = &quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>out<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</pre><h4 class="mume-header" id="%E7%BB%93%E6%9E%9C-5">&#x7ED3;&#x679C;</h4>

<pre data-role="codeBlock" data-info class="language-"><code>out = [ 0.09018463  1.23489773  0.46822017  0.0367176   0.          0.65516603]
</code></pre><h2 class="mume-header" id="%E6%9E%84%E5%BB%BAresnet%E6%A8%A1%E5%9E%8B50%E5%B1%82">&#x6784;&#x5EFA;ResNet&#x6A21;&#x578B;(50&#x5C42;)</h2>

<pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment"># GRADED FUNCTION: ResNet50</span>

<span class="token keyword">def</span> <span class="token function">ResNet50</span><span class="token punctuation">(</span>input_shape <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> classes <span class="token operator">=</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&quot;&quot;&quot;
    Implementation of the popular ResNet50 the following architecture:
    CONV2D -&gt; BATCHNORM -&gt; RELU -&gt; MAXPOOL -&gt; CONVBLOCK -&gt; IDBLOCK*2 -&gt; CONVBLOCK -&gt; IDBLOCK*3
    -&gt; CONVBLOCK -&gt; IDBLOCK*5 -&gt; CONVBLOCK -&gt; IDBLOCK*2 -&gt; AVGPOOL -&gt; TOPLAYER

    Arguments:
    input_shape -- shape of the images of the dataset
    classes -- integer, number of classes

    Returns:
    model -- a Model() instance in Keras
    &quot;&quot;&quot;</span>
    
    <span class="token comment"># &#x5C06;&#x8F93;&#x51FA;&#x5B9A;&#x4E49;&#x4E3A;&#x4E00;&#x4E2A;tensor&#x3010;shape&#x4E3A;input_shape&#x3011;</span>
    X_input <span class="token operator">=</span> Input<span class="token punctuation">(</span>input_shape<span class="token punctuation">)</span>

    
    <span class="token comment"># &#x96F6;&#x586B;&#x5145;</span>
    X <span class="token operator">=</span> ZeroPadding2D<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X_input<span class="token punctuation">)</span>
    
    <span class="token comment"># &#x9636;&#x6BB5; 1</span>
    X <span class="token operator">=</span> Conv2D<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> name <span class="token operator">=</span> <span class="token string">&apos;conv1&apos;</span><span class="token punctuation">,</span> kernel_initializer <span class="token operator">=</span> glorot_uniform<span class="token punctuation">(</span>seed<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    X <span class="token operator">=</span> BatchNormalization<span class="token punctuation">(</span>axis <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span> name <span class="token operator">=</span> <span class="token string">&apos;bn_conv1&apos;</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    X <span class="token operator">=</span> Activation<span class="token punctuation">(</span><span class="token string">&apos;relu&apos;</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    X <span class="token operator">=</span> MaxPooling2D<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>

    <span class="token comment"># &#x9636;&#x6BB5; 2</span>
    X <span class="token operator">=</span> convolutional_block<span class="token punctuation">(</span>X<span class="token punctuation">,</span> f <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span> filters <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">]</span><span class="token punctuation">,</span> stage <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span> block<span class="token operator">=</span><span class="token string">&apos;a&apos;</span><span class="token punctuation">,</span> s <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>
    X <span class="token operator">=</span> identity_block<span class="token punctuation">(</span>X<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">]</span><span class="token punctuation">,</span> stage<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> block<span class="token operator">=</span><span class="token string">&apos;b&apos;</span><span class="token punctuation">)</span>
    X <span class="token operator">=</span> identity_block<span class="token punctuation">(</span>X<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">]</span><span class="token punctuation">,</span> stage<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> block<span class="token operator">=</span><span class="token string">&apos;c&apos;</span><span class="token punctuation">)</span>

    <span class="token comment">### START CODE HERE ###</span>

    <span class="token comment"># &#x9636;&#x6BB5; 3 (&#x2248;4 lines)</span>
    X <span class="token operator">=</span> convolutional_block<span class="token punctuation">(</span>X<span class="token punctuation">,</span> f <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span> filters <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">]</span><span class="token punctuation">,</span> stage <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span> block<span class="token operator">=</span><span class="token string">&apos;a&apos;</span><span class="token punctuation">,</span> s <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span>
    X <span class="token operator">=</span> identity_block<span class="token punctuation">(</span>X<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">]</span><span class="token punctuation">,</span> stage<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> block<span class="token operator">=</span><span class="token string">&apos;b&apos;</span><span class="token punctuation">)</span>
    X <span class="token operator">=</span> identity_block<span class="token punctuation">(</span>X<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">]</span><span class="token punctuation">,</span> stage<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> block<span class="token operator">=</span><span class="token string">&apos;c&apos;</span><span class="token punctuation">)</span>
    X <span class="token operator">=</span> identity_block<span class="token punctuation">(</span>X<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">]</span><span class="token punctuation">,</span> stage<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> block<span class="token operator">=</span><span class="token string">&apos;d&apos;</span><span class="token punctuation">)</span>

    <span class="token comment"># &#x9636;&#x6BB5; 4 (&#x2248;6 lines)</span>
    X <span class="token operator">=</span> convolutional_block<span class="token punctuation">(</span>X<span class="token punctuation">,</span> f <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span> filters <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">]</span><span class="token punctuation">,</span> stage <span class="token operator">=</span> <span class="token number">4</span><span class="token punctuation">,</span> block<span class="token operator">=</span><span class="token string">&apos;a&apos;</span><span class="token punctuation">,</span> s <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span>
    X <span class="token operator">=</span> identity_block<span class="token punctuation">(</span>X<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">]</span><span class="token punctuation">,</span> stage<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> block<span class="token operator">=</span><span class="token string">&apos;b&apos;</span><span class="token punctuation">)</span>
    X <span class="token operator">=</span> identity_block<span class="token punctuation">(</span>X<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">]</span><span class="token punctuation">,</span> stage<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> block<span class="token operator">=</span><span class="token string">&apos;c&apos;</span><span class="token punctuation">)</span>
    X <span class="token operator">=</span> identity_block<span class="token punctuation">(</span>X<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">]</span><span class="token punctuation">,</span> stage<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> block<span class="token operator">=</span><span class="token string">&apos;d&apos;</span><span class="token punctuation">)</span>
    X <span class="token operator">=</span> identity_block<span class="token punctuation">(</span>X<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">]</span><span class="token punctuation">,</span> stage<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> block<span class="token operator">=</span><span class="token string">&apos;e&apos;</span><span class="token punctuation">)</span>
    X <span class="token operator">=</span> identity_block<span class="token punctuation">(</span>X<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">]</span><span class="token punctuation">,</span> stage<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> block<span class="token operator">=</span><span class="token string">&apos;f&apos;</span><span class="token punctuation">)</span>

    <span class="token comment"># &#x9636;&#x6BB5; 5 (&#x2248;3 lines)</span>
    X <span class="token operator">=</span> convolutional_block<span class="token punctuation">(</span>X<span class="token punctuation">,</span> f <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span> filters <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">2048</span><span class="token punctuation">]</span><span class="token punctuation">,</span> stage <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">,</span> block<span class="token operator">=</span><span class="token string">&apos;a&apos;</span><span class="token punctuation">,</span> s <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span>
    X <span class="token operator">=</span> identity_block<span class="token punctuation">(</span>X<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">2048</span><span class="token punctuation">]</span><span class="token punctuation">,</span> stage<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> block<span class="token operator">=</span><span class="token string">&apos;b&apos;</span><span class="token punctuation">)</span>
    X <span class="token operator">=</span> identity_block<span class="token punctuation">(</span>X<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">2048</span><span class="token punctuation">]</span><span class="token punctuation">,</span> stage<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> block<span class="token operator">=</span><span class="token string">&apos;c&apos;</span><span class="token punctuation">)</span>

    <span class="token comment"># AVGPOOL (&#x2248;1 line). Use &quot;X = AveragePooling2D(...)(X)&quot;</span>
    X <span class="token operator">=</span> AveragePooling2D<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    
    <span class="token comment">### END CODE HERE ###</span>

    <span class="token comment"># &#x8F93;&#x51FA;&#x5C42;</span>
    X <span class="token operator">=</span> Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    X <span class="token operator">=</span> Dense<span class="token punctuation">(</span>classes<span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">&apos;softmax&apos;</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">&apos;fc&apos;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>classes<span class="token punctuation">)</span><span class="token punctuation">,</span> kernel_initializer <span class="token operator">=</span> glorot_uniform<span class="token punctuation">(</span>seed<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    
    
    <span class="token comment"># &#x521B;&#x5EFA;&#x6A21;&#x578B;</span>
    model <span class="token operator">=</span> Model<span class="token punctuation">(</span>inputs <span class="token operator">=</span> X_input<span class="token punctuation">,</span> outputs <span class="token operator">=</span> X<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">&apos;ResNet50&apos;</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> model
</pre><h3 class="mume-header" id="%E5%AE%9E%E4%BE%8B%E5%8C%96%E6%A8%A1%E5%9E%8B">&#x5B9E;&#x4F8B;&#x5316;&#x6A21;&#x578B;</h3>

<pre data-role="codeBlock" data-info class="language-"><code>model = ResNet50(input_shape = (64, 64, 3), classes = 6)
</code></pre><h3 class="mume-header" id="%E7%BC%96%E8%AF%91%E6%A8%A1%E5%9E%8B-1">&#x7F16;&#x8BD1;&#x6A21;&#x578B;</h3>

<pre data-role="codeBlock" data-info class="language-"><code>model.compile(optimizer=&apos;adam&apos;, loss=&apos;categorical_crossentropy&apos;, metrics=[&apos;accuracy&apos;])
</code></pre><h3 class="mume-header" id="%E5%87%86%E5%A4%87%E6%95%B0%E6%8D%AE%E9%9B%86">&#x51C6;&#x5907;&#x6570;&#x636E;&#x96C6;</h3>

<pre data-role="codeBlock" data-info="python" class="language-python">X_train_orig<span class="token punctuation">,</span> Y_train_orig<span class="token punctuation">,</span> X_test_orig<span class="token punctuation">,</span> Y_test_orig<span class="token punctuation">,</span> classes <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Normalize image vectors</span>
X_train <span class="token operator">=</span> X_train_orig<span class="token operator">/</span><span class="token number">255</span><span class="token punctuation">.</span>
X_test <span class="token operator">=</span> X_test_orig<span class="token operator">/</span><span class="token number">255</span><span class="token punctuation">.</span>

<span class="token comment"># Convert training and test labels to one hot matrices</span>
Y_train <span class="token operator">=</span> convert_to_one_hot<span class="token punctuation">(</span>Y_train_orig<span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">.</span>T
Y_test <span class="token operator">=</span> convert_to_one_hot<span class="token punctuation">(</span>Y_test_orig<span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">.</span>T

</pre><h4 class="mume-header" id="%E6%B5%8B%E8%AF%95shape">&#x6D4B;&#x8BD5;shape</h4>

<pre data-role="codeBlock" data-info="python" class="language-python"><span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&quot;number of training examples = &quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>X_train<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&quot;number of test examples = &quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>X_test<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&quot;X_train shape: &quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>X_train<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&quot;Y_train shape: &quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>Y_train<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&quot;X_test shape: &quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>X_test<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&quot;Y_test shape: &quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>Y_test<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
</pre><h4 class="mume-header" id="%E7%BB%93%E6%9E%9C-6">&#x7ED3;&#x679C;</h4>

<pre data-role="codeBlock" data-info class="language-"><code>number of training examples = 1080
number of test examples = 120
X_train shape: (1080, 64, 64, 3)
Y_train shape: (1080, 6)
X_test shape: (120, 64, 64, 3)
Y_test shape: (120, 6)
</code></pre><h3 class="mume-header" id="%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B-1">&#x8BAD;&#x7EC3;&#x6A21;&#x578B;</h3>

<pre data-role="codeBlock" data-info class="language-"><code>model.fit(X_train, Y_train, epochs = 2, batch_size = 32)
</code></pre><h4 class="mume-header" id="%E7%BB%93%E6%9E%9C-7">&#x7ED3;&#x679C;</h4>

<pre data-role="codeBlock" data-info class="language-"><code>Epoch 1/2
1080/1080 [==============================] - 288s - loss: 3.1092 - acc: 0.2380   
Epoch 2/2
1080/1080 [==============================] - 256s - loss: 2.2482 - acc: 0.3306   
</code></pre><h3 class="mume-header" id="%E6%9F%A5%E7%9C%8B%E6%95%88%E6%9E%9C">&#x67E5;&#x770B;&#x6548;&#x679C;</h3>

<pre data-role="codeBlock" data-info="python" class="language-python">preds <span class="token operator">=</span> model<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>X_test<span class="token punctuation">,</span> Y_test<span class="token punctuation">)</span>
<span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&quot;Loss = &quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>preds<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&quot;Test Accuracy = &quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>preds<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</pre><h4 class="mume-header" id="%E7%BB%93%E6%9E%9C-8">&#x7ED3;&#x679C;</h4>

<pre data-role="codeBlock" data-info class="language-"><code>120/120 [==============================] - 10s    
Loss = 2.35326625506
Test Accuracy = 0.166666666667
</code></pre><p>ResNet50&#x662F;&#x4E00;&#x4E2A;&#x5F3A;&#x5927;&#x7684;&#x56FE;&#x50CF;&#x5206;&#x7C7B;&#x6A21;&#x578B;&#xFF0C;&#x5F53;&#x8BAD;&#x7EC3;&#x5B83;&#x8DB3;&#x591F;&#x7684;&#x8FED;&#x4EE3;&#x6B21;&#x6570;&#x3002;&#x6211;&#x4EEC;&#x5E0C;&#x671B;&#x60A8;&#x53EF;&#x4EE5;&#x4F7F;&#x7528;&#x60A8;&#x6240;&#x5B66;&#x5230;&#x7684;&#xFF0C;&#x5E76;&#x5C06;&#x5176;&#x5E94;&#x7528;&#x5230;&#x60A8;&#x81EA;&#x5DF1;&#x7684;&#x5206;&#x7C7B;&#x95EE;&#x9898;&#xFF0C;&#x4EE5;&#x6267;&#x884C;&#x6700;&#x5148;&#x8FDB;&#x7684;&#x51C6;&#x786E;&#x6027;&#x3002;</p>
<h2 class="mume-header" id="%E6%B5%8B%E8%AF%95%E8%87%AA%E5%B7%B1%E7%9A%84%E5%9B%BE%E7%89%87-%E9%80%89%E5%81%9A-1">&#x6D4B;&#x8BD5;&#x81EA;&#x5DF1;&#x7684;&#x56FE;&#x7247; (&#x9009;&#x505A;)</h2>

<pre data-role="codeBlock" data-info="python" class="language-python">img_path <span class="token operator">=</span> <span class="token string">&apos;images/my_image.jpg&apos;</span>
img <span class="token operator">=</span> image<span class="token punctuation">.</span>load_img<span class="token punctuation">(</span>img_path<span class="token punctuation">,</span> target_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
x <span class="token operator">=</span> image<span class="token punctuation">.</span>img_to_array<span class="token punctuation">(</span>img<span class="token punctuation">)</span>
x <span class="token operator">=</span> np<span class="token punctuation">.</span>expand_dims<span class="token punctuation">(</span>x<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
x <span class="token operator">=</span> preprocess_input<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&apos;Input image shape:&apos;</span><span class="token punctuation">,</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
my_image <span class="token operator">=</span> scipy<span class="token punctuation">.</span>misc<span class="token punctuation">.</span>imread<span class="token punctuation">(</span>img_path<span class="token punctuation">)</span>
imshow<span class="token punctuation">(</span>my_image<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;class prediction vector [p(0), p(1), p(2), p(3), p(4), p(5)] = &quot;</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>

</pre><h3 class="mume-header" id="%E7%BB%93%E6%9E%9C-9">&#x7ED3;&#x679C;</h3>

<pre data-role="codeBlock" data-info class="language-"><code>Input image shape: (1, 64, 64, 3)
class prediction vector [p(0), p(1), p(2), p(3), p(4), p(5)] = 
[[ 0.  0.  0.  0.  1.  0.]]
</code></pre><p><img src="img/QQ%E6%88%AA%E5%9B%BE20200820160001.jpg" alt></p>
<h3 class="mume-header" id="%E6%89%93%E5%8D%B0%E6%91%98%E8%A6%81">&#x6253;&#x5370;&#x6458;&#x8981;</h3>

<p>&#x60A8;&#x8FD8;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;&#x8FD0;&#x884C;&#x4EE5;&#x4E0B;&#x4EE3;&#x7801;&#x6253;&#x5370;&#x6A21;&#x578B;&#x7684;&#x6458;&#x8981;&#x3002;</p>
<pre data-role="codeBlock" data-info="python" class="language-python">model<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span>
</pre><h4 class="mume-header" id="%E7%BB%93%E6%9E%9C-10">&#x7ED3;&#x679C;</h4>

<pre data-role="codeBlock" data-info class="language-"><code>____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
input_1 (InputLayer)             (None, 64, 64, 3)     0                                            
____________________________________________________________________________________________________
zero_padding2d_1 (ZeroPadding2D) (None, 70, 70, 3)     0           input_1[0][0]                    
____________________________________________________________________________________________________
conv1 (Conv2D)                   (None, 32, 32, 64)    9472        zero_padding2d_1[0][0]           
____________________________________________________________________________________________________
bn_conv1 (BatchNormalization)    (None, 32, 32, 64)    256         conv1[0][0]                      
____________________________________________________________________________________________________
activation_4 (Activation)        (None, 32, 32, 64)    0           bn_conv1[0][0]                   
____________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)   (None, 15, 15, 64)    0           activation_4[0][0]               
____________________________________________________________________________________________________
res2a_branch2a (Conv2D)          (None, 15, 15, 64)    4160        max_pooling2d_1[0][0]            
____________________________________________________________________________________________________
bn2a_branch2a (BatchNormalizatio (None, 15, 15, 64)    256         res2a_branch2a[0][0]             
____________________________________________________________________________________________________
activation_5 (Activation)        (None, 15, 15, 64)    0           bn2a_branch2a[0][0]              
____________________________________________________________________________________________________
res2a_branch2b (Conv2D)          (None, 15, 15, 64)    36928       activation_5[0][0]               
____________________________________________________________________________________________________
bn2a_branch2b (BatchNormalizatio (None, 15, 15, 64)    256         res2a_branch2b[0][0]             
____________________________________________________________________________________________________
activation_6 (Activation)        (None, 15, 15, 64)    0           bn2a_branch2b[0][0]              
____________________________________________________________________________________________________
res2a_branch2c (Conv2D)          (None, 15, 15, 256)   16640       activation_6[0][0]               
____________________________________________________________________________________________________
res2a_branch1 (Conv2D)           (None, 15, 15, 256)   16640       max_pooling2d_1[0][0]            
____________________________________________________________________________________________________
bn2a_branch2c (BatchNormalizatio (None, 15, 15, 256)   1024        res2a_branch2c[0][0]             
____________________________________________________________________________________________________
bn2a_branch1 (BatchNormalization (None, 15, 15, 256)   1024        res2a_branch1[0][0]              
____________________________________________________________________________________________________
add_2 (Add)                      (None, 15, 15, 256)   0           bn2a_branch2c[0][0]              
                                                                   bn2a_branch1[0][0]               
____________________________________________________________________________________________________
activation_7 (Activation)        (None, 15, 15, 256)   0           add_2[0][0]                      
____________________________________________________________________________________________________
res2b_branch2a (Conv2D)          (None, 15, 15, 64)    16448       activation_7[0][0]               
____________________________________________________________________________________________________
bn2b_branch2a (BatchNormalizatio (None, 15, 15, 64)    256         res2b_branch2a[0][0]             
____________________________________________________________________________________________________
activation_8 (Activation)        (None, 15, 15, 64)    0           bn2b_branch2a[0][0]              
____________________________________________________________________________________________________
res2b_branch2b (Conv2D)          (None, 15, 15, 64)    36928       activation_8[0][0]               
____________________________________________________________________________________________________
bn2b_branch2b (BatchNormalizatio (None, 15, 15, 64)    256         res2b_branch2b[0][0]             
____________________________________________________________________________________________________
activation_9 (Activation)        (None, 15, 15, 64)    0           bn2b_branch2b[0][0]              
____________________________________________________________________________________________________
res2b_branch2c (Conv2D)          (None, 15, 15, 256)   16640       activation_9[0][0]               
____________________________________________________________________________________________________
bn2b_branch2c (BatchNormalizatio (None, 15, 15, 256)   1024        res2b_branch2c[0][0]             
____________________________________________________________________________________________________
add_3 (Add)                      (None, 15, 15, 256)   0           bn2b_branch2c[0][0]              
                                                                   activation_7[0][0]               
____________________________________________________________________________________________________
activation_10 (Activation)       (None, 15, 15, 256)   0           add_3[0][0]                      
____________________________________________________________________________________________________
res2c_branch2a (Conv2D)          (None, 15, 15, 64)    16448       activation_10[0][0]              
____________________________________________________________________________________________________
bn2c_branch2a (BatchNormalizatio (None, 15, 15, 64)    256         res2c_branch2a[0][0]             
____________________________________________________________________________________________________
activation_11 (Activation)       (None, 15, 15, 64)    0           bn2c_branch2a[0][0]              
____________________________________________________________________________________________________
res2c_branch2b (Conv2D)          (None, 15, 15, 64)    36928       activation_11[0][0]              
____________________________________________________________________________________________________
bn2c_branch2b (BatchNormalizatio (None, 15, 15, 64)    256         res2c_branch2b[0][0]             
____________________________________________________________________________________________________
activation_12 (Activation)       (None, 15, 15, 64)    0           bn2c_branch2b[0][0]              
____________________________________________________________________________________________________
res2c_branch2c (Conv2D)          (None, 15, 15, 256)   16640       activation_12[0][0]              
____________________________________________________________________________________________________
bn2c_branch2c (BatchNormalizatio (None, 15, 15, 256)   1024        res2c_branch2c[0][0]             
____________________________________________________________________________________________________
add_4 (Add)                      (None, 15, 15, 256)   0           bn2c_branch2c[0][0]              
                                                                   activation_10[0][0]              
____________________________________________________________________________________________________
activation_13 (Activation)       (None, 15, 15, 256)   0           add_4[0][0]                      
____________________________________________________________________________________________________
res3a_branch2a (Conv2D)          (None, 8, 8, 128)     32896       activation_13[0][0]              
____________________________________________________________________________________________________
bn3a_branch2a (BatchNormalizatio (None, 8, 8, 128)     512         res3a_branch2a[0][0]             
____________________________________________________________________________________________________
activation_14 (Activation)       (None, 8, 8, 128)     0           bn3a_branch2a[0][0]              
____________________________________________________________________________________________________
res3a_branch2b (Conv2D)          (None, 8, 8, 128)     147584      activation_14[0][0]              
____________________________________________________________________________________________________
bn3a_branch2b (BatchNormalizatio (None, 8, 8, 128)     512         res3a_branch2b[0][0]             
____________________________________________________________________________________________________
activation_15 (Activation)       (None, 8, 8, 128)     0           bn3a_branch2b[0][0]              
____________________________________________________________________________________________________
res3a_branch2c (Conv2D)          (None, 8, 8, 512)     66048       activation_15[0][0]              
____________________________________________________________________________________________________
res3a_branch1 (Conv2D)           (None, 8, 8, 512)     131584      activation_13[0][0]              
____________________________________________________________________________________________________
bn3a_branch2c (BatchNormalizatio (None, 8, 8, 512)     2048        res3a_branch2c[0][0]             
____________________________________________________________________________________________________
bn3a_branch1 (BatchNormalization (None, 8, 8, 512)     2048        res3a_branch1[0][0]              
____________________________________________________________________________________________________
add_5 (Add)                      (None, 8, 8, 512)     0           bn3a_branch2c[0][0]              
                                                                   bn3a_branch1[0][0]               
____________________________________________________________________________________________________
activation_16 (Activation)       (None, 8, 8, 512)     0           add_5[0][0]                      
____________________________________________________________________________________________________
res3b_branch2a (Conv2D)          (None, 8, 8, 128)     65664       activation_16[0][0]              
____________________________________________________________________________________________________
bn3b_branch2a (BatchNormalizatio (None, 8, 8, 128)     512         res3b_branch2a[0][0]             
____________________________________________________________________________________________________
activation_17 (Activation)       (None, 8, 8, 128)     0           bn3b_branch2a[0][0]              
____________________________________________________________________________________________________
res3b_branch2b (Conv2D)          (None, 8, 8, 128)     147584      activation_17[0][0]              
____________________________________________________________________________________________________
bn3b_branch2b (BatchNormalizatio (None, 8, 8, 128)     512         res3b_branch2b[0][0]             
____________________________________________________________________________________________________
activation_18 (Activation)       (None, 8, 8, 128)     0           bn3b_branch2b[0][0]              
____________________________________________________________________________________________________
res3b_branch2c (Conv2D)          (None, 8, 8, 512)     66048       activation_18[0][0]              
____________________________________________________________________________________________________
bn3b_branch2c (BatchNormalizatio (None, 8, 8, 512)     2048        res3b_branch2c[0][0]             
____________________________________________________________________________________________________
add_6 (Add)                      (None, 8, 8, 512)     0           bn3b_branch2c[0][0]              
                                                                   activation_16[0][0]              
____________________________________________________________________________________________________
activation_19 (Activation)       (None, 8, 8, 512)     0           add_6[0][0]                      
____________________________________________________________________________________________________
res3c_branch2a (Conv2D)          (None, 8, 8, 128)     65664       activation_19[0][0]              
____________________________________________________________________________________________________
bn3c_branch2a (BatchNormalizatio (None, 8, 8, 128)     512         res3c_branch2a[0][0]             
____________________________________________________________________________________________________
activation_20 (Activation)       (None, 8, 8, 128)     0           bn3c_branch2a[0][0]              
____________________________________________________________________________________________________
res3c_branch2b (Conv2D)          (None, 8, 8, 128)     147584      activation_20[0][0]              
____________________________________________________________________________________________________
bn3c_branch2b (BatchNormalizatio (None, 8, 8, 128)     512         res3c_branch2b[0][0]             
____________________________________________________________________________________________________
activation_21 (Activation)       (None, 8, 8, 128)     0           bn3c_branch2b[0][0]              
____________________________________________________________________________________________________
res3c_branch2c (Conv2D)          (None, 8, 8, 512)     66048       activation_21[0][0]              
____________________________________________________________________________________________________
bn3c_branch2c (BatchNormalizatio (None, 8, 8, 512)     2048        res3c_branch2c[0][0]             
____________________________________________________________________________________________________
add_7 (Add)                      (None, 8, 8, 512)     0           bn3c_branch2c[0][0]              
                                                                   activation_19[0][0]              
____________________________________________________________________________________________________
activation_22 (Activation)       (None, 8, 8, 512)     0           add_7[0][0]                      
____________________________________________________________________________________________________
res3d_branch2a (Conv2D)          (None, 8, 8, 128)     65664       activation_22[0][0]              
____________________________________________________________________________________________________
bn3d_branch2a (BatchNormalizatio (None, 8, 8, 128)     512         res3d_branch2a[0][0]             
____________________________________________________________________________________________________
activation_23 (Activation)       (None, 8, 8, 128)     0           bn3d_branch2a[0][0]              
____________________________________________________________________________________________________
res3d_branch2b (Conv2D)          (None, 8, 8, 128)     147584      activation_23[0][0]              
____________________________________________________________________________________________________
bn3d_branch2b (BatchNormalizatio (None, 8, 8, 128)     512         res3d_branch2b[0][0]             
____________________________________________________________________________________________________
activation_24 (Activation)       (None, 8, 8, 128)     0           bn3d_branch2b[0][0]              
____________________________________________________________________________________________________
res3d_branch2c (Conv2D)          (None, 8, 8, 512)     66048       activation_24[0][0]              
____________________________________________________________________________________________________
bn3d_branch2c (BatchNormalizatio (None, 8, 8, 512)     2048        res3d_branch2c[0][0]             
____________________________________________________________________________________________________
add_8 (Add)                      (None, 8, 8, 512)     0           bn3d_branch2c[0][0]              
                                                                   activation_22[0][0]              
____________________________________________________________________________________________________
activation_25 (Activation)       (None, 8, 8, 512)     0           add_8[0][0]                      
____________________________________________________________________________________________________
res4a_branch2a (Conv2D)          (None, 4, 4, 256)     131328      activation_25[0][0]              
____________________________________________________________________________________________________
bn4a_branch2a (BatchNormalizatio (None, 4, 4, 256)     1024        res4a_branch2a[0][0]             
____________________________________________________________________________________________________
activation_26 (Activation)       (None, 4, 4, 256)     0           bn4a_branch2a[0][0]              
____________________________________________________________________________________________________
res4a_branch2b (Conv2D)          (None, 4, 4, 256)     590080      activation_26[0][0]              
____________________________________________________________________________________________________
bn4a_branch2b (BatchNormalizatio (None, 4, 4, 256)     1024        res4a_branch2b[0][0]             
____________________________________________________________________________________________________
activation_27 (Activation)       (None, 4, 4, 256)     0           bn4a_branch2b[0][0]              
____________________________________________________________________________________________________
res4a_branch2c (Conv2D)          (None, 4, 4, 1024)    263168      activation_27[0][0]              
____________________________________________________________________________________________________
res4a_branch1 (Conv2D)           (None, 4, 4, 1024)    525312      activation_25[0][0]              
____________________________________________________________________________________________________
bn4a_branch2c (BatchNormalizatio (None, 4, 4, 1024)    4096        res4a_branch2c[0][0]             
____________________________________________________________________________________________________
bn4a_branch1 (BatchNormalization (None, 4, 4, 1024)    4096        res4a_branch1[0][0]              
____________________________________________________________________________________________________
add_9 (Add)                      (None, 4, 4, 1024)    0           bn4a_branch2c[0][0]              
                                                                   bn4a_branch1[0][0]               
____________________________________________________________________________________________________
activation_28 (Activation)       (None, 4, 4, 1024)    0           add_9[0][0]                      
____________________________________________________________________________________________________
res4b_branch2a (Conv2D)          (None, 4, 4, 256)     262400      activation_28[0][0]              
____________________________________________________________________________________________________
bn4b_branch2a (BatchNormalizatio (None, 4, 4, 256)     1024        res4b_branch2a[0][0]             
____________________________________________________________________________________________________
activation_29 (Activation)       (None, 4, 4, 256)     0           bn4b_branch2a[0][0]              
____________________________________________________________________________________________________
res4b_branch2b (Conv2D)          (None, 4, 4, 256)     590080      activation_29[0][0]              
____________________________________________________________________________________________________
bn4b_branch2b (BatchNormalizatio (None, 4, 4, 256)     1024        res4b_branch2b[0][0]             
____________________________________________________________________________________________________
activation_30 (Activation)       (None, 4, 4, 256)     0           bn4b_branch2b[0][0]              
____________________________________________________________________________________________________
res4b_branch2c (Conv2D)          (None, 4, 4, 1024)    263168      activation_30[0][0]              
____________________________________________________________________________________________________
bn4b_branch2c (BatchNormalizatio (None, 4, 4, 1024)    4096        res4b_branch2c[0][0]             
____________________________________________________________________________________________________
add_10 (Add)                     (None, 4, 4, 1024)    0           bn4b_branch2c[0][0]              
                                                                   activation_28[0][0]              
____________________________________________________________________________________________________
activation_31 (Activation)       (None, 4, 4, 1024)    0           add_10[0][0]                     
____________________________________________________________________________________________________
res4c_branch2a (Conv2D)          (None, 4, 4, 256)     262400      activation_31[0][0]              
____________________________________________________________________________________________________
bn4c_branch2a (BatchNormalizatio (None, 4, 4, 256)     1024        res4c_branch2a[0][0]             
____________________________________________________________________________________________________
activation_32 (Activation)       (None, 4, 4, 256)     0           bn4c_branch2a[0][0]              
____________________________________________________________________________________________________
res4c_branch2b (Conv2D)          (None, 4, 4, 256)     590080      activation_32[0][0]              
____________________________________________________________________________________________________
bn4c_branch2b (BatchNormalizatio (None, 4, 4, 256)     1024        res4c_branch2b[0][0]             
____________________________________________________________________________________________________
activation_33 (Activation)       (None, 4, 4, 256)     0           bn4c_branch2b[0][0]              
____________________________________________________________________________________________________
res4c_branch2c (Conv2D)          (None, 4, 4, 1024)    263168      activation_33[0][0]              
____________________________________________________________________________________________________
bn4c_branch2c (BatchNormalizatio (None, 4, 4, 1024)    4096        res4c_branch2c[0][0]             
____________________________________________________________________________________________________
add_11 (Add)                     (None, 4, 4, 1024)    0           bn4c_branch2c[0][0]              
                                                                   activation_31[0][0]              
____________________________________________________________________________________________________
activation_34 (Activation)       (None, 4, 4, 1024)    0           add_11[0][0]                     
____________________________________________________________________________________________________
res4d_branch2a (Conv2D)          (None, 4, 4, 256)     262400      activation_34[0][0]              
____________________________________________________________________________________________________
bn4d_branch2a (BatchNormalizatio (None, 4, 4, 256)     1024        res4d_branch2a[0][0]             
____________________________________________________________________________________________________
activation_35 (Activation)       (None, 4, 4, 256)     0           bn4d_branch2a[0][0]              
____________________________________________________________________________________________________
res4d_branch2b (Conv2D)          (None, 4, 4, 256)     590080      activation_35[0][0]              
____________________________________________________________________________________________________
bn4d_branch2b (BatchNormalizatio (None, 4, 4, 256)     1024        res4d_branch2b[0][0]             
____________________________________________________________________________________________________
activation_36 (Activation)       (None, 4, 4, 256)     0           bn4d_branch2b[0][0]              
____________________________________________________________________________________________________
res4d_branch2c (Conv2D)          (None, 4, 4, 1024)    263168      activation_36[0][0]              
____________________________________________________________________________________________________
bn4d_branch2c (BatchNormalizatio (None, 4, 4, 1024)    4096        res4d_branch2c[0][0]             
____________________________________________________________________________________________________
add_12 (Add)                     (None, 4, 4, 1024)    0           bn4d_branch2c[0][0]              
                                                                   activation_34[0][0]              
____________________________________________________________________________________________________
activation_37 (Activation)       (None, 4, 4, 1024)    0           add_12[0][0]                     
____________________________________________________________________________________________________
res4e_branch2a (Conv2D)          (None, 4, 4, 256)     262400      activation_37[0][0]              
____________________________________________________________________________________________________
bn4e_branch2a (BatchNormalizatio (None, 4, 4, 256)     1024        res4e_branch2a[0][0]             
____________________________________________________________________________________________________
activation_38 (Activation)       (None, 4, 4, 256)     0           bn4e_branch2a[0][0]              
____________________________________________________________________________________________________
res4e_branch2b (Conv2D)          (None, 4, 4, 256)     590080      activation_38[0][0]              
____________________________________________________________________________________________________
bn4e_branch2b (BatchNormalizatio (None, 4, 4, 256)     1024        res4e_branch2b[0][0]             
____________________________________________________________________________________________________
activation_39 (Activation)       (None, 4, 4, 256)     0           bn4e_branch2b[0][0]              
____________________________________________________________________________________________________
res4e_branch2c (Conv2D)          (None, 4, 4, 1024)    263168      activation_39[0][0]              
____________________________________________________________________________________________________
bn4e_branch2c (BatchNormalizatio (None, 4, 4, 1024)    4096        res4e_branch2c[0][0]             
____________________________________________________________________________________________________
add_13 (Add)                     (None, 4, 4, 1024)    0           bn4e_branch2c[0][0]              
                                                                   activation_37[0][0]              
____________________________________________________________________________________________________
activation_40 (Activation)       (None, 4, 4, 1024)    0           add_13[0][0]                     
____________________________________________________________________________________________________
res4f_branch2a (Conv2D)          (None, 4, 4, 256)     262400      activation_40[0][0]              
____________________________________________________________________________________________________
bn4f_branch2a (BatchNormalizatio (None, 4, 4, 256)     1024        res4f_branch2a[0][0]             
____________________________________________________________________________________________________
activation_41 (Activation)       (None, 4, 4, 256)     0           bn4f_branch2a[0][0]              
____________________________________________________________________________________________________
res4f_branch2b (Conv2D)          (None, 4, 4, 256)     590080      activation_41[0][0]              
____________________________________________________________________________________________________
bn4f_branch2b (BatchNormalizatio (None, 4, 4, 256)     1024        res4f_branch2b[0][0]             
____________________________________________________________________________________________________
activation_42 (Activation)       (None, 4, 4, 256)     0           bn4f_branch2b[0][0]              
____________________________________________________________________________________________________
res4f_branch2c (Conv2D)          (None, 4, 4, 1024)    263168      activation_42[0][0]              
____________________________________________________________________________________________________
bn4f_branch2c (BatchNormalizatio (None, 4, 4, 1024)    4096        res4f_branch2c[0][0]             
____________________________________________________________________________________________________
add_14 (Add)                     (None, 4, 4, 1024)    0           bn4f_branch2c[0][0]              
                                                                   activation_40[0][0]              
____________________________________________________________________________________________________
activation_43 (Activation)       (None, 4, 4, 1024)    0           add_14[0][0]                     
____________________________________________________________________________________________________
res5a_branch2a (Conv2D)          (None, 2, 2, 512)     524800      activation_43[0][0]              
____________________________________________________________________________________________________
bn5a_branch2a (BatchNormalizatio (None, 2, 2, 512)     2048        res5a_branch2a[0][0]             
____________________________________________________________________________________________________
activation_44 (Activation)       (None, 2, 2, 512)     0           bn5a_branch2a[0][0]              
____________________________________________________________________________________________________
res5a_branch2b (Conv2D)          (None, 2, 2, 512)     2359808     activation_44[0][0]              
____________________________________________________________________________________________________
bn5a_branch2b (BatchNormalizatio (None, 2, 2, 512)     2048        res5a_branch2b[0][0]             
____________________________________________________________________________________________________
activation_45 (Activation)       (None, 2, 2, 512)     0           bn5a_branch2b[0][0]              
____________________________________________________________________________________________________
res5a_branch2c (Conv2D)          (None, 2, 2, 2048)    1050624     activation_45[0][0]              
____________________________________________________________________________________________________
res5a_branch1 (Conv2D)           (None, 2, 2, 2048)    2099200     activation_43[0][0]              
____________________________________________________________________________________________________
bn5a_branch2c (BatchNormalizatio (None, 2, 2, 2048)    8192        res5a_branch2c[0][0]             
____________________________________________________________________________________________________
bn5a_branch1 (BatchNormalization (None, 2, 2, 2048)    8192        res5a_branch1[0][0]              
____________________________________________________________________________________________________
add_15 (Add)                     (None, 2, 2, 2048)    0           bn5a_branch2c[0][0]              
                                                                   bn5a_branch1[0][0]               
____________________________________________________________________________________________________
activation_46 (Activation)       (None, 2, 2, 2048)    0           add_15[0][0]                     
____________________________________________________________________________________________________
res5b_branch2a (Conv2D)          (None, 2, 2, 512)     1049088     activation_46[0][0]              
____________________________________________________________________________________________________
bn5b_branch2a (BatchNormalizatio (None, 2, 2, 512)     2048        res5b_branch2a[0][0]             
____________________________________________________________________________________________________
activation_47 (Activation)       (None, 2, 2, 512)     0           bn5b_branch2a[0][0]              
____________________________________________________________________________________________________
res5b_branch2b (Conv2D)          (None, 2, 2, 512)     2359808     activation_47[0][0]              
____________________________________________________________________________________________________
bn5b_branch2b (BatchNormalizatio (None, 2, 2, 512)     2048        res5b_branch2b[0][0]             
____________________________________________________________________________________________________
activation_48 (Activation)       (None, 2, 2, 512)     0           bn5b_branch2b[0][0]              
____________________________________________________________________________________________________
res5b_branch2c (Conv2D)          (None, 2, 2, 2048)    1050624     activation_48[0][0]              
____________________________________________________________________________________________________
bn5b_branch2c (BatchNormalizatio (None, 2, 2, 2048)    8192        res5b_branch2c[0][0]             
____________________________________________________________________________________________________
add_16 (Add)                     (None, 2, 2, 2048)    0           bn5b_branch2c[0][0]              
                                                                   activation_46[0][0]              
____________________________________________________________________________________________________
activation_49 (Activation)       (None, 2, 2, 2048)    0           add_16[0][0]                     
____________________________________________________________________________________________________
res5c_branch2a (Conv2D)          (None, 2, 2, 512)     1049088     activation_49[0][0]              
____________________________________________________________________________________________________
bn5c_branch2a (BatchNormalizatio (None, 2, 2, 512)     2048        res5c_branch2a[0][0]             
____________________________________________________________________________________________________
activation_50 (Activation)       (None, 2, 2, 512)     0           bn5c_branch2a[0][0]              
____________________________________________________________________________________________________
res5c_branch2b (Conv2D)          (None, 2, 2, 512)     2359808     activation_50[0][0]              
____________________________________________________________________________________________________
bn5c_branch2b (BatchNormalizatio (None, 2, 2, 512)     2048        res5c_branch2b[0][0]             
____________________________________________________________________________________________________
activation_51 (Activation)       (None, 2, 2, 512)     0           bn5c_branch2b[0][0]              
____________________________________________________________________________________________________
res5c_branch2c (Conv2D)          (None, 2, 2, 2048)    1050624     activation_51[0][0]              
____________________________________________________________________________________________________
bn5c_branch2c (BatchNormalizatio (None, 2, 2, 2048)    8192        res5c_branch2c[0][0]             
____________________________________________________________________________________________________
add_17 (Add)                     (None, 2, 2, 2048)    0           bn5c_branch2c[0][0]              
                                                                   activation_49[0][0]              
____________________________________________________________________________________________________
activation_52 (Activation)       (None, 2, 2, 2048)    0           add_17[0][0]                     
____________________________________________________________________________________________________
average_pooling2d_1 (AveragePool (None, 1, 1, 2048)    0           activation_52[0][0]              
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 2048)          0           average_pooling2d_1[0][0]        
____________________________________________________________________________________________________
fc6 (Dense)                      (None, 6)             12294       flatten_1[0][0]                  
====================================================================================================
Total params: 23,600,006
Trainable params: 23,546,886
Non-trainable params: 53,120
____________________________________________________________________________________________________
</code></pre>
      </div>
      
      
    
    
    
    
    
    
    
    
  
    </body></html>